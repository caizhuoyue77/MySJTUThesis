\chapter{知识图谱与大语言模型互增益的API编排方法}

\section{引言}
\label{sec:intro}

\subsection{问题构建}

工具增强的 LLM 通过结构化的自然语言文本与环境进行交互。一般的交互过程可以描述如下：在步骤 \( s \) 时，LLM 接收当前环境观察 \( o_s \) 以及交互活动历史 \( C_s \) 作为输入，并产生一个语言思维 \( t_s \in L \)。然后，LLM 通过采取一个动作 \( a_s \in A \) 与环境进行交互，该动作可以描述为一个工具名称及其参数的元组，例如 \( a_s = (tools, args) \)，其中 \( tools \in T \)。随后，LLM 从环境 \( E \) 中获取新的观察 \( o_{s+1} \)。通过迭代这个交互过程，LLM 最终可能解决给定的任务。

LLM 大多是无状态的。交互历史 \( C_s \) 通常作为 LLM 输入的一部分，帮助 LLM 回忆之前的过程并推断下一个动作 \( a_{s+1} \)。我们将 \( C_s \) 定义为大小为 \( K \) 的队列，包含过去的观察、思维和动作，例如 

\[
C_s = [(o_{s-k}, t_{s-k}, a_{s-k}), \ldots, (o_{s-1}, t_{s-1}, a_{s-1})].
\]

在每一步中，新的思维、动作和观察的元组被附加到 \( C_s \) 中；如果达到最大容量，最早的元组将被弹出。

除了 \( C_s \)，可用工具集合 \( T \) 也需要作为输入上下文的一部分，其中 LLM 可以选择一个合适的工具。设 \( P_\theta \) 表示具有参数 \( \theta \) 的工具增强 LLM。严格地说，上述交互过程可以形式化为以下公式：

\[
t_s = P_\theta(C_s \cup o_s) \tag{1}
\]

\[
a_s = P_\theta(C_s \cup o_s, t_s, T) \tag{2}
\]

\[
o_{s+1} = E(a_s) \tag{3}
\]

现有工具增强 LLM 的一个主要问题是它们的重 token 消耗，这在很大程度上归因于 \( C_s \) 和 \( T \) 的长输入上下文。一种代表性的解决方案是将 \( C_s \) 的长文本分段并压缩为语义嵌入。随后，可以计算并排名候选段落与当前观察 \( o_s \) 之间的语义相似度分数。最后，公式 (1) 和 (2) 中的 \( C_s \) 被替换为与 LLM 输入最相关的段落。直观上，这一解决方案可以扩展到 \( T \)，例如，搜索与思维 \( t_s \) 最相关的工具。然而，根据公式 (1)，\( t_s \) 的生成并不具备关于 \( T \) 的全面知识。\( t_s \) 中的语义信息可能与 \( T \) 中的任何工具无关。此外，在大量 API 函数的库中，可能有许多工具共享类似的语义信息，但功能上略有不同。当 \( |T| \) 变大时，通过语义嵌入搜索工具可能会粗糙且不准确。因此，现有的工具学习方法要么局限于数量有限的专门设计的工具，要么使用指令微调来增强 LLM \( P_\theta \) 以包含 \( T \) 的先验知识，这在计算上可能是资源密集型的。

\subsection{基于深度优先遍历的动态搜索算法}

为了更好地利用我们构建的工具图谱，并挖掘隐藏节点关系中的知识，我们开发了一个基于深度优先遍历的寻路算法。与“思维链”（Chain-of-Thought）或ReACT方法相比，该算法的优点在于能够防止错误传播，并对整体工具行动空间进行更深入的探索。

我们提出的基于深度优先的寻路算法的流程图如下所示：

首先，由于图谱上的节点数量众多，选择初始节点是算法中非常关键的一步。在选择初始节点时，我们利用基于语义相似度的API召回器，得到与用户需求在语义上最相似的一组工具，让大语言模型进行选择，最终确定初始节点，并从该节点开始进行后续探索。

其次，我们在图上构建一棵深度优先搜索树，允许模型在图上不断选择新的节点并评估每一条推理路径。具体逻辑如下：对于每个选择的节点，我们调用该节点并获取对应的API响应内容，然后将已经调用的工具轨迹、解析后的API响应、用户需求等提供给大语言模型，让模型选择下一步操作。下一步操作可以是继续选择节点，也可以是回溯到上一节点。

如果模型选择了下一步操作，我们将获取当前节点的邻居节点及其权值，并提供给大模型智能体。对于邻居节点的选择，我们会获取到当前节点权值最大的5个节点作为下一步操作。如果邻居节点不足5个，我们将重新调用API召回器，以补全5个选择的选项。模型会根据当前状态继续迭代选择，直到结束选择或放弃。

如果模型选择回溯到上一节点，我们将在短期记忆模块中添加回溯步骤，并恢复到上一个节点的状态。将回溯步骤添加到短期记忆的原因是让模型记住在本次推理中之前采取的错误操作，避免后续重复选择不可行的工具。如果模型回溯到了初始节点，并且需要继续回溯，我们可以理解为基于当前的工具组，该任务不可行，即放弃任务执行。

\begin{algorithm}[htb]
    \caption{图谱节点选择算法}
    \label{algo:algorithm}
    \small
    \SetAlgoLined
    \KwData{用户需求 $user需求$}
    \KwResult{选择合适的工具}
  
    // 选择初始节点\;
    $initialNodes \gets API召回器(user需求)$\;
    $selectedNode \gets LLM选择初始节点(initialNodes)$\;
    
    // 初始化深度优先搜索树\;
    $dfsTree \gets \text{new Tree()}$\;
    $dfsTree.addNode(selectedNode)$\;
  
    \While{true}{
      $response \gets 调用API(selectedNode)$\;
      
      // 提供信息给大语言模型\;
      $状态信息 \gets \{\text{工具轨迹}, \text{API响应}, \text{用户需求}\}$\;
      $nextAction \gets LLM选择下一步操作(状态信息)$\;
  
      \eIf{nextAction == "选择下一节点"}{
        $topNeighbors \gets 选择邻居节点(selectedNode)$\;
        \If{length(topNeighbors) < 5}{
          $topNeighbors \gets API召回器补全选择(selectedNode)$\;
        }
        $selectedNode \gets LLM选择下一个节点(topNeighbors)$\;
        $dfsTree.addNode(selectedNode)$\;
      }{
        // 回溯逻辑\;
        $短期记忆.add回溯步骤(dfsTree.currentNode())$\;
        $selectedNode \gets dfsTree.backtrack()$\;
  
        \If{selectedNode == dfsTree.root() \&\& 需要继续回溯()}{
          放弃任务()\;
          break\;
        }
      }
      
      \If{模型结束选择()}{
        break\;
      }
    }
  \end{algorithm}

\subsection{自我反思机制}

本文构建的自我反思框架会在动态寻路算法选择“放弃”或者评判器将该路径判定为“失败”的情况下被激活。在自我反思框架中，我们首先需要进行“反思”，即根据当前编排得到的工具调用路径，识别未能成功满足用户需求的原因。具体而言，当动态寻路算法的选择器决定“放弃”某条路径时，会提供该路径放弃的具体原因。这些“放弃原因”可作为反思的依据，以指导模型在后续的路径选择中作出更为合理的决策。此外，在动态寻路算法得出一个解决方案后，若经过评估器的评估发现该路径未能充分满足用户需求，则会引用评估器所提供的失败理由。评估器在评估失败时会对该路径及总结器的最终回答提供一个等级，根据失败的等级我们可以选择以下两种不同的重新寻路算法：第一种是从中间步骤开始重新寻找路径，另一种是从头开始重新寻找路径。

\begin{enumerate}
  \item \textbf{从中间步骤继续}: 在任务未完成的情况下，我们将持续记录检索过程中的每一步输入、输出及上下文信息。当路径被标记为“放弃”或被评判器认定为“失败”时，我们会重新激活该路径上的智能体，并将识别到的失败原因重新纳入历史上下文。评判器在判定“失败”时，通常会标记出它认为的第一个出现错误的节点。在重新激活智能体并进行寻路时，我们将从该节点继续，而不是从头开始。这种从中间步骤继续的策略不仅能够加快寻路速度，减少大语言模型的调用次数，还能充分利用先前成功调用的经验，从而提升决策的准确性。
  \item \textbf{重新寻路}: 在评判器认为路径“完全失败”时，我们需要从头开始重新生成整条路径。评判器会识别路径初始节点中与用户查询无关的工具名称作为反思的一部分。为了提高系统的整体效率，我们会首先从初始工具节点中移除这些无关的工具，避免大模型受到这些噪声的影响，从而选择无关的工具进行调用，导致后续调用出错。通过这一清理过程，我们能够有效减少噪声工具的影响，确保后续搜索的准确性。尽管本文提出的基于深度优先遍历的算法可以通过回溯来避免错误传播的问题，但我们也应尽可能地避免选择错误和无关的工具，这样会增加寻路时间，也会使算法面临更多的不稳定性。\n 接下来，我们将会在经过噪声清理的工具组中重新开始选择下一节点并组成路径。这种从头开始的自我反思允许算法在一个更加简洁与优化的初始条件下进行搜索，从而提升工具调用路径的质量与响应速度。
\end{enumerate}
 
该自我反思机制可以反复应用，直至满足终止条件为止。这种持续的反思过程确保了对问题的深入理解和逐步优化，有助于形成更加有效的调用路径。

综上所述，这两种反思策略——从中间步骤继续优化和从头开始的寻路——的结合使用，能够在处理用户需求未满足的情况下，提供更高的灵活性与效率。通过不断的反思与优化，系统将逐步提升其在动态环境中的适应能力，确保用户体验的持续改进。

\subsection{工具调用路径长短期记忆框架}

\subsubsection{长短期记忆框架概述}

本小节提出了关于增强模型规划和推理准确性的长短期记忆框架。该框架主要分为短期记忆和长期记忆两个部分。短期记忆部分指的是当模型在图上动态推理时存储的每个步骤的记录，主要聚焦于以什么数据格式来存储推理步骤，以及记录哪些有用的记忆信息：在图上前进、回溯还有大模型的思考过程等。长期记忆部分主要有记忆存储、召回和利用三个部分，围绕着如何进一步利用过去成功推理的经验来辅助后续的推理和规划过程。

\subsubsection{短期记忆}

短期记忆指的是模型在图上进行不断推理时保存的一些状态信息，这些信息包括：用户的任务、当前遍历到的节点、历史遍历的节点、轨迹路径信息等。在遍历的过程中，我们会动态地更新和维护短期记忆存储的内容，来辅助模型进行推理和规划。在短期记忆中，我们一般将全部的信息存储在内存中，然后直接构建提示词添加到大语言模型的上下文中，让模型能够感知到当前的状态和环境。

\subsubsection{长期记忆}

长期记忆是与短期记忆相对的概念，长期记忆会固定地存在数据库中，并且随着调用次数增多而积累。长期记忆记录的是最终形成的工具调用链以及结果，每次在系统进行推理时都会从长期记忆库中进行搜索，从而利用历史经验知识来辅助模型的推理。

长期记忆的具体实现方式如下，包括记忆的添加、删除、修改和查询四个部分。

\begin{enumerate}
    \item \textbf{记忆添加} \\
    记忆增加是该框架中最基础的功能。首先，除了初始记忆批量添加的阶段，其他的记忆添加都是在生成了新的推理路径时进行。我们先对新生成的推理路径进行筛选，通过一个评判器来对推理路径判断质量。如果评判器认定为“失败”或“不确定”，那么就舍弃当前的推理路径。这一步的判别是为了保证记忆的质量，不存储有失败风险的路径在记忆中。随后，我们将用户的需求与推理路径形成一个二元组，将用户需求输入向量模型转为嵌入向量，将推理路径作为文本格式存储，方便计算和检索记忆。

    \item \textbf{记忆修改} \\
    对于同一个任务，系统可能会生成不同的推理路径。在这种情况下，我们会用新的记忆来替换旧的记忆，对记忆做出及时的更新。在记忆修改时，我们只需要对推理路径部分进行修改，并保存更新后的路径在数据库中，而不需要对用户需求的向量部分进行修改。

    \item \textbf{记忆删除} \\
    由于工具节点的状态是随时变化的，比如开发者停止维护了某个工具，或者是某个工具 API 出现故障等等，因此有的时候我们会删除一些工具节点或修改节点状态为“失效”。在这种情况下，我们除了在工具图谱上进行修改，也应该同时删除有关的记忆，避免对模型造成困扰。记忆删除的逻辑较为清晰，即当某工具被删除或失效时，在记忆库中匹配所有包含该工具的路径并删除对应的记忆。

    \item \textbf{记忆查询} \\
    在有新的用户需求时，系统会首先将用户需求转为向量形式，然后在向量数据库中通过相似度检索算法查找到与当前需求最相似的 K 个历史需求以及对应的工具轨迹，即搜索得到的记忆。
\end{enumerate}

\subsubsection{记忆搜索与召回}
\subsubsection{记忆利用}
（可以做消融实验）

\section{真实工具调用模拟}
\label{sec:real_tool_simulation}

\section{实验与评估}
\subsection{测试数据集}
\label{subsec:test_dataset}

ToolBench。ToolBench\cite{Qin2023}是一个公开的针对工具调用的数据集，其中包含了来自49个类别的16464个真实世界的API工具的推理轨迹数据。该数据集包括三个部分，三个子数据集的难度逐级上升：G1数据集，其中目标任务所需的API都在同一个工具组；G2数据集，其中目标任务所需的API在同一个类别但是属于不同的工具组；G3数据集，其中目标任务所需的API会跨越不同类别。为了测试各个难度等级上的能力，本工作从三个类别分别抽取了350，350和300条数据构建测试集。测试集一共涉及18个category的358个工具。

API-Bank。API-Bank\cite{Li2023}是另一个公开的工具调用数据集，作者们针对模型工具调用的检索、规划能力的评估精心构建了测试数据，其中包含73个API工具，并对314个工具调用进行了标注。本工作从中抽取了300条数据作为测试集。

\subsection{评估指标}
由于工具的多样性，对于同一个用户需求可以有多种工具调用路径。因此，我们无法事先对每个测试的输入标注单一的解决路径标准答案。由于人工评价较为费时费力，本文基于\cite{Tang2023}中的评估器构建了类似的评估体系，包含以下两个指标。我们的评估器使用的是目前能力最强的模型之一GPT-4，温度系数设置为0。（todo）

\begin{itemize}
    \item \textbf{通过率（Pass Rate）} \\
    通过率是计算在有限的工具执行步骤内完成了需求的比例。该指标衡量了系统工具调用最基本的执行能力。通过率的公式如下：

    \begin{equation}
        PR = \frac{ \#(\text{Solved}) }{ \#(\text{Solved}) + \#(\text{Unsolved}) }.
    \end{equation}

    \item \textbf{胜率（Win Rate）} \\
    胜率是评价两条针对同一需求生成的路径的偏好。在模型判断胜率的评估器的提示词中，我们预先定义了一组标准，其中包括：探索性、真实性、工具个数。胜率的公式如下：

    \begin{equation}
        WR = \frac{ \#(\text{Won}) }{ \#(\text{Won}) + \#(\text{Lost}) + \#(\text{Tie}) }.
    \end{equation}

\end{itemize}

同时，为了验证评估器与人类标注者的标注一致性，我们人工标注了100条通过率和100条胜率的数据。经过这200条数据，我们发现标注器在通过率上与人工标注的一致性达到了xxx（todo），在胜率上该数字达到了xxx（todo），这表明该基于大语言模型的标注器与人工标注的标准基本吻合。

\subsection{实验结果}
我们在不同基模型上测试了不同的工具编排调用方式并与我们的方法进行对比。
\begin{itemize}
    \item 基准线：其他的vanilla、cot、react的prompt等。
\end{itemize}

\subsection{实验分析}
\label{subsec:exp_analysis}

\section{本章小结}
\label{sec:summary_chap4}