\chapter{知识图谱与大语言模型互增益的API编排方法}

\section{引言}
\label{sec:intro}

\section{问题构建}

工具增强的 LLM 通过结构化的自然语言文本与环境进行交互。一般的交互过程可以描述如下：在步骤 \( s \) 时，LLM 接收当前环境观察 \( o_s \) 以及交互活动历史 \( C_s \) 作为输入，并产生一个语言思维 \( t_s \in L \)。然后，LLM 通过采取一个动作 \( a_s \in A \) 与环境进行交互，该动作可以描述为一个工具名称及其参数的元组，例如 \( a_s = (tools, args) \)，其中 \( tools \in T \)。随后，LLM 从环境 \( E \) 中获取新的观察 \( o_{s+1} \)。通过迭代这个交互过程，LLM 最终可能解决给定的任务。

LLM 大多是无状态的。交互历史 \( C_s \) 通常作为 LLM 输入的一部分，帮助 LLM 回忆之前的过程并推断下一个动作 \( a_{s+1} \)。我们将 \( C_s \) 定义为大小为 \( K \) 的队列，包含过去的观察、思维和动作，例如 

\[
C_s = [(o_{s-k}, t_{s-k}, a_{s-k}), \ldots, (o_{s-1}, t_{s-1}, a_{s-1})].
\]

在每一步中，新的思维、动作和观察的元组被附加到 \( C_s \) 中；如果达到最大容量，最早的元组将被弹出。

除了 \( C_s \)，可用工具集合 \( T \) 也需要作为输入上下文的一部分，其中 LLM 可以选择一个合适的工具。设 \( P_\theta \) 表示具有参数 \( \theta \) 的工具增强 LLM。严格地说，上述交互过程可以形式化为以下公式：

\[
t_s = P_\theta(C_s \cup o_s) \tag{1}
\]

\[
a_s = P_\theta(C_s \cup o_s, t_s, T) \tag{2}
\]

\[
o_{s+1} = E(a_s) \tag{3}
\]

现有工具增强 LLM 的一个主要问题是它们的重 token 消耗，这在很大程度上归因于 \( C_s \) 和 \( T \) 的长输入上下文。一种代表性的解决方案是将 \( C_s \) 的长文本分段并压缩为语义嵌入。随后，可以计算并排名候选段落与当前观察 \( o_s \) 之间的语义相似度分数。最后，公式 (1) 和 (2) 中的 \( C_s \) 被替换为与 LLM 输入最相关的段落。直观上，这一解决方案可以扩展到 \( T \)，例如，搜索与思维 \( t_s \) 最相关的工具。然而，根据公式 (1)，\( t_s \) 的生成并不具备关于 \( T \) 的全面知识。\( t_s \) 中的语义信息可能与 \( T \) 中的任何工具无关。此外，在大量 API 函数的库中，可能有许多工具共享类似的语义信息，但功能上略有不同。当 \( |T| \) 变大时，通过语义嵌入搜索工具可能会粗糙且不准确。因此，现有的工具学习方法要么局限于数量有限的专门设计的工具，要么使用指令微调来增强 LLM \( P_\theta \) 以包含 \( T \) 的先验知识，这在计算上可能是资源密集型的。

\section{任务改写与子任务拆解模块}

1. 用户需求模糊，需要分析用户意图，转为更加明确的语句

2. 用户需求包含多个子任务（子任务可能是不同领域的、差别较大、如果混在一起搜索会如何如何）

\section{基于深度优先遍历的动态搜索算法}

为了更好地利用我们构建的工具图谱，并挖掘隐藏节点关系中的知识，我们开发了一个基于深度优先遍历的寻路算法。与“思维链”（Chain-of-Thought）或ReACT方法相比，该算法的优点在于能够防止错误传播，并对整体工具行动空间进行更深入的探索。

我们提出的基于深度优先的寻路算法的流程图如下所示：

首先，由于图谱上的节点数量众多，选择初始节点是算法中非常关键的一步。在选择初始节点时，我们利用基于语义相似度的API召回器，得到与用户需求在语义上最相似的一组工具，让大语言模型进行选择，最终确定初始节点，并从该节点开始进行后续探索。

其次，我们在图上构建一棵深度优先搜索树，允许模型在图上不断选择新的节点并评估每一条推理路径。具体逻辑如下：对于每个选择的节点，我们调用该节点并获取对应的API响应内容，然后将已经调用的工具轨迹、解析后的API响应、用户需求等提供给大语言模型，让模型选择下一步操作。下一步操作可以是继续选择节点，也可以是回溯到上一节点。

如果模型选择了下一步操作，我们将获取当前节点的邻居节点及其权值，并提供给大模型智能体。对于邻居节点的选择，我们会获取到当前节点权值最大的5个节点作为下一步操作。如果邻居节点不足5个，我们将重新调用API召回器，以补全5个选择的选项。模型会根据当前状态继续迭代选择，直到结束选择或放弃。

如果模型选择回溯到上一节点，我们将在短期记忆模块中添加回溯步骤，并恢复到上一个节点的状态。将回溯步骤添加到短期记忆的原因是让模型记住在本次推理中之前采取的错误操作，避免后续重复选择不可行的工具。如果模型回溯到了初始节点，并且需要继续回溯，我们可以理解为基于当前的工具组，该任务不可行，即放弃任务执行。

\begin{algorithm}[htb]
    \caption{图谱节点选择算法}
    \label{algo:algorithm}
    \small
    \SetAlgoLined
    \KwData{用户需求 $user需求$}
    \KwResult{选择合适的工具}
  
    // 选择初始节点\;
    $initialNodes \gets API召回器(user需求)$\;
    $selectedNode \gets LLM选择初始节点(initialNodes)$\;
    
    // 初始化深度优先搜索树\;
    $dfsTree \gets \text{new Tree()}$\;
    $dfsTree.addNode(selectedNode)$\;
  
    \While{true}{
      $response \gets 调用API(selectedNode)$\;
      
      // 提供信息给大语言模型\;
      $状态信息 \gets \{\text{工具轨迹}, \text{API响应}, \text{用户需求}\}$\;
      $nextAction \gets LLM选择下一步操作(状态信息)$\;
  
      \eIf{nextAction == "选择下一节点"}{
        $topNeighbors \gets 选择邻居节点(selectedNode)$\;
        \If{length(topNeighbors) < 5}{
          $topNeighbors \gets API召回器补全选择(selectedNode)$\;
        }
        $selectedNode \gets LLM选择下一个节点(topNeighbors)$\;
        $dfsTree.addNode(selectedNode)$\;
      }{
        // 回溯逻辑\;
        $短期记忆.add回溯步骤(dfsTree.currentNode())$\;
        $selectedNode \gets dfsTree.backtrack()$\;
  
        \If{selectedNode == dfsTree.root() \&\& 需要继续回溯()}{
          放弃任务()\;
          break\;
        }
      }
      
      \If{模型结束选择()}{
        break\;
      }
    }
  \end{algorithm}

\section{自我反思机制}

本文构建的自我反思框架会在动态寻路算法选择“放弃”或者评判器将该路径判定为“失败”的情况下被激活。在自我反思框架中，我们首先需要进行“反思”，即根据当前编排得到的工具调用路径，识别未能成功满足用户需求的原因。具体而言，当动态寻路算法的选择器决定“放弃”某条路径时，会提供该路径放弃的具体原因。这些“放弃原因”可作为反思的依据，以指导模型在后续的路径选择中作出更为合理的决策。此外，在动态寻路算法得出一个解决方案后，若经过评估器的评估发现该路径未能充分满足用户需求，则会引用评估器所提供的失败理由。评估器在评估失败时会对该路径及总结器的最终回答提供一个等级，根据失败的等级我们可以选择以下两种不同的重新寻路算法：第一种是从中间步骤开始重新寻找路径，另一种是从头开始重新寻找路径。

\begin{enumerate}
  \item \textbf{从中间步骤继续}: 在任务未完成的情况下，我们将持续记录检索过程中的每一步输入、输出及上下文信息。当路径被标记为“放弃”或被评判器认定为“失败”时，我们会重新激活该路径上的智能体，并将识别到的失败原因重新纳入历史上下文。评判器在判定“失败”时，通常会标记出它认为的第一个出现错误的节点。在重新激活智能体并进行寻路时，我们将从该节点继续，而不是从头开始。这种从中间步骤继续的策略不仅能够加快寻路速度，减少大语言模型的调用次数，还能充分利用先前成功调用的经验，从而提升决策的准确性。
  \item \textbf{重新寻路}: 在评判器认为路径“完全失败”时，我们需要从头开始重新生成整条路径。评判器会识别路径初始节点中与用户查询无关的工具名称作为反思的一部分。为了提高系统的整体效率，我们会首先从初始工具节点中移除这些无关的工具，避免大模型受到这些噪声的影响，从而选择无关的工具进行调用，导致后续调用出错。通过这一清理过程，我们能够有效减少噪声工具的影响，确保后续搜索的准确性。尽管本文提出的基于深度优先遍历的算法可以通过回溯来避免错误传播的问题，但我们也应尽可能地避免选择错误和无关的工具，这样会增加寻路时间，也会使算法面临更多的不稳定性。\par
  接下来，我们将会在经过噪声清理的工具组中重新开始选择下一节点并组成路径。这种从头开始的自我反思允许算法在一个更加简洁与优化的初始条件下进行搜索，从而提升工具调用路径的质量与响应速度。
\end{enumerate}
 
该自我反思机制可以反复应用，直至满足终止条件为止。这种持续的反思过程确保了对问题的深入理解和逐步优化，有助于形成更加有效的调用路径。

综上所述，这两种反思策略——从中间步骤继续优化和从头开始的寻路——的结合使用，能够在处理用户需求未满足的情况下，提供更高的灵活性与效率。通过不断的反思与优化，系统将逐步提升其在动态环境中的适应能力，确保用户体验的持续改进。

\section{工具调用路径长短期记忆框架}

\subsection{长短期记忆框架概述}

本小节提出了关于增强模型规划和推理准确性的长短期记忆框架。该框架主要分为短期记忆和长期记忆两个部分。短期记忆部分指的是当模型在图上动态推理时存储的每个步骤的记录，主要聚焦于以什么数据格式来存储推理步骤，以及记录哪些有用的记忆信息：在图上前进、回溯还有大模型的思考过程等。长期记忆部分主要有记忆存储、召回和利用三个部分，围绕着如何进一步利用过去成功推理的经验来辅助后续的推理和规划过程。

\subsection{短期记忆}

短期记忆指的是模型在图上进行不断推理时保存的一些状态信息，这些信息包括：用户的任务、当前遍历到的节点、历史遍历的节点、轨迹路径信息等。在遍历的过程中，我们会动态地更新和维护短期记忆存储的内容，来辅助模型进行推理和规划。在短期记忆中，我们一般将全部的信息存储在内存中，然后直接构建提示词添加到大语言模型的上下文中，让模型能够感知到当前的状态和环境。

\subsection{长期记忆}

长期记忆是与短期记忆相对的概念，长期记忆会固定地存在数据库中，并且随着调用次数增多而积累。长期记忆记录的是最终形成的工具调用链以及结果，每次在系统进行推理时都会从长期记忆库中进行搜索，从而利用历史经验知识来辅助模型的推理。

长期记忆的具体实现方式如下，包括记忆的添加、删除、修改和查询四个部分。

\begin{enumerate}
    \item \textbf{记忆添加} \\
    记忆增加是该框架中最基础的功能。首先，除了初始记忆批量添加的阶段，其他的记忆添加都是在生成了新的推理路径时进行。我们先对新生成的推理路径进行筛选，通过一个评判器来对推理路径判断质量。如果评判器认定为“失败”或“不确定”，那么就舍弃当前的推理路径。这一步的判别是为了保证记忆的质量，不存储有失败风险的路径在记忆中。随后，我们将用户的需求与推理路径形成一个二元组，将用户需求输入向量模型转为嵌入向量，将推理路径作为文本格式存储，方便计算和检索记忆。

    \item \textbf{记忆修改} \\
    对于同一个任务，系统可能会生成不同的推理路径。在这种情况下，我们会用新的记忆来替换旧的记忆，对记忆做出及时的更新。在记忆修改时，我们只需要对推理路径部分进行修改，并保存更新后的路径在数据库中，而不需要对用户需求的向量部分进行修改。

    \item \textbf{记忆删除} \\
    由于工具节点的状态是随时变化的，比如开发者停止维护了某个工具，或者是某个工具 API 出现故障等等，因此有的时候我们会删除一些工具节点或修改节点状态为“失效”。在这种情况下，我们除了在工具图谱上进行修改，也应该同时删除有关的记忆，避免对模型造成困扰。记忆删除的逻辑较为清晰，即当某工具被删除或失效时，在记忆库中匹配所有包含该工具的路径并删除对应的记忆。

    \item \textbf{记忆查询} \\
    在有新的用户需求时，系统会首先将用户需求转为向量形式，然后在向量数据库中通过相似度检索算法查找到与当前需求最相似的 K 个历史需求以及对应的工具轨迹，即搜索得到的记忆。
\end{enumerate}

\subsection{记忆搜索与召回}
\subsection{记忆利用}
（可以做消融实验）

\section{工具调用模块}
\label{sec:real_tool_simulation}

\subsection{整体逻辑}

工具调用模块的主要功能是执行规划好的API调用路径，并将得到的结果返回给系统，从而为后续的推理和规划提供支持，最终生成符合用户需求的答案。该模块的整体逻辑可以分为两个主要部分：工具调用和工具响应解析。具体而言，我们首先根据工具的描述信息生成请求体，然后通过工具规划流程确定请求体中的参数，最后结合用户需求填充请求体中的参数值。在生成请求体后，我们通过API调用接口将请求体发送给目标API工具，以获取其响应。获得响应后，我们首先检查响应内容的长度，以决定是否需要对API响应进行压缩。最后，经过压缩的API响应将被存储在路径规划智能体的“短期记忆”中，即模型的上下文，以辅助模型生成最终结果。

\subsection{工具调用模块}

工具调用模块的主要工作就是生成API工具的请求体。在请求体的生成过程中，我们首先将与工具调用相关的内容提供给大语言模型智能体，要求其生成指定的JSON格式调用输入，包括但不限于工具调用的URL、所需输入参数及工具的登录验证信息等。接着，我们对生成的JSON数据中的参数信息进行验证，并确定请求体中各个参数的结构和格式。

首先，我们会确认生成的参数URL与工具库中的URL是否匹配。其次，参数的正确性对API工具调用的成功至关重要，因此在执行调用工具代码之前，我们会对参数进行严格的校验。在这一步中，我们验证具体的参数数量、类型和名称，并对这些部分进行精确匹配。如果缺少必要的参数或参数类型不匹配，我们将返回固定的错误信息，并要求参数解析器重新生成参数。这一过程会一直重复，直到获取正确的参数或超过最大尝试次数后放弃该API调用。

在成功验证URL和参数后，我们将调用固定的函数来执行API请求，并获取JSON格式的响应，随后将其提供给响应解析模块。

\subsection{工具响应解析模块}

生成请求体后，我们将其通过API调用接口发送给目标API工具，以获取相应的响应数据。响应数据通常是以JSON格式返回的，这其中可能包含大量的信息，而这些信息并不总是直接相关。在我们的实际实验中，我们通过分析发现许多API返回内容包含大量冗余信息，导致其长度过长，无法将调用结果输入到大语言模型中，直接使用大语言模型从中提取重要信息较为困难。因此，我们对API的响应结果进行了压缩。该模块的目标是在尽可能多地保留关键信息的同时减少API响应的长度，便于放入大语言模型的上下文中。

由于每个API的响应格式不是固定的，无法确定每个字段应该舍弃还是保留，因此我们采用大语言模型来分析示例响应，仅保留与用户需求相关的字段，以减小响应长度。具体步骤包括：

\begin{enumerate}
    \item \textbf{工具文档信息}：所有API工具均来自ToolBench等开源数据集，这些数据集同时包含每个API的详细描述信息和API响应示例。因此，我们可以将工具名称、工具描述、API名称、API描述、参数及API响应示例的内容以文本形式提供给大型语言模型。这部分构成了压缩模块的基本提示词。
    
    \item \textbf{详细规则指令}：我们要求大型语言模型仔细阅读API的功能描述，并保留与功能描述最相关的信息，诸如API版本、调用时间或无效信息等可以被舍弃。
    
    \item \textbf{上下文学习示例}：我们使用了三个上下文学习示例，每个示例由一个原始API响应和对应的专家撰写的压缩响应组成。我们要求压缩器以自然语言文本格式输出所有需要保留的字段，然后通过正则表达式匹配得到一个保留字段的列表，并用固定的代码逻辑筛选出相应字段的返回内容。
\end{enumerate}

在推理过程中，当API响应长度超过1024个字符时，我们会通过移除不重要的信息来压缩响应。如果压缩后的响应仍然超过1024个字符，则只保留压缩后的前1024个字符。这种方法能够有效地减少API响应长度，对API响应进行去噪。同时，也能够缓解大型语言模型有限的上下文窗口的问题，确保系统的正常调用。

通过分析我们在ToolBench中的API响应示例，其中一个API的平均响应字符串长度为xxx个字符。经过响应压缩后，最长的响应也不超过1024个字符。通过这种方式，我们有效降低了xx\%的超出上下文的情况，平均每个API响应结果节约了xx个字符。

（todo，做实验）

\section{实验与评估}

\subsection{测试数据集}
\label{subsec:test_dataset}

ToolBench。ToolBench\cite{Qin2023}是一个公开的针对工具调用的数据集，其中包含了来自49个类别的16464个真实世界的API工具的推理轨迹数据。该数据集包括三个部分，三个子数据集的难度逐级上升：G1数据集，其中目标任务所需的API都在同一个工具组；G2数据集，其中目标任务所需的API在同一个类别但是属于不同的工具组；G3数据集，其中目标任务所需的API会跨越不同类别。为了测试各个难度等级上的能力，本工作从三个类别分别抽取了350，350和300条数据构建测试集。测试集一共涉及18个category的358个工具。

API-Bank。API-Bank\cite{Li2023}是另一个公开的工具调用数据集，作者们针对模型工具调用的检索、规划能力的评估精心构建了测试数据，其中包含73个API工具，并对314个工具调用进行了标注。本工作从中抽取了300条数据作为测试集。

考虑到RapidAPIHub上的API的质量参差不齐，比如有一些API工具为废弃的，并且存在一大部分API工具为付费工具，这都可能会给测试过程引入不必要的噪声。

因此本工作首先筛选得到了一组覆盖各种类别的已知可用的高质量API工具，然后针对这些API工具，沿用ToolBench的方法构建了三个不同难度的测试数据集，作为该方法的测试数据。下面将会详细介绍数据集的构建过程。


\subsubsection{高质量API工具集筛选}

首先，我们需要定义什么是高质量的API工具。在我们的使用场景中，工具的可用性是首要考虑因素，因此必须确保筛选后的API工具都是可用的。此外，在工具选择模块中，我们使用API工具的名称和描述信息作为输入，供模型参考和选择。因此，API名称的易读性和描述的丰富性也是筛选时的重要参考标准。

同时，在保证API质量的基础上，我们也希望尽可能覆盖更多的工具类别和工具集。因此，我们从每个不同类别的工具中进行采样，选择了共计xx个类别、xx个工具集的xx个工具，作为筛选前的工具池。

基于上述规则，我们构建了一个工具筛选流程，并针对不同维度设置了相应的筛选机制。对于API工具的可用性，我们通过调用示例代码来测试每个工具的有效性。根据API的返回状态码、请求响应时间和响应内容，我们选择最合适的API。在我们评估的xx个API工具中，有xx个API的响应状态码为错误码，且有xx个API未能在规定的时间内返回。经过可用性筛选后，我们从xx个工具中筛选得到了xx个可用工具。

对于API描述的丰富性和完整性，我们采用大语言模型标注的方法进行筛选。我们构建了包含详细指令和筛选标准的提示词，并提供了few-shot样例，供模型对每个API进行评估。为加快筛选速度并节约模型调用的字数，每次将5个API进行批量判断。模型将输出一个JSON格式的列表，包含对每个API的保留或丢弃的判断。

经过第二轮筛选后，最终剩下的高质量API工具共有xx个。

画表格，介绍每个不同部分有哪些API种类。

\subsubsection{工具调用数据集构造}

为了覆盖不同难度和复杂度的用户需求，我们参考ToolBench中的分类方法，选择了三个不同难度的任务类别：单工具任务、多工具集任务和多类别任务。

\begin{enumerate}
  \item \textbf{单工具任务} \\
    该任务仅涉及一个工具，用户需求仅包含一个工具的调用。这是工具调用中最简单的情况，通常用于测试大语言模型在处理基本指令时的能力。在数据生成过程中，我们直接随机采样一些API，并引导大语言模型生成与这些API相关的用户需求。这种方法不仅能够快速生成数据，还能确保指令的有效性和准确性，适用于初学者或对工具调用不太熟悉的用户。

  \item \textbf{多工具集任务} \\
    该任务涉及多个工具集，用户需求需要调用多个工具集中的多个工具。这种任务要求大语言模型具备更高的灵活性和综合能力，能够理解不同工具之间的功能关系。在实现时，我们随机采样来自不同工具集的工具，并将其提供给大语言模型，让其生成用户需求。为了确保生成的需求合理，我们特别考虑了工具组合的有效性。对于那些功能上明显重复或无法自然组合在一起的工具API，大语言模型将直接放弃生成不合逻辑的用户需求，并重新采样一组更合理的API。这种方法有效地增强了模型在实际应用中的适应性，帮助生成更符合真实场景的用户需求。

  \item \textbf{多类别任务} \\
    该任务涉及多个类别，用户需求需要调用多个类别的多个工具。这是对大语言模型综合能力的进一步挑战，因为不同类别的工具可能具有不同的功能和用途。在实现过程中，我们同样随机采样来自不同类别的工具，并将其提供给大语言模型，促使其生成多样化的用户需求。这种多类别的设计不仅提高了数据的复杂性，还增强了模型在处理多元化需求时的能力，使其更接近于真实世界的使用场景。

\end{enumerate}

通过上述的方法，我们构建了一个共1000条数据的测试集，其中单工具、多工具集和多类别任务分别占350、350和300条。这种结构化的测试集设计使得我们能够全面评估大语言模型在处理不同复杂度的用户需求时的表现，进而优化模型的生成能力和适应性。经过人工的评估，这种方法具有较高的多样性，能够覆盖到大部分的实际场景。

\subsection{评估指标}
由于工具的多样性，对于同一个用户需求可以有多种工具调用路径。因此，我们无法事先对每个测试的输入标注单一的解决路径标准答案。由于人工评价较为费时费力，本文基于\cite{Tang2023}中的评估器构建了类似的评估体系，包含以下两个指标。我们的评估器使用的是目前能力最强的模型之一GPT-4，温度系数设置为0。（todo）

\begin{itemize}
    \item \textbf{通过率（Pass Rate）} \\
    通过率是计算在有限的工具执行步骤内完成了需求的比例。该指标衡量了系统工具调用最基本的执行能力。通过率的公式如下：

    \begin{equation}
        PR = \frac{ \#(\text{Solved}) }{ \#(\text{Solved}) + \#(\text{Unsolved}) }.
    \end{equation}

    \item \textbf{胜率（Win Rate）} \\
    胜率是评价两条针对同一需求生成的路径的偏好。在模型判断胜率的评估器的提示词中，我们预先定义了一组标准，其中包括：探索性、真实性、工具个数。胜率的公式如下：

    \begin{equation}
        WR = \frac{ \#(\text{Won}) }{ \#(\text{Won}) + \#(\text{Lost}) + \#(\text{Tie}) }.
    \end{equation}

\end{itemize}

同时，为了验证评估器与人类标注者的标注一致性，我们人工标注了100条通过率和100条胜率的数据。经过这200条数据，我们发现标注器在通过率上与人工标注的一致性达到了xxx（todo），在胜率上该数字达到了xxx（todo），这表明该基于大语言模型的标注器与人工标注的标准基本吻合。

\subsection{基准线}

为了对比本研究提出的基于Agent与知识图谱的任务编排与执行方法的效果，本文选用下列方法作为实验的基准方法。

\indent \textbf{基本提示方法}

\indent \textbf{思维链方法}

\indent \textbf{ReACT方法}

\subsection{实验结果}

实验设置

\label{subsec:exp_results}

\subsection{错误分析}
\label{subsec:error_analysis}


\section{本章小结}
\label{sec:summary_chap4}