\chapter{基于工具图谱与深度优先遍历的API编排与调用方法}

\section{引言}
\label{sec:intro}

\indent 在第三章中，我们介绍了基于工具调用路径构建的API知识图谱，包括有对调用路径数据的清洗、图谱的静动态构建算法、API节点召回模型训练等部分。
尽管工具图谱能够表示大量的工具调用路径，但是仅依赖图上搜到的路径不具有灵活性，对于不同的用户需求，图上的路径不一定能够灵活满足。
同时，工具也具有生命周期和动态性，会有新建的工具或者废弃的工具，图谱上的节点也会随之变化，因此需要一种动态的API选择方法。
大语言模型能弥补这一种灵活性、动态性的缺乏，但仅依赖大语言模型的选择而不利用图谱信息，则难以解析工具之间的复杂依赖关系。

因此，我们提出了一个在工具图谱上动态遍历的算法，通过大语言模型智能体在图上动态选择节点。本章集中介绍图谱遍历和API路径选择的部分，即如何根据用户需求在大型工具图谱上进行高效的搜索和选择。
在本章主要有以下几个重要问题需要研究：
1.如何合理利用工具图谱上的依赖信息进行工具选择？
2.如何对路径选择流程进行优化，以提升整体的准确率和效率？
3.如何处理工具调用中遇到的工具调用异常、工具响应过长等问题？

\indent 针对上述问题，我们提出了一种基于工具图谱的动态寻路算法。该算法首先将用户的需求进行分析和拆解，以得到
更小的任务编排与执行单位。其次，本章提出了一种基于深度优先搜索的搜索算法，
能够实时地在图上进行搜索并选择合适的API调用路径。最后，由于API工具调用的返回结果内容较多，本着减少大语言模型推理时间与提升系统效率的考虑，
我们提出了一种响应内容压缩方法，通过让模型选择重要的字段来生成更短的响应结果，能够有效保留重要信息并提升交互效率。

\section{问题定义}

工具增强的大语言模型（LLM）通过结构化的自然语言文本与环境进行交互。我们提出了一种新的解决方案，结合了一个由1.6万个API构成的API图作为工具池，以优化API调用和任务执行的过程。具体的交互流程如下：

在接收到任务时，首先通过任务分解模块将任务分解为多个子任务，每个子任务将单独进行处理。任务分解的过程可以表示为：

\[
T_{sub} = \text{Task\_decomposer}(T) \tag{1}
\]

其中，\( T_{sub} \) 是分解后的子任务集合，\( T \) 是输入的原始任务。

对于每个子任务的API选择，采用API检索模型在API池中检索出前 \( k \) 个与子任务最相关的API作为初始节点。具体步骤可以形式化为：

\[
A_{init} = \text{API\_retriever}(T_{sub}, q) \tag{2}
\]

其中，\( A_{init} \) 表示初始节点的集合，\( T_{sub} \) 是API工具池，\( q \) 是当前子任务的查询。

随后，LLM将基于初始节点进行迭代选择新的API节点并进行调用。这个选择过程不仅考虑当前任务的需求，还会记录选择过程中的调用结果，以便后续的回溯和调整：

\[
a_s = P_\theta(C_s \cup o_s, t_s, A_{current}) \tag{3}
\]

在上式中，\( A_{current} \) 代表当前任务相关的API节点集合，而 \( a_s \) 是选择的API动作。

在所有子任务的API调用成功后，我们将每个子任务的输出和结果汇总到汇总器，最终得出一个综合的结论。汇总的过程可以表示为：

\[
R_{final} = \text{Aggregator}(R_{sub}) \tag{4}
\]

其中，\( R_{final} \) 是最终的结论，\( R_{sub} \) 是各子任务的结果集合。

为提升长期记忆能力，我们还存储过去的调用历史，并通过向量检索方法查找类似的查询和路径，从而辅助当前的决策过程。长期记忆的更新可以通过以下公式表示：

\[
M_{long} = \text{Vector\_search}(H, q) \tag{5}
\]

其中，\( M_{long} \) 表示长期记忆，\( H \) 是过去的调用历史，\( q \) 是当前查询。

此外，API调用的过程经过简单配置参数后，可以直接进行调用，并对过长的响应进行压缩，以提高响应效率。这个过程可以表示为：

\[
r_s = \text{API\_call}(a_s, \text{params}) \tag{6}
\]

在这里，\( r_s \) 表示API的响应，\( a_s \) 是所选择的API动作，\(\text{params}\) 是配置的参数。

通过这样的设计，我们的基于大语言模型Agent和图谱的API编排和调用工具能够有效地处理复杂任务，优化API的调用流程和准确性。

\section{整体框架}

图~\ref{fig:ch4-framework}展示了本章提出的基于深度优先遍历算法的动态工具编排算法的整体技术框架。


\begin{figure}[!htp]
  \vspace{1em}
  \centering
  \setlength{\abovecaptionskip}{10pt} % 控制图片和caption之间的距离
  \includegraphics[height=7cm]{../assets/ch4-整体框架图-3.pdf}
  \bicaption{整体框架}{Overview of the Dynamic Tool Selection Framework}
  \label{fig:ch4-framework}
\end{figure}

该方法整体由以下几个部分组成：

\begin{enumerate}
  \item \textbf{任务解耦模块}：任务分解模块负责将复杂、模糊的用户需求分解为多个子任务，能够充分提高系统处理复杂任务的能力。
  \item \textbf{任务编排模块}：该部分包括基于深度优先遍历的动态工具搜索算法、自我反思机制和长短期记忆模块。
  本质上来说，该算法就是在图上进行深度优先遍历，我们将图上的节点的权值、节点的邻居点的边权等信息，以及节点工具的描述信息等全部提供给大语言模型，让模型在图上动态选择节点。
  在工具路径选择的过程中，若遇到了路径信息，我们将会进调用“自我反思机制”，即对路径上遇到的错误进行分析并基于此错误分析内容重新
  进行路径选择。模型可以选择回溯到某个中间过程，或者是从头开始寻路。
  在大语言模型智能体不断寻路的过程中，我们会维护一个“短期记忆”，即对整体寻路流程的记录。
  为了利用历史经验知识，我们添加了“长期记忆模块”，即我们会搜索类似任务的历史工具调用路径放在提示词辅助大语言模型的规划。
  自我反思机制能够通过格式化的反思提升系统的准确性，。
  \item \textbf{任务执行模块}：在得到了整体的路径后，任务执行模块负责调用工具API，并将结果进行汇总，最终输出结果。
  其中涉及到了API参数配置、API响应压缩模块。API参数配置模块直接将API工具的说明信息和所需参数信息提供给模型，让模型提供合适参数并进行校验。
  API响应压缩模块则负责对API的响应结果进行压缩，以减少响应时间，提升交互效率。
  \item \textbf{任务总结模块}：任务总结模块即对子任务的工具调用链执行结果进行汇总，输出最终结果。
\end{enumerate}

在流程上，对于每个用户需求，只会执行一次子任务分解。但是对于每个子任务，都会执行一次动态工具搜索算法，并且会根据搜索到的工具路径执行若干次API工具，因此会多次调用API执行模块。
最后，我们通过任务总结模块对所有子任务的结果进行汇总，得到最终输出。

\section{具体实现}

\subsection{任务分解模块}

由于用户的需求可能会较为模糊、笼统，或者在同一个需求语句中存在多个潜在的子任务。通过对用户提供的复杂需求进行分解、改写，并生成适合执行的具体指令，这一过程使得任务变得更加明确和易于解决。

任务分解模块的输入包括具体用户需求、子任务格式的指令、输出格式案例以及当前工具的具体分类，输出则是JSON格式的一组子任务。每个子任务都是一个独立的任务单元，包括“子任务名称”、“子任务描述”、“子任务类别”等重要信息。每个子任务都可以看作一个完整的任务进行执行。

首先，任务分解模块的核心功能是将用户提出的复杂或模糊需求拆解为可执行的子任务。许多用户在表达需求时，往往由于信息不明确或需求过于笼统，导致系统难以直接响应。例如，用户可能提出多个相关或不相关的要求，或者在一个指令中混合了不同领域的子任务。在这种情况下，大语言模型通过对用户输入的语义分析，将任务按照逻辑和类别进行分解。每一个子任务将独立处理，从而避免因任务过于复杂而导致系统误解或错误执行。

其次，改写器的作用是将分解后的子任务进一步精炼成更具体、明确的语句。这一过程借助于大语言模型强大的自然语言处理能力，通过对原始需求的语义理解和推理，将模糊的任务表达转化为更加清晰、具体的指令。例如，用户可能提出“帮我分析特斯拉的股票数据并生成趋势报告”的需求。改写器会将其分解为多个步骤：首先获取股票数据，然后分析数据中的关键趋势，最后生成一份详细报告。通过这一改写过程，系统可以更好地执行每一步任务，通过调用查询数据的工具API获得相关信息，并在获取股票数据后，通过大语言模型自身的分析功能生成分析报告。此外，任务分解模块能够显著提升大语言模型在多工具和多类别场景中的应用能力。通过将复杂任务拆解为多个相互独立的子任务，系统能够并行执行这些子任务，并分别调用不同的工具或API来完成每一步。子任务中包含“任务类别”，通过在任务分解模块中划分好任务的类别，可以有效减少后续动态工具搜索时的搜索空间，提升搜索的准确性和速度。这种设计允许各个子任务同时进行，显著提高任务执行效率。

总的来说，基于大语言模型的任务分解模块通过分解复杂任务、改写用户需求，并动态调整任务规划，使得该系统在执行复杂任务时更加灵活、精准且高效。

% 设置颜色
% \definecolor{bgcolor}{RGB}{240,240,240} % 背景颜色
% \definecolor{titlecolor}{RGB}{20,20,20} % 标题背景颜色

% \begin{center}
% % 使用 tcolorbox 创建背景
% \begin{tcolorbox}[colback=bgcolor, colframe=black, width=0.8\textwidth, boxrule=0.5mm, 
% coltitle=white, colbacktitle=titlecolor, title=An Example for Response Generation with GPT-4]

% % 使文字居中

% \textbf{Instruction Prompt:} You are currently in the response generation stage. You are given the output of selected tools that can be potentially used to solve the sub-task. Your goal is to generate a response to the user question based on the results from tools and your internal knowledge.

% \textbf{User Question:} I would like to know the value of 5 ounces of gold plus 1 million AMZN stocks in CNY.

% \textbf{Return from Tool Calling:} The stock price of AMZN is 130 USD, XAU USD is 1919.7605807522993, and the exchange rate between USD and YNC is 7.24.

% \textbf{Output:} \textcolor{red}{Total value in CNY: Total value = Value of gold in CNY + Value of stocks in CNY = 69,495.87 + 941,200,000 = 941,269,495.87 CNY. Therefore, the combined value of 5 ounces of gold and 1 million Amazon stocks in Chinese Yuan is approximately 941,269,495.87 CNY.}

% \end{tcolorbox}

% \end{center}


\subsection{任务编排模块}

为了更好地利用我们构建的工具图谱，并挖掘隐藏节点关系中的知识，
我们开发了一个基于深度优先遍历的寻路算法。
与“思维链”（Chain-of-Thought）或ReACT方法相比，
该算法的优点在于该方法在图谱上进行可回溯的动态选路，能够防止错误传播的问题，
并能够对整个工具空间进行更全面的探索。
在动态选择API工具路径的同时，我们会维护一个“短期记忆”，即
当前的路径和每一步路径选择（前进/回溯）的理由。同时，为了利用历史经验知识，
我们将历史上类似的任务的正确工具路径作为提示词提供给模型，以辅助模型进行路径选择。
最后，在该算法能够通过“自我反思机制”来对路径进行判断和错误诊断，
这一机制进一步提升了路径选择的准确率。

\subsubsection{基于深度优先遍历的动态搜索算法}

图~\ref{fig:ch4-dfs}为本文提出的基于深度优先的寻路算法。

\begin{figure}[!htp]
  \vspace{1em}
  \centering
  \setlength{\abovecaptionskip}{10pt} % 控制图片和caption之间的距离
  \includegraphics[height=8cm]{../assets/ch4-dfs算法.pdf}
  \bicaption{基于深度优先的寻路算法}{Dynamic DFS Search on Tool Graph}
  \label{fig:ch4-dfs}
\end{figure}

首先，由于图谱上的节点数量众多，选择初始节点是算法中非常关键的一步。
在选择初始节点时，我们训练了一个基于语义相似度的API召回器，能够根据用户的需求语句得到一组
在语义上最相似的工具作为初始工具的候选集。然后我们从中选择一个节点并开始在图上进行深度优先搜索遍历，
让模型在图上不断遍历其他节点。

具体算法逻辑如下：对于每个选择的节点，
我们将获取当前节点的邻居节点及其权值，并提供给大模型智能体，
要求大语言模型选择下一个工具节点或回溯。
对于邻居节点候选集的筛选，
我们会首先获取到图中所有邻居节点，然后
我们根据当前节点与该邻居节点的
工具转移边权进行排序，
选择边权最大的K个节点
作为候选邻居节点。
同时，我们会获取每个邻居节点的点权，
同样作为额外信息提供给大语言模型，
作为工具可用性的参考。
如果邻居节点不足K个，
我们将再次调用API召回器，以补全K个候选节点的选项。

该算法会根据当前状态继续迭代选择下一个工具节点或发起回溯，
直到模型决定结束选择或放弃该任务。

不管模型选择下一节点还是选择回溯，我们都将把模型的理由和具体操作加入短期记忆中，
将回溯步骤添加到短期记忆的原因是让模型记住在本次推理中之前采取的错误操作，
避免后续重复选择不可行的工具。
如果模型回溯到了初始节点，并且需要继续回溯，
我们可以理解为基于当前的工具选择，
该任务不可行，即放弃任务执行。

\subsubsection{初始节点召回器}

在上述算法中，除初始节点外的其他点都是根据当前节点的邻居节点及其权值来选择的。
因此，初始节点的选择是选择正确路径的关键。

由于工具图中包含大量的工具，无法让大语言模型浏览所有工具信息并选择最合适的。
因此在这里我们设计了基于语义相似度的API召回器，能够根据用户的需求语句召回一组在语义上最相似的工具作为初始工具的候选集。

通常API召回是通过向量模型和相似度算法来进行的，具体而言，我们将用户需求（查询）和每个API的信息都转化为向量表示，并通过计算查询向量与API向量之间的相似度来检索相关API。这个过程首先使用预训练的语言模型将API的文本描述转化为向量，这些向量能够捕捉文本的语义信息。接着，通过计算查询向量与API向量之间的相似度，常用的相似度度量包括余弦相似度和欧氏距离，系统会召回与查询最相关的若干个API，通常会设置一个阈值，以确保返回的结果在一定的相似度范围内。随后，对召回的API进行排序，通常按照相似度从高到低排列，以便优先展示最相关的结果。在某些情况下，可以结合额外的规则或业务逻辑进一步优化结果，例如排除某些不相关的API或添加领域特定的过滤条件。

然而，我们在实际应用中发现，针对一些模糊的用户需求，开源的向量模型在召回工具列表时往往会收到噪声的影响。

如图~\ref{fig:why-tune}所示，在工具召回时，有很多噪声工具被召回，而真正对任务有用的工具排名靠后。

\begin{figure}[!htp]
  \vspace{1em}
  \centering
  \setlength{\abovecaptionskip}{10pt} % 控制图片和caption之间的距离
  \includegraphics[height=8cm]{../assets/ch3-为何需要微调.pdf}
  \bicaption{使用开源向量模型得到的API排序结果}{API Ranking Using Open-source Embedding Models}
  \label{fig:why-tune}
\end{figure}

因此，为了解决上述问题，本文提出了基于通用向量模型进行微调，通过构造高质量的工具训练数据来将领域知识注入模型，从而提升模型在工具选择上的准确性。

在训练向量模型时，训练数据包含三个部分：正样本，负样本，查询语句。
查询语句即为数据集中的“query”字段，对应用户输入的查询信息。
正样本也可以直接使用数据集提供的参考API列表。

对于负样本的部分，如图~\ref{fig:negative-sample-generation}，我们采取了两种不同的负样本构造方式：
一种是简单负样本（Simple Negative）构造，另一种是困难负样本构造（Hard Negative）。

\begin{figure}[!htp]
  \vspace{1em}
  \centering
  \setlength{\abovecaptionskip}{10pt} % 控制图片和caption之间的距离
  \includegraphics[height=7cm]{../assets/ch3-负样本构造.pdf}
  \bicaption{负样本构造的两种方式}{Negative Sample Generation}
  \label{fig:negative-sample-generation}
\end{figure}

\indent \textbf{简单负样本构造}。对于简单负样本构造，我们直接选择不同类别的K个工具作为负样本。
在简单负样本构造中，不同类别的API之间的功能上一般有区别，因此简单负样本构造能够保证负样本与正样本之间在工具上的差异。

\indent \textbf{困难负样本构造}。在工具选择、调用场景，开源的通用向量模型难以区分工具之间细微的语义区别。
困难负样本构造的目的是帮助模型更好地区分工具之间细微的语义区别，帮助更好地应对噪声。
我们选择采用GPT-3.5完成困难负样本的构造。由于原工具数据量众多，
从中筛选语义表述类似、但是功能上有区别的工具样本费时费力。
因此我们采取了直接用大语言模型生成工具描述作为负样本的策略。

具体策略如下：
首先，我们采样一批<query,推荐工具集>的数据，
然后我们遍历其中的推荐工具集的工具，
通过提示词将用户需求和工具描述提供给大语言模型，
要求模型生成类似但是功能上无法满足用户需求的工具描述。
通过这样遍历工具描述生成负样本，可以生成一组高质量的困难负样本供模型学习。

\subsubsection{自我反思机制}

自我反思机制的主要目的是对生成的工具调用路径进行反思，以提升整体的准确率。

自我反思机制的触发时间点有三个：1.动态寻路算法找到路径并主动结束路径 2.动态寻路算法超过了最大迭代次数并终止或放弃寻路

具体而言，自我反思模块的输入是
我们当前的工具调用路径和用户需求，
根据API工具召回器召回的初始节点，
以及我们撰写的反思格式说明。
输出包括以下几部分：1.成功/部分失败/完全失败的等级 2.若部分失败，从哪一个工具节点开始为首个错误节点 3.若全部失败，有哪些可以删除的噪声工具初始节点

评价为“成功”的路径，我们直接进入API调用模块进行调用。
对于评价为“失败”的路径，我们
会根据失败的等级选择进行不同的重新寻找工具调用路径：
第一种是从中间步骤开始重新寻找路径，
另一种是从头开始重新寻找路径。

\begin{enumerate}
  \item \textbf{从中间步骤继续}: 在任务未完成的情况下，我们将在短期记忆中记录寻路过程中的每一步的选择节点和理由。
  当路径被标记为“放弃”或被评判器认定为“失败”时，我们会重新激活该路径上的智能体，
  并将识别到的失败原因重新纳入历史上下文。
  评判器在判定“失败”时，通常会标记出它认为的第一个出现错误的节点。
  在重新激活智能体并进行寻路时，我们将从该节点继续，
  而不是从头开始。这种从中间步骤继续的策略不仅能够加快寻路速度，
  减少大语言模型的调用次数，还能充分利用先前成功调用的经验，
  从而提升决策的准确性。
  \item \textbf{重新寻路}: 在自我反思模块认为路径“完全失败”时，
  我们需要从头开始重新生成整条路径。评判器会识别路径初始节点中与用户查询无关的工具名称作为反思的一部分。
  为了提高系统的整体效率，我们会首先从初始工具节点中移除这些无关的工具，
  避免大模型受到这些噪声的影响，从而选择无关的工具进行调用，
  导致后续调用出错。通过这一清理过程，我们能够有效减少噪声工具的影响，
  确保后续搜索的准确性。\par
  接下来，我们将会在经过噪声清理的工具组中重新开始选择下一节点并组成路径。
  这种从头开始的自我反思允许算法在一个更加简洁与优化的初始条件下进行搜索，
  从而提升工具调用路径的质量与响应速度。
\end{enumerate}
 
该自我反思机制可以反复应用，直至满足终止条件为止。这种持续的反思过程确保了对问题的逐步优化，有助于形成更加有效的调用路径。

综上所述，这两种反思策略——从中间步骤继续优化和从头开始的寻路——的结合使用，能够在处理用户需求未满足的情况下，提供更高的灵活性与效率。
通过不断的反思与优化，系统将逐步提升其在动态环境中的适应能力，确保用户体验的持续改进。

\subsubsection{工具调用路径长短期记忆框架}

本小节提出了关于增强模型规划和推理准确性的长短期记忆框架。该框架主要分为短期记忆和长期记忆两个部分。
短期记忆部分指的是当模型在图上动态推理时存储的每个步骤的记录，
主要聚焦于以什么数据格式来存储推理步骤，
以及记录哪些有用的记忆信息：在图上前进、回溯还有大模型的思考过程等。
长期记忆部分主要是将历史的工具调用路径存储在数据库中，通过相似度搜索算法加入到工具选择器
的提示词中，以增强其推理和规划能力。

\indent \textbf{短期记忆}

短期记忆指的是模型在图上进行不断推理时保存的一些状态信息，
这些信息包括：用户的任务、当前遍历到的节点、历史遍历的节点、调用路径信息等。
在遍历的过程中，我们会动态地更新和维护短期记忆存储的内容，来辅助模型进行推理和规划。
在短期记忆中，我们一般将全部的信息存储在内存中，
然后每次直接构建提示词添加到大语言模型的上下文中，
让模型能够感知到当前的状态和环境。

\indent \textbf{长期记忆}

长期记忆与短期记忆相对，是固定存储在数据库中的信息，且会随着调用次数的增加不断积累。
它记录最终形成的工具调用链和结果，每次推理时，系统都会从长期记忆库中搜索，将搜到的相似需求的工具调用路径提供给
工具选择器，利用历史经验辅助大语言模型的推理。

长期记忆模块基于检索增强生成（Retrieval-Augmented Generation, RAG）逻辑，通过将历史上成功的<用户需求，工具调用路径>转为向量存储。新需求通过向量模型转为嵌入向量，并与数据库中的向量进行相似度计算。系统会根据相似度排序，检索出与当前需求最相似的 K 个历史需求及其工具调用路径。最终，这些<用户需求，工具调用路径>的二元组会被加入大语言模型的上下文中，辅助推理与规划。

\subsection{工具调用模块}
\label{sec:real_tool_simulation}

\subsubsection{整体逻辑}

工具调用模块的主要功能是执行规划好的API调用路径，并将得到的结果返回给系统，
从而为后续的推理和规划提供支持，最终生成符合用户需求的答案。

该模块的整体逻辑可以分为两个主要部分：工具调用和工具响应解析。
具体而言，我们首先根据工具的描述信息和用户需求生成API调用的参数，然后通过代码生成请求体并通过API调用接口将请求体发送给目标API工具，
以获取其响应。
获得响应后，理论上我们可以直接将所有工具的调用结果直接提供给总结器，要求模型根据所有的API响应输出最终结果。

但由于每个响应的长度参差不齐，对于一些响应长度较长的API工具，可能单个API的响应数据就超出了大语言模型的上下文限制。
因此，我们添加了一个基于大语言模型的响应压缩模块，通过对响应的压缩，将API响应的字符数控制在1024个字符以内，以缓解大语言模型的上下文限制。

\subsubsection{工具参数生成}

工具调用模块的主要工作就是生成API工具的请求体。在请求体的生成过程中，我们首先将与工具调用相关的内容提供给大语言模型智能体，要求其生成指定的JSON格式调用输入，包括但不限于工具调用的URL、所需输入参数及工具的登录验证信息等。接着，我们对生成的JSON数据中的参数信息进行验证，并确定请求体中各个参数的结构和格式。

首先，我们会确认生成的参数URL与工具库中的URL是否匹配。其次，参数的正确性对API工具调用的成功至关重要，因此在执行调用工具代码之前，我们会对参数进行严格的校验。在这一步中，我们验证具体的参数数量、类型和名称，并对这些部分进行精确匹配。如果缺少必要的参数或参数类型不匹配，我们将返回固定的错误信息，并要求参数解析器重新生成参数。这一过程会一直重复，直到获取正确的参数或超过最大尝试次数后放弃该API调用。

在成功验证URL和参数后，我们将调用固定的函数来执行API请求，并获取JSON格式的响应，随后将其提供给响应解析模块。

\subsubsection{工具响应解析模块}

生成请求体后，我们将其通过API调用接口发送给目标API工具，以获取相应的响应数据。响应数据通常是以JSON格式返回的，这其中可能包含大量的信息，而这些信息并不总是直接相关。在我们的实际实验中，我们通过分析发现许多API返回内容包含大量冗余信息，导致其长度过长，无法将调用结果输入到大语言模型中，直接使用大语言模型从中提取重要信息较为困难。因此，我们对API的响应结果进行了压缩。该模块的目标是在尽可能多地保留关键信息的同时减少API响应的长度，便于放入大语言模型的上下文中。

由于每个API的响应格式不是固定的，无法确定每个字段应该舍弃还是保留，因此我们采用大语言模型来分析示例响应，仅保留与用户需求相关的字段，以减小响应长度。

图~\ref{}具体步骤包括：

\begin{figure}[!htp]
  \vspace{1em}
  \centering
  \setlength{\abovecaptionskip}{10pt} % 控制图片和caption之间的距离
  \includegraphics[height=4cm]{../assets/ch4-响应压缩.pdf}
  \bicaption{响应压缩模块}{Compression of API responses}
  \label{fig:ch4-framework}
\end{figure}

\begin{enumerate}
    \item \textbf{工具文档信息}：所有API工具均来自ToolBench等开源数据集，这些数据集同时包含每个API的详细描述信息和API响应示例。因此，我们可以将工具名称、工具描述、API名称、API描述、参数及API响应示例的内容以文本形式提供给大型语言模型。这部分构成了压缩模块的基本提示词。
    
    \item \textbf{详细规则指令}：我们要求大型语言模型仔细阅读API的功能描述，并保留与功能描述最相关的信息，诸如API版本、调用时间或无效信息等可以被舍弃。
    
    \item \textbf{上下文学习示例}：我们使用了三个上下文学习示例，每个示例由一个原始API响应和对应的专家撰写的压缩响应组成。我们要求压缩器以自然语言文本格式输出所有需要保留的字段，然后通过正则表达式匹配得到一个保留字段的列表，并用固定的代码逻辑筛选出相应字段的返回内容。
\end{enumerate}

在推理过程中，当API响应长度超过1024个字符时，我们会通过移除不重要的信息来压缩响应。如果压缩后的响应仍然超过1024个字符，则只保留压缩后的前1024个字符。这种方法能够有效地减少API响应长度，对API响应进行去噪。同时，也能够缓解大型语言模型有限的上下文窗口的问题，确保系统的正常调用。

通过分析我们在ToolBench中的API响应示例，其中一个API的平均响应字符串长度为xxx个字符。经过响应压缩后，最长的响应也不超过1024个字符。通过这种方式，我们有效降低了xx\%的超出上下文的情况，平均每个API响应结果节约了xx个字符。

（todo，实验部分待补充）


\section{实验与评估}

\subsection{API召回器实验评估}

本文分别使用简单负样本构造和困难负样本构造方法构造了xxx条数据和xxx条数据，分别对模型进行了微调。
同时，在测试集中，我们除了使用从ToolBench中筛选得到的数据。

\subsubsection{模型训练及超参数设置}

在进行向量模型微调之前，选择合适的基座模型是一个关键步骤，这将直接影响到微调后模型的性能以及效率。
在选择基座模型时，通常需要考虑到模型的规模、大小，模型支持的语言，模型的训练任务等。我们对bge-small,bge-m3,m3e,bce等
常用的向量模型进行了实验，在对比性能后选择了bge-m3模型作为基础模型进行训练。


本工作基于bge-m3进行了微调。实现过程中将epoch数量设置为xx，学习率设置为3e-5进行学习。
模型大小为xxx，在xxx芯片上训练了xxx得到了结果。

\subsubsection{评估指标}

我们将会用召回率（Recall）和NDCG分数来衡量微调后的工具召回器的效果。

\textbf{Recall}

Recall（召回率）是衡量推荐系统或搜索引擎中，系统成功检索到的相关项占所有相关项的比例，在本系统中即为计算搜索到的有关工具在所有相关工具的占比。它的计算公式为：

\[
\text{Recall} = \frac{|\text{Relevant Tools} \cap \text{Retrieved Tools}|}{|\text{Relevant Tools}|}
\]

其中：
- \(\text{Relevant Tools}\) 表示所有相关的工具（即正确答案的集合）。
- \(\text{Retrieved Tools}\) 表示系统返回的所有工具结果集合。

Recall 的取值范围为 [0, 1]，值越大表明系统检索出的相关项越多，即召回率越高。

\textbf{NDCG (Normalized Discounted Cumulative Gain)}

NDCG 是一种常用的排名质量指标，用于衡量检索结果的排序好坏。NDCG 的思想是，相关性越高的项应排在越前面，越靠前的正确答案权重越大。

NDCG 由 DCG（Discounted Cumulative Gain）归一化得到，DCG 的计算公式为：

\[
\text{DCG}_p = \sum_{i=1}^{p} \frac{2^{rel_i} - 1}{\log_2(i + 1)}
\]

其中：
- \(rel_i\) 表示结果中第 \(i\) 个文档的相关性得分。
- \(i\) 是文档在排序中的位置。

为了将 DCG 标准化，我们需要计算理想情况下的 DCG（即相关性最高的项排在最前面），称为 IDCG（Ideal DCG）：

\[
\text{IDCG}_p = \sum_{i=1}^{|REL_p|} \frac{2^{rel_i} - 1}{\log_2(i + 1)}
\]

最后，NDCG 通过 DCG 与 IDCG 的比值计算得出：

\[
\text{NDCG}_p = \frac{\text{DCG}_p}{\text{IDCG}_p}
\]

其中 \(p\) 表示计算到结果的前 \(p\) 个文档。NDCG 的值范围为 [0, 1]，越接近 1 表示排序效果越好。

这两个指标结合起来可以综合衡量系统在API召回任务中的表现。
Recall关注的是系统能找到多少相关结果，
而NDCG更关注结果排序的质量，尤其是优先把最相关的工具放在前面。

\subsubsection{实验结果}

\begin{table}[!ht]
  \centering
  \caption{API工具召回实验结果}
  \label{tab:comparison}
  \begin{tabular}{lccc>{\bfseries}c} % 'lccc' defines 1 left and 3 center aligned columns, '>{\bfseries}c' makes last column bold
    \toprule
    \textbf{Method} & \textbf{I1} & \textbf{I2} & \textbf{I3} & \textbf{Average} \\ \midrule
    BCE         & 30.1 & 40.0 & 28.6 & 32.9 \\
    BGE-Small         & 42.3 & 45.6 & 33.2 & 40.4 \\
    ToolBench's API Retriever   & 46.5 & 49.1 & 38.9 & 44.8 \\
    Ours        & \textbf{58.0} & \textbf{70.6} & \textbf{62.8} & \textbf{63.8} \\ \bottomrule
  \end{tabular}
\end{table}

\subsubsection{实验分析}

具体的分析。

\subsection{基于深度优先遍历的API编排算法实验}
\label{subsec:test_dataset}

ToolBench。ToolBench\cite{Qin2023}是一个公开的针对工具调用的数据集，其中包含了来自49个类别的16464个真实世界的API工具的推理调用数据。该数据集包括三个部分，三个子数据集的难度逐级上升：G1数据集，其中目标任务所需的API都在同一个工具组；G2数据集，其中目标任务所需的API在同一个类别但是属于不同的工具组；G3数据集，其中目标任务所需的API会跨越不同类别。为了测试各个难度等级上的能力，本工作从三个类别分别抽取了350，350和300条数据构建测试集。测试集一共涉及18个category的358个工具。

考虑到RapidAPIHub上的API的质量参差不齐，比如有一些API工具为废弃的，并且存在一大部分API工具为付费工具，这都可能会给测试过程引入不必要的噪声。

因此本工作首先筛选得到了一组覆盖各种类别的已知可用的高质量API工具，然后针对这些API工具，沿用ToolBench的方法构建了三个不同难度的测试数据集，作为该方法的测试数据。下面将会详细介绍数据集的构建过程。

\subsubsection{高质量API工具集筛选}

首先，我们需要定义什么是高质量的API工具。在我们的使用场景中，工具的可用性是首要考虑因素，因此必须确保筛选后的API工具都是可用的。此外，在工具选择模块中，我们使用API工具的名称和描述信息作为输入，供模型参考和选择。因此，API名称的易读性和描述的丰富性也是筛选时的重要参考标准。

同时，在保证API质量的基础上，我们也希望尽可能覆盖更多的工具类别和工具集。因此，我们从每个不同类别的工具中进行采样，选择了共计xx个类别、xx个工具集的xx个工具，作为筛选前的工具池。

基于上述规则，我们构建了一个工具筛选流程，并针对不同维度设置了相应的筛选机制。对于API工具的可用性，我们通过调用示例代码来测试每个工具的有效性。根据API的返回状态码、请求响应时间和响应内容，我们选择最合适的API。在我们评估的xx个API工具中，有xx个API的响应状态码为错误码，且有xx个API未能在规定的时间内返回。经过可用性筛选后，我们从xx个工具中筛选得到了xx个可用工具。

对于API描述的丰富性和完整性，我们采用大语言模型标注的方法进行筛选。我们构建了包含详细指令和筛选标准的提示词，并提供了few-shot样例，供模型对每个API进行评估。为加快筛选速度并节约模型调用的字数，每次将K个API进行批量判断。模型将输出一个JSON格式的列表，包含对每个API的保留或丢弃的判断。

经过第二轮筛选后，最终剩下的高质量API工具共有xx个。

画表格，介绍每个不同部分有哪些API种类。

\subsubsection{工具调用数据集构造}

为了覆盖不同难度和复杂度的用户需求，我们参考ToolBench中的分类方法，选择了三个不同难度的任务类别：单工具任务、多工具集任务和多类别任务。

\begin{enumerate}
  \item \textbf{单工具任务} \\
    该任务仅涉及一个工具，用户需求仅包含一个工具的调用。这是工具调用中最简单的情况，通常用于测试大语言模型在处理基本指令时的能力。在数据生成过程中，我们直接随机采样一些API，并引导大语言模型生成与这些API相关的用户需求。这种方法不仅能够快速生成数据，还能确保指令的有效性和准确性，适用于初学者或对工具调用不太熟悉的用户。

  \item \textbf{多工具集任务} \\
    该任务涉及多个工具集，用户需求需要调用多个工具集中的多个工具。这种任务要求大语言模型具备更高的灵活性和综合能力，能够理解不同工具之间的功能关系。在实现时，我们随机采样来自不同工具集的工具，并将其提供给大语言模型，让其生成用户需求。为了确保生成的需求合理，我们特别考虑了工具组合的有效性。对于那些功能上明显重复或无法自然组合在一起的工具API，大语言模型将直接放弃生成不合逻辑的用户需求，并重新采样一组更合理的API。这种方法有效地增强了模型在实际应用中的适应性，帮助生成更符合真实场景的用户需求。

  \item \textbf{多类别任务} \\
    该任务涉及多个类别，用户需求需要调用多个类别的多个工具。这是对大语言模型综合能力的进一步挑战，因为不同类别的工具可能具有不同的功能和用途。在实现过程中，我们同样随机采样来自不同类别的工具，并将其提供给大语言模型，促使其生成多样化的用户需求。这种多类别的设计不仅提高了数据的复杂性，还增强了模型在处理多元化需求时的能力，使其更接近于真实世界的使用场景。

\end{enumerate}

通过上述的方法，我们构建了一个共1000条数据的测试集，其中单工具、多工具集和多类别任务分别占350、350和300条。这种结构化的测试集设计使得我们能够全面评估大语言模型在处理不同复杂度的用户需求时的表现，进而优化模型的生成能力和适应性。经过人工的评估，这种方法具有较高的多样性，能够覆盖到大部分的实际场景。

\subsection{评估指标}
由于工具的多样性，对于同一个用户需求可以有多种工具调用路径。因此，我们无法事先对每个测试的输入标注单一的解决路径标准答案。由于人工评价较为费时费力，本文基于\cite{Tang2023}中的评估器构建了类似的评估体系，包含以下两个指标。我们的评估器使用的是目前能力最强的模型之一GPT-4，温度系数设置为0。（todo）

\begin{itemize}
    \item \textbf{通过率（Pass Rate）} \\
    通过率是计算在有限的工具执行步骤内完成了需求的比例。该指标衡量了系统工具调用最基本的执行能力。通过率的公式如下：

    \begin{equation}
        PR = \frac{ \#(\text{Solved}) }{ \#(\text{Solved}) + \#(\text{Unsolved}) }.
    \end{equation}

    \item \textbf{胜率（Win Rate）} \\
    胜率是评价两条针对同一需求生成的路径的偏好。在模型判断胜率的评估器的提示词中，我们预先定义了一组标准，其中包括：探索性、真实性、工具个数。胜率的公式如下：

    \begin{equation}
        WR = \frac{ \#(\text{Won}) }{ \#(\text{Won}) + \#(\text{Lost}) + \#(\text{Tie}) }.
    \end{equation}

\end{itemize}

同时，为了验证评估器与人类标注者的标注一致性，我们人工标注了100条通过率和100条胜率的数据。经过这200条数据，我们发现标注器在通过率上与人工标注的一致性达到了xxx（todo），在胜率上该数字达到了xxx（todo），这表明该基于大语言模型的标注器与人工标注的标准基本吻合。

\subsection{基准线}

为了对比本研究提出的基于Agent与知识图谱的任务编排与执行方法的效果，本文选用下列方法作为实验的基准方法。

\begin{itemize}
  \item  \textbf{基本提示方法}。基本提示方法即在大语言模型中直接输入所有候选API的信息，然后要求大语言模型输出需要调用的API的名称和参数等。
  \item  \textbf{思维链方法}\cite{Wang2023}。思维链方式在提示词中加入了"Let's think step by step"的提示信息，引导大语言模型能够进行按步骤的推理。
  \item  \textbf{ReACT方法}\cite{Yao2023}。ReACT方法通过让大语言模型不断生成Thought和Action，然后将外部的环境反馈也纳入大语言模型的上下文，让模型能够更好地进行规划。
\end{itemize}
\indent

关于大语言模型的选择，我们选择了Qwen2.5-7b和GPT-4作为基础模型，这两个模型都具有中英文双语能力，且能够对比开源模型和能力更强的闭源模型在工具能力上的区别。

\subsection{实验结果}

实验设置xxx。

结果画个表。

有哪些提升画个表。

\label{subsec:exp_results}

\subsection{错误分析}
\label{subsec:error_analysis}

对于失败的案例，分析到底是为什么会失败

\section{本章小结}
\label{sec:summary_chap4}