\chapter{基于工具图谱与深度优先遍历的工具召工具回编排与调用方法}

\section{引言}
\label{sec:intro}

\indent 在第三章中，我们介绍了基于工具调用路径构建的工具召工具回知识图谱，包括有对调用路径数据的清洗、工具图谱的构建方法、工具召工具回节点召回模型训练等部分。
尽管工具图谱能够表示大量的工具调用路径，但是仅依赖图上搜到的路径不具有灵活性，对于不同的用户需求，图上的路径不一定能够灵活满足。
同时，工具也具有生命周期和动态性，会有新建的工具或者废弃的工具，图谱上的节点也会随之变化，因此需要一种动态的工具召工具回选择方法。
大语言模型能弥补这一种灵活性、动态性的缺乏，但仅依赖大语言模型的选择而不利用图谱信息，则难以解析工具之间的复杂依赖关系。

因此，我们提出了一个在工具图谱上动态遍历的算法，通过大语言模型智能体在图上动态选择节点。本章集中介绍图谱遍历和工具召工具回路径选择的部分，即如何根据用户需求在大型工具图谱上进行高效的搜索和选择。
在本章主要有以下几个重要问题需要研究：
1.如何合理利用工具图谱上的依赖信息进行工具选择？
2.如何对路径选择流程进行优化，以提升整体的准确率和效率？
3.如何处理工具调用中遇到的工具调用异常、工具响应过长等问题？

\indent 针对上述问题，我们提出了一种基于工具图谱的动态寻路算法。该算法首先将用户的需求进行分析和拆解，以得到
更小的任务编排与执行单位。其次，本章提出了一种基于深度优先搜索的搜索算法，
能够实时地在图上进行搜索并选择合适的工具召工具回调用路径。最后，由于工具召工具回工具调用的返回结果内容较多，本着减少大语言模型推理时间与提升系统效率的考虑，
我们提出了一种响应内容压缩方法，通过让模型选择重要的字段来生成更短的响应结果，能够有效保留重要信息并提升交互效率。

\section{整体框架}

图~\ref{fig:ch4-framework}展示了本章提出的基于深度优先遍历算法的动态工具编排算法的整体技术框架。

\begin{figure}[!htp]
  \vspace{1em}
  \centering
  \setlength{\abovecaptionskip}{10pt} % 控制图片和caption之间的距离
  \includegraphics[height=7cm]{../assets/ch4-整体框架图-3.pdf}
  \bicaption{整体框架}{Overview of the Dynamic Tool Selection Framework}
  \label{fig:ch4-framework}
\end{figure}

该方法整体由以下几个部分组成：

\begin{enumerate}
  \item \textbf{任务分解模块}：任务分解模块负责将复杂、模糊的用户需求分解为多个涉及不同大类工具召工具回的子任务，能够充分提高系统处理复杂任务的能力。
  \item \textbf{任务编排模块}：该部分包括基于深度优先遍历的动态工具搜索算法、自我反思机制和记忆模块。
  本质上来说，该算法就是在图上进行深度优先遍历，我们将图上的节点的权值、节点的邻居点的边权等信息，以及节点工具的描述信息等全部提供给大语言模型，让模型在图上动态选择节点。
  在工具路径选择的过程中，若遇到了路径信息，我们将会进调用“自我反思机制”，即对路径上遇到的错误进行分析并基于此错误分析内容重新
  进行路径选择。模型可以选择回溯到某个中间过程，或者是从头开始寻路。
  在大语言模型智能体不断寻路的过程中，我们会维护一个“短期记忆”，即对整体寻路流程的记录。
  为了利用历史经验知识，我们添加了“长期记忆模块”，即我们会搜索类似任务的历史工具调用路径放在提示词辅助大语言模型的规划。
  自我反思机制能够通过格式化的反思提升系统的准确性。
  \item \textbf{任务执行模块}：在得到了整体的路径后，任务执行模块负责调用工具工具召工具回，并将结果进行汇总，最终输出结果。
  其中涉及到了工具召工具回参数配置、工具召工具回响应压缩模块。工具召工具回参数配置模块直接将工具召工具回工具的说明信息和所需参数信息提供给模型，让模型提供合适参数并进行校验。
  工具召工具回响应压缩模块则负责对工具召工具回的响应结果进行压缩，以减少响应时间，提升交互效率。
  \item \textbf{任务总结模块}：任务总结模块即对子任务的工具调用链执行结果进行汇总，输出最终结果。
\end{enumerate}

在流程上，对于每个用户需求，只会执行一次子任务分解。但是对于每个子任务，都会执行一次动态工具搜索算法，并且会根据搜索到的工具路径执行若干次工具召工具回工具，因此会多次调用工具召工具回执行模块。
最后，我们通过任务总结模块对所有子任务的结果进行汇总，得到最终输出。

\section{具体实现}

\subsection{任务分解模块}

由于用户的需求可能会较为模糊、笼统，或者在同一个需求语句中存在多个潜在的子任务。通过对用户提供的复杂需求进行分解、改写，并生成适合执行的具体指令，这一过程使得任务变得更加明确和易于解决。

任务分解模块的输入包括具体用户需求、子任务格式的指令、输出格式案例以及当前工具的具体分类，输出则是JSON格式的一组子任务。

每个子任务都是一个独立的执行单元，包括“子任务编号“、“子任务描述”、“子任务类别”等重要信息。
子任务之间可能会存在时间或者参数上的依赖，该依赖会在任务分解的时候通过特殊的占位符来表示，用于串联整体的任务编排流程。

首先，任务分解模块的核心功能是将用户提出的复杂或模糊需求拆解为可执行的子任务。
许多用户在表达需求时，往往由于信息不明确或需求过于笼统，
导致系统难以直接响应。
例如，用户可能提出多个相关或不相关的要求，或者在一个指令中混合了不同领域的子任务。
在这种情况下，大语言模型通过对用户输入的语义分析，将任务按照逻辑和类别进行分解。
逻辑上分解有利于明确每个任务的目标，没有依赖关系的任务可以并行执行，能够有效提高任务的效率和正确率。
按照类别来分解能够缩小在工具池中的搜索范围，提高搜索效率和准确性。
其提示词如下所示：

% Set Colors
\definecolor{bgcolor}{RGB}{240,240,240} % Background color
\definecolor{titlecolor}{RGB}{20,20,20} % Title background color

\begin{center}
% Create background with tcolorbox
\begin{tcolorbox}[colback=bgcolor, colframe=black, width=0.8\textwidth, boxrule=0.5mm, 
coltitle=white, colbacktitle=titlecolor, title=Task Decomposition and Response Planning with GPT-4]

% Centered content

\textbf{Instruction Prompt:} Decompose the task and plan its steps in a structured way. Identify tool dependencies and output the result as a JSON list.

\textbf{Task Description:}  
1. Break down the task into multiple subtasks in a step-by-step manner. Each subtask should be labeled as \textbf{StepX} (e.g., Step1, Step2).  
2. Specify tool usage and dependencies:  
   - If a step depends on another step's result, represent the input using its output reference, e.g., \texttt{Input: [A1]} where \texttt{A1} refers to the result from Step1.  
   - Use multiple inputs if needed, e.g., \texttt{Input: [A1, A3]}.  
3. Output the plan in a \texttt{JSON} format list.  
4. Ensure logical dependencies and a clear structure for each subtask. 

\textbf{Example Task:}  
What is the most popular travel destination in Europe? And what’s the weather like there?

\textbf{Expected Output:}  
\texttt{%
\{ \\
\ \ \ "Steps": [ \\
\ \ \ \ \ \ \ \{ "Step1": "Identify the most popular travel destination in Europe.", "context": [], "category": "travel" \}, \\
\ \ \ \ \ \ \ \{ "Step2": "Fetch the current weather for the identified destination.", "context": ["A1"], "category": "weather" \}, \\
\ \ \ \ \ \ \ \{ "Step3": "Generate a summarized response combining the destination and weather information.", "context": ["A1", "A2"], "category": "llm" \} \\
\ \ \ ]
\}
}

\end{tcolorbox}
\end{center}

通过以上的大语言模型提示词工程，我们可以让大语言模型输出JSON格式的任务执行流程，并且根据任务之间的依赖关系对任务进行排序。

如图\ref{fig:ch4-decomposition}最终形成的任务执行结构应该是一个DAG，其中每个节点代表一个子任务，每条边代表任务之间的依赖关系。

\begin{figure}[!htp]
  \vspace{1em}
  \centering
  \setlength{\abovecaptionskip}{10pt} % 控制图片和caption之间的距离
  \includegraphics[height=7cm]{../assets/ch4-任务分解模块.pdf}
  \bicaption{任务分解模块}{Task decomposition Module}
  \label{fig:ch4-decomposition}
\end{figure}

总的来说，基于大语言模型的任务分解模块通过分解复杂任务、改写用户需求，并显式表示子任务之间的依赖，使得该系统在执行复杂任务时更加灵活、精准且高效。

\subsection{任务编排模块}

为了更好地利用我们构建的工具图谱，并挖掘隐藏节点关系中的知识，
我们开发了一个基于深度优先遍历的寻路算法。
与“思维链”（Chain-of-Thought）或ReACT方法相比，
该算法的优点在于该方法在图谱上进行可回溯的动态选路，能够防止错误传播的问题，
并能够对整个工具空间进行更全面的探索。
在动态选择工具召工具回工具路径的同时，我们会维护一个“短期记忆”，即
当前的路径和每一步路径选择（前进/回溯）的理由。同时，为了利用历史经验知识，
我们将历史上类似的任务的正确工具路径作为提示词提供给模型，以辅助模型进行路径选择。
最后，在该算法能够通过“自我反思机制”来对路径进行判断和错误诊断，
这一机制进一步提升了路径选择的准确率。

\subsubsection{基于深度优先遍历的动态搜索算法}

图~\ref{fig:ch4-dfs}为本文提出的基于深度优先的寻路算法。

\begin{figure}[!htp]
  \vspace{1em}
  \centering
  \setlength{\abovecaptionskip}{10pt} % 控制图片和caption之间的距离
  \includegraphics[height=8cm]{../assets/ch4-dfs算法.pdf}
  \bicaption{基于深度优先的寻路算法}{Dynamic DFS Search on Tool Graph}
  \label{fig:ch4-dfs}
\end{figure}

首先，在上一步任务分解模块中，我们将整个任务构建为了一个有向无环图，并且用边来表示任务之间的依赖关系。
那么我们在选择每个子任务的工具时，需要考虑到前序任务的所调用的工具。

因此算法流程如下所示，对没有前序任务的节点，我们通过语义相似度算法得到一组候选的工具集合，然后通过
提供LLM这些工具的名称、描述和参数等信息，直接让LLM来选择对应的工具。

对于有前序任务的节点，我们通过寻找前序任务的工具节点的邻居节点来得到一组候选工具。不同前序任务之间的邻居节点取并集提供给LLM。
在筛选邻居时，我们会根据任务分解器的“类别”字段筛选特定工具类别的邻居，以过滤掉噪声工具节点，提高工具选择的有效性。
若取并集之后的工具节点仍过多，我们将会计算每个工具与子任务描述的相似度，并进行排序，选择前K个工具节点提供给大语言模型。
我们设计了简单实验来选择这个K值以及选取前K个的有效性，具体见第五章的实验部分。

通过该算法可以迭代得到子任务图上每个子任务所需要调用的工具节点，并且形成一个工具之间的有向无环图，为后续调用提供调用顺序和依赖关系。


% 设置颜色
\definecolor{bgcolor}{RGB}{240,240,240} % 背景颜色
\definecolor{titlecolor}{RGB}{20,20,20} % 标题背景颜色

\begin{center}
% 使用 tcolorbox 创建背景
\begin{tcolorbox}[colback=bgcolor, colframe=black, width=0.8\textwidth, boxrule=0.5mm, 
coltitle=white, colbacktitle=titlecolor, title=An Example for Response Generation with GPT-4]

% 使文字居中

\textbf{Instruction Prompt:} You are currently in the response generation stage. You are given the output of selected tools that can be potentially used to solve the sub-task. Your goal is to generate a response to the user question based on the results from tools and your internal knowledge.

\textbf{User Question:} I would like to know the value of 5 ounces of gold plus 1 million AMZN stocks in CNY.

\textbf{Return from Tool Calling:} The stock price of AMZN is 130 USD, XAU USD is 1919.7605807522993, and the exchange rate between USD and YNC is 7.24.

\textbf{Output:} \textcolor{red}{Total value in CNY: Total value = Value of gold in CNY + Value of stocks in CNY = 69,495.87 + 941,200,000 = 941,269,495.87 CNY. Therefore, the combined value of 5 ounces of gold and 1 million Amazon stocks in Chinese Yuan is approximately 941,269,495.87 CNY.}

\end{tcolorbox}

\end{center}

\subsubsection{工具召回器}

在上述算法中，初始工具集以及后续候选前K个工具集都是根据工具和子任务描述的语义相似度来选择的，将
子任务描述和工具描述转为向量的嵌入模型对选择正确工具有很大的影响。

由于工具图中包含大量的工具，无法让大语言模型浏览所有工具信息并选择最合适的。
因此在这里我们设计了基于语义相似度的工具召回器，能够根据用户的需求语句召回一组在语义上最相似的工具作为初始工具的候选集。

通常工具召回是通过向量模型和相似度算法来进行的，具体而言，我们将子任务描述和每个工具的信息都转化为向量表示，并通过计算查询向量与工具召工具回向量之间的相似度来检索相关工具召工具回。这个过程首先使用预训练的语言模型将工具召工具回的文本描述转化为向量，这些向量能够捕捉文本的语义信息。接着，通过计算查询向量与工具召工具回向量之间的相似度，常用的相似度度量包括余弦相似度和欧氏距离，系统会召回与查询最相关的若干个工具召工具回，通常会设置一个阈值，以确保返回的结果在一定的相似度范围内。随后，对召回的工具召工具回进行排序，通常按照相似度从高到低排列，以便优先展示最相关的结果。在某些情况下，可以结合额外的规则或业务逻辑进一步优化结果，例如排除某些不相关的工具召工具回或添加领域特定的过滤条件。

然而，我们在实际应用中发现，针对一些模糊的用户需求，开源的向量模型在召回工具列表时往往会收到噪声的影响。

如图~\ref{fig:why-tune}所示，在工具召回时，有很多噪声工具被召回，而真正对任务有用的工具排名靠后。

\begin{figure}[!htp]
  \vspace{1em}
  \centering
  \setlength{\abovecaptionskip}{10pt} % 控制图片和caption之间的距离
  \includegraphics[height=8cm]{../assets/ch3-为何需要微调.pdf}
  \bicaption{使用开源向量模型得到的工具召工具回排序结果}{工具召工具回 Ranking Using Open-source Embedding Models}
  \label{fig:why-tune}
\end{figure}

因此，为了解决上述问题，本文提出了基于通用向量模型进行微调，通过构造高质量的工具训练数据来将领域知识注入模型，从而提升模型在工具选择上的准确性。

在训练向量模型时，训练数据包含三个部分：正样本，负样本，查询语句。
查询语句即为数据集中的“query”字段，对应用户输入的查询信息。
正样本也可以直接使用数据集提供的参考工具召工具回列表。

对于负样本的部分，如图~\ref{fig:negative-sample-generation}，我们采取了两种不同的负样本构造方式：
一种是简单负样本（Simple Negative）构造，另一种是困难负样本构造（Hard Negative）。

\begin{figure}[!htp]
  \vspace{1em}
  \centering
  \setlength{\abovecaptionskip}{10pt} % 控制图片和caption之间的距离
  \includegraphics[height=7cm]{../assets/ch3-负样本构造.pdf}
  \bicaption{负样本构造的两种方式}{Negative Sample Generation}
  \label{fig:negative-sample-generation}
\end{figure}

\indent \textbf{简单负样本构造}。对于简单负样本构造，我们直接选择不同类别的K个工具作为负样本。
在简单负样本构造中，不同类别的工具召工具回之间的功能上一般有区别，因此简单负样本构造能够保证负样本与正样本之间在工具上的差异。

\indent \textbf{困难负样本构造}。在工具选择、调用场景，开源的通用向量模型难以区分工具之间细微的语义区别。
困难负样本构造的目的是帮助模型更好地区分工具之间细微的语义区别，帮助更好地应对噪声。
我们选择采用GPT-3.5完成困难负样本的构造。由于原工具数据量众多，
从中筛选语义表述类似、但是功能上有区别的工具样本费时费力。
因此我们采取了直接用大语言模型生成工具描述作为负样本的策略。

具体策略如下：
首先，我们采样一批<query,推荐工具集>的数据，
然后我们遍历其中的推荐工具集的工具，
通过提示词将用户需求和工具描述提供给大语言模型，
要求模型生成类似但是功能上无法满足用户需求的工具描述。
通过这样遍历工具描述生成负样本，可以生成一组高质量的困难负样本供模型学习。

\subsubsection{自我反思机制}

自我反思机制的主要目的是对生成的工具调用路径进行反思，以提升整体的准确率。

自我反思机制的触发时间点有三个：1.动态寻路算法找到路径并主动结束路径 2.动态寻路算法超过了最大迭代次数并终止或放弃寻路

具体而言，自我反思模块的输入是
我们当前的工具调用路径和用户需求，
根据工具召工具回工具召回器召回的初始节点，
以及我们撰写的反思格式说明。
输出包括以下几部分：1.成功/部分失败/完全失败的等级 2.若部分失败，从哪一个工具节点开始为首个错误节点 3.若全部失败，有哪些可以删除的噪声工具初始节点

评价为“成功”的路径，我们直接进入工具召工具回调用模块进行调用。
对于评价为“失败”的路径，我们
会根据失败的等级选择进行不同的重新寻找工具调用路径：
第一种是从中间步骤开始重新寻找路径，
另一种是从头开始重新寻找路径。

\begin{enumerate}
  \item \textbf{从中间步骤继续}: 在任务未完成的情况下，我们将在短期记忆中记录寻路过程中的每一步的选择节点和理由。
  当路径被标记为“放弃”或被评判器认定为“失败”时，我们会重新激活该路径上的智能体，
  并将识别到的失败原因重新纳入历史上下文。
  评判器在判定“失败”时，通常会标记出它认为的第一个出现错误的节点。
  在重新激活智能体并进行寻路时，我们将从该节点继续，
  而不是从头开始。这种从中间步骤继续的策略不仅能够加快寻路速度，
  减少大语言模型的调用次数，还能充分利用先前成功调用的经验，
  从而提升决策的准确性。
  \item \textbf{重新寻路}: 在自我反思模块认为路径“完全失败”时，
  我们需要从头开始重新生成整条路径。评判器会识别路径初始节点中与用户查询无关的工具名称作为反思的一部分。
  为了提高系统的整体效率，我们会首先从初始工具节点中移除这些无关的工具，
  避免大模型受到这些噪声的影响，从而选择无关的工具进行调用，
  导致后续调用出错。通过这一清理过程，我们能够有效减少噪声工具的影响，
  确保后续搜索的准确性。\par
  接下来，我们将会在经过噪声清理的工具组中重新开始选择下一节点并组成路径。
  这种从头开始的自我反思允许算法在一个更加简洁与优化的初始条件下进行搜索，
  从而提升工具调用路径的质量与响应速度。
\end{enumerate}
 
该自我反思机制可以反复应用，直至满足终止条件为止。这种持续的反思过程确保了对问题的逐步优化，有助于形成更加有效的调用路径。

综上所述，这两种反思策略——从中间步骤继续优化和从头开始的寻路——的结合使用，能够在处理用户需求未满足的情况下，提供更高的灵活性与效率。
通过不断的反思与优化，系统将逐步提升其在动态环境中的适应能力，确保用户体验的持续改进。

\subsubsection{工具调用路径记忆框架}

本小节提出了关于增强模型规划和推理准确性的记忆框架。该框架主要分为短期记忆和长期记忆两个部分。
短期记忆部分指的是当模型在图上动态推理时存储的每个步骤的记录，
主要聚焦于以什么数据格式来存储推理步骤，
以及记录哪些有用的记忆信息：在图上前进、回溯还有大模型的思考过程等。
长期记忆部分主要是将历史的工具调用路径存储在数据库中，通过相似度搜索算法加入到工具选择器
的提示词中，以增强其推理和规划能力。

\indent \textbf{短期记忆}

短期记忆指的是模型在图上进行不断推理时保存的一些状态信息，
这些信息包括：用户的任务、当前遍历到的节点、历史遍历的节点、调用路径信息等。
在遍历的过程中，我们会动态地更新和维护短期记忆存储的内容，来辅助模型进行推理和规划。
在短期记忆中，我们一般将全部的信息存储在内存中，
然后每次直接构建提示词添加到大语言模型的上下文中，
让模型能够感知到当前的状态和环境。

\indent \textbf{长期记忆}

长期记忆与短期记忆相对，是固定存储在数据库中的信息，且会随着调用次数的增加不断积累。
它记录最终形成的工具调用链和结果，每次推理时，系统都会从长期记忆库中搜索，将搜到的相似需求的工具调用路径提供给
工具选择器，利用历史经验辅助大语言模型的推理。

长期记忆模块基于检索增强生成（Retrieval-Augmented Generation, RAG）逻辑，通过将历史上成功的<用户需求，工具调用路径>转为向量存储。新需求通过向量模型转为嵌入向量，并与数据库中的向量进行相似度计算。系统会根据相似度排序，检索出与当前需求最相似的 K 个历史需求及其工具调用路径。最终，这些<用户需求，工具调用路径>的二元组会被加入大语言模型的上下文中，辅助推理与规划。

\subsection{工具调用模块}
\label{sec:real_tool_simulation}

\subsubsection{整体逻辑}

工具调用模块的主要功能是执行规划好的工具召工具回调用路径，并将得到的结果返回给系统，
从而为后续的推理和规划提供支持，最终生成符合用户需求的答案。

该模块的整体逻辑可以分为两个主要部分：工具调用和工具响应解析。
具体而言，我们首先根据工具的描述信息和用户需求生成工具召工具回调用的参数，然后通过代码生成请求体并通过工具召工具回调用接口将请求体发送给目标工具召工具回工具，
以获取其响应。
获得响应后，理论上我们可以直接将所有工具的调用结果直接提供给总结器，要求模型根据所有的工具召工具回响应输出最终结果。

但由于每个响应的长度参差不齐，对于一些响应长度较长的工具召工具回工具，可能单个工具召工具回的响应数据就超出了大语言模型的上下文限制。
因此，我们添加了一个基于大语言模型的响应压缩模块，通过对响应的压缩，将工具召工具回响应的字符数控制在1024个字符以内，以缓解大语言模型的上下文限制。

\subsubsection{工具参数生成}

工具调用模块的主要工作就是生成工具召工具回工具的请求体。在请求体的生成过程中，我们首先将与工具调用相关的内容提供给大语言模型智能体，要求其生成指定的JSON格式调用输入，包括但不限于工具调用的URL、所需输入参数及工具的登录验证信息等。接着，我们对生成的JSON数据中的参数信息进行验证，并确定请求体中各个参数的结构和格式。

首先，我们会确认生成的参数URL与工具库中的URL是否匹配。其次，参数的正确性对工具召工具回工具调用的成功至关重要，因此在执行调用工具代码之前，我们会对参数进行严格的校验。在这一步中，我们验证具体的参数数量、类型和名称，并对这些部分进行精确匹配。如果缺少必要的参数或参数类型不匹配，我们将返回固定的错误信息，并要求参数解析器重新生成参数。这一过程会一直重复，直到获取正确的参数或超过最大尝试次数后放弃该工具召工具回调用。

在成功验证URL和参数后，我们将调用固定的函数来执行工具召工具回请求，并获取JSON格式的响应，随后将其提供给响应解析模块。

\subsubsection{工具响应解析模块}

生成请求体后，我们将其通过工具召工具回调用接口发送给目标工具召工具回工具，以获取相应的响应数据。响应数据通常是以JSON格式返回的，这其中可能包含大量的信息，而这些信息并不总是直接相关。在我们的实际实验中，我们通过分析发现许多工具召工具回返回内容包含大量冗余信息，导致其长度过长，无法将调用结果输入到大语言模型中，直接使用大语言模型从中提取重要信息较为困难。因此，我们对工具召工具回的响应结果进行了压缩。该模块的目标是在尽可能多地保留关键信息的同时减少工具召工具回响应的长度，便于放入大语言模型的上下文中。

由于每个工具召工具回的响应格式不是固定的，无法确定每个字段应该舍弃还是保留，因此我们采用大语言模型来分析示例响应，仅保留与用户需求相关的字段，以减小响应长度。

如图~\ref{fig:ch4-compression}，响应压缩的逻辑如下所示：

\begin{figure}[!htp]
  \vspace{1em}
  \centering
  \setlength{\abovecaptionskip}{10pt} % 控制图片和caption之间的距离
  \includegraphics[height=7cm]{../assets/ch4-工具调用模块.pdf}
  \bicaption{响应压缩模块}{Compression of 工具召工具回 responses}
  \label{fig:ch4-compression}
\end{figure}

\begin{enumerate}
    \item \textbf{工具文档信息}：所有工具召工具回工具均来自ToolBench等开源数据集，这些数据集同时包含每个工具召工具回的详细描述信息和工具召工具回响应示例。因此，我们可以将工具名称、工具描述、工具召工具回名称、工具召工具回描述、参数及工具召工具回响应示例的内容以文本形式提供给大型语言模型。这部分构成了压缩模块的基本提示词。
    
    \item \textbf{详细规则指令}：我们要求大型语言模型仔细阅读工具召工具回的功能描述，并保留与功能描述最相关的信息，诸如工具召工具回版本、调用时间或无效信息等可以被舍弃。
    
    \item \textbf{上下文学习示例}：我们使用了三个上下文学习示例，每个示例由一个原始工具召工具回响应和对应的专家撰写的压缩响应组成。我们要求压缩器以自然语言文本格式输出所有需要保留的字段，然后通过正则表达式匹配得到一个保留字段的列表，并用固定的代码逻辑筛选出相应字段的返回内容。
\end{enumerate}

在推理过程中，当工具召工具回响应长度超过1024个字符时，我们会通过移除不重要的信息来压缩响应。如果压缩后的响应仍然超过1024个字符，则只保留压缩后的前1024个字符。这种方法能够有效地减少工具召工具回响应长度，对工具召工具回响应进行去噪。同时，也能够缓解大型语言模型有限的上下文窗口的问题，确保系统的正常调用。

通过分析我们在ToolBench中的工具召工具回响应示例，其中一个工具召工具回的平均响应字符串长度为xxx个字符。经过响应压缩后，最长的响应也不超过1024个字符。通过这种方式，我们有效降低了xx\%的超出上下文的情况，平均每个工具召工具回响应结果节约了xx个字符。

\subsection{工具总结模块}

【主要就写对所有工具召工具回的调用结果进行总结，重要的是如何进行错误处理和拒答】

工具总结模块的功能是依赖大语言模型对所有工具召工具回的调用结果进行总结，以生成符合用户需求的答案。

\ref{fig:ch4-summary}

\begin{figure}[!htp]
  \vspace{1em}
  \centering
  \setlength{\abovecaptionskip}{10pt} % 控制图片和caption之间的距离
  \includegraphics[height=5cm]{../assets/ch4-工具总结模块.pdf}
  \bicaption{整体框架}{Overview of the Dynamic Tool Selection Framework}
  \label{fig:ch4-summary}
\end{figure}


这部分类似传统的检索增强生成，通过调用工具召工具回工具得到的结果就类似检索到的信息，对用户需求进行回答就类似
检索生成的生成部分。
这一部分最重要的是：
1.减少幻觉现象
2.确保回答的稳定性（每次回答都有类似的答案）
3.确保回答的相关性（减少噪声）

为了完成上述目标，我们通过提示词工程进行设计了一个工具总结模块的提示词模板，通过提供一个供模型思考和回答的模板，
让模型能够更加稳定、有逻辑地生成符合用户需求的答案。

% Set Colors
\definecolor{bgcolor}{RGB}{240,240,240} % Background color
\definecolor{titlecolor}{RGB}{20,20,20} % Title background color

\begin{center}
% Create background with tcolorbox
\begin{tcolorbox}[colback=bgcolor, colframe=black, width=0.8\textwidth, boxrule=0.5mm, 
coltitle=white, colbacktitle=titlecolor, title=An Example for Response Generation with GPT-4]

% Centered content

\textbf{Instruction Prompt:} Generate a response to the user's question based on the results from the tools and your internal knowledge.

\textbf{Task:} What's the most popular travel destination in Europe? And what's the weather like there?

\textbf{Return from Tool Calling:} 
\{%
    "popular\_travel\_destination": \{%
        "destination": "Paris, France",%
        "popularity\_score": 9.8%
    \},%
    "global\_weather\_search": \{%
        "location": "Paris, France",%
        "weather": \{%
            "temperature": "15°C",%
            "condition": "Partly Cloudy",%
            "humidity": "60\%",%
        \},%
        "timestamp": "2024-11-17T14:00:00Z"%
    \}%
\}

\textbf{Instructions:}
1. If the tool's output is incorrect, or if the information from the tools and your internal knowledge is insufficient to answer, do not respond. Avoid fabricating any untrue information.

2. Think step by step before answering. Plan the key points to address before formulating your response.

3. Only answer the user's request. Do not include any additional or irrelevant information.

4. Use the same language as the Task (in this case, English).

5. Provide the output in JSON format.

\textbf{Output Format:}  
\{%
    "Steps": [%
        "Find the most popular travel destination in Europe.",%
        "Describe the current weather at that destination."%
    ],%
    "Result": "The most popular travel destination in Europe is Paris, France. The weather in Paris is partly cloudy with a temperature of 15°C, a humidity level of 60\%."%
\}

\end{tcolorbox}
\end{center}

\section{本章小结}
\label{sec:summary_chap4}