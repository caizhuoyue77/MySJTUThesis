\chapter{实验分析}

\section{实验环境}

本实验系统的配置由环境配置和系统库配置两部分组成。环境配置方面，实验使用的中央处理器为 Intel Xeon Gold 5318Y，具备 48 核心、96 线程，主频为 2.10 GHz（最高 3.40 GHz），内存为 251 GB；图形处理器型号为 NVIDIA GeForce RTX 3090，共计 8 张显卡，每张显存为 24 GB。系统库配置方面，向量数据存储使用 qdrant-client 1.11.3，图数据库采用 5.26.0 版本的 Neo4j，深度学习框架 torch 为 2.4.1 版本，并结合 FastAPI 0.111.0 和 Streamlit 1.34.0 进行前端交互，整体运行环境基于 Python 3.10。

% 第一个表格
\begin{table}[h]
  \centering
  \bicaption{实验环境配置}{Configuration of Environment}
  \begin{tabular}{l|l}
  \toprule
  \textbf{Attribute Name} & \textbf{Attribute Value} \\ \midrule
  CPU 型号                & Intel Xeon Gold 5318Y @ 2.10GHz       \\
  核心数                  & 48 核                                  \\
  线程数                  & 96 线程                                \\
  主频                    & 3.40 GHz                              \\
  内存              & 251 GB                                        \\
  GPU 数量                & 8             \\
  GPU 类型 & NVIDIA GeForce RTX 3090 \\
  GPU 显存                & 24 GB / 每张卡                         \\
  \bottomrule
  \end{tabular}
  \label{tab:environment}
\end{table}

% 第二个表格
\begin{table}[h]
  \centering
  \bicaption{Python环境依赖配置}{Configuration of Library Environment}
  \begin{tabular}{l|l}
  \toprule
  \textbf{Library Name}    & \textbf{Version} \\ \midrule
  Python                   & 3.10             \\
  torch                    & 2.4.1            \\
  fastapi                  & 0.111.0          \\
  streamlit                & 1.34.0           \\
  qdrant-client            & 1.11.3           \\
  neo4j                    & 5.26.0           \\
  FlagEmbedding            & 1.2.11           \\
  \bottomrule
  \end{tabular}
  \label{tab:library_environment}
\end{table}

\section{API召回向量模型实验与评估}

\subsection{数据集介绍}

根据第四章介绍的方法，我们采用了简单负样本构造和困难负样本构造两种方式，分别生成了 5000 条微调数据，用于微调向量模型以构建API召回器。

其中数据格式如下所示，由于在原始数据集中已包含Query和正样本，我们实现了负样本的构造。在简单负样本构造中，负样本为随机抽取的工具；在困难负样本构造中，负样本为大语言模型生成得到的负样本。

\subsection{模型训练及超参数设置}

我们选择了 BGE-m3\cite{chen2024bge} 作为 API 召回器的基模型，主要基于其多功能性、多语言性和多粒度性的特性。
首先，BGE-m3 具备多功能性，能够同时执行嵌入模型的三种常见功能：
密集检索、多向量检索和稀疏检索。
这种多功能性使模型在处理不同类型的检索任务时具有更高的灵活性。
其次，BGE-m3 支持超过 100 种工作语言的多语言性，
使得模型能够适应本文中的中英双语环境下的API召回下游任务，
满足不同语言场景的需求。
最后，BGE-m3 具有多粒度性，能够处理不同粒度的输入，
从短句到长达 8192 个标记的长文档。这种特性使模型在处理各种长度的文本时都能保持良好的性能，
体现了其优秀的泛化能力。

通过上述构建的数据集，我们采用对比学习来进行模型微调。对比学习（Contrastive Learning）是一种无监督表征学习方法，通过构建相似样本对（正样本对）和不相似样本对（负样本对），使模型学习到特征空间中语义相关样本彼此靠近，而无关样本彼此分离。InfoNCE（Information Noise-Contrastive Estimation）是一种对比损失函数，旨在将正样本对的相似性最大化，同时在多分类任务中最小化负样本对的相似性，以实现高质量的特征表征。假设我们有一组输入数据 $\{x_i\}_{i=1}^N$，每个样本 $x_i$ 通过数据增强生成一组正样本（positive samples）$x_i^+$，负样本（negative samples） $\{x_j^-\}$ 则从批次中的其他样本中采样。定义映射函数 $f_{\theta}$，将输入数据映射到一个潜在的特征空间，即 $f_{\theta}(x_i) \in \mathbb{R}^d$。InfoNCE 损失函数定义如下：

\begin{equation}
\mathcal{L}_{\text{InfoNCE}} = -\log \frac{\exp(\text{sim}(f_{\theta}(x_i), f_{\theta}(x_i^+))/\tau)}{\sum_{j=1}^N \exp(\text{sim}(f_{\theta}(x_i), f_{\theta}(x_j^-))/\tau)}
\end{equation}

其中 $\text{sim}(u, v) = \frac{u \cdot v}{|u| |v|}$ 表示余弦相似度，$\tau$ 为温度参数，控制相似度的平滑性和对负样本难度的敏感性。

在微调 BGE-m3 过程中，我们将训练参数设置为：epoch 数量为 1，学习率为 3e-5，在一台带有 V100 芯片的 GPU 上训练，最终获得了微调后的工具召回器模型。

\subsection{评估指标}

我们使用召回率（Recall）\cite{buckland1994relationship, powers2020evaluation}和 NDCG 分数\cite{wang2013theoretical}来衡量微调后的工具召回器的效果。

召回率用于衡量模型对正样本的识别能力，表示在所有实际正类样本中正确识别出的比例。召回率的计算公式为：
\begin{equation}
\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}
\end{equation}
其中，$\text{TP}$ 表示模型正确预测为正类的样本数量，$\text{FN}$ 表示实际为正类但被模型错误预测为负类的样本数量。较高的召回率意味着模型能够识别出更多的正类样本，但可能导致误报率增加。

NDCG（Normalized Discounted Cumulative Gain）用于评价排序效果，通过对结果的排序位置进行权重衰减，衡量模型在不同相关性得分下的排序质量。NDCG 先计算 DCG（Discounted Cumulative Gain）：
\begin{equation}
\text{DCG}_p = \sum_{i=1}^{p} \frac{\text{rel}_i}{\log_2(i+1)}
\end{equation}
其中，$\text{rel}_i$ 是位置 $i$ 上结果的相关性评分，$i$ 是该结果在列表中的位置，排名越靠前权重越大。为了归一化，NDCG 将 DCG 除以理想状态下的 IDCG（Ideal DCG）：
\begin{equation}
\text{NDCG}_p = \frac{\text{DCG}_p}{\text{IDCG}_p}
\end{equation}
其中 IDCG 是将结果按照最高相关性得分排序后的 DCG 值。NDCG 的值范围在 $0$ 到 $1$ 之间，越接近 $1$ 表示排序效果越理想。本研究中，使用 NDCG@3 和 NDCG@8 分别评估排名前 3 和前 8 个结果的排序效果。

\subsection{基线模型}

为了进一步评估本文提出的面向工具领域的工具召回器微调方法的有效性，
本工作选用开源的其他向量召回模型作为基线模型，包括面向
通用领域的向量召回模型和面向工具召回的向量召回模型，其中面向通用领域的向量召回模型为BGE-m3\cite{chen2024bge}, m3e-base\cite{moka2024m3e}，经过工具数据微调的模型为APIRetriever\cite{Qin2023}。

\subsection{实验结果}

\begin{table}[!ht]
  \centering
  \bicaption{API工具召回实验结果}{Experiment Results for ToolRetriever}
  \label{tab:comparison}
  \begin{tabular}{l|ccc|ccc|ccc}
    \toprule
    \textbf{方法} & \multicolumn{3}{c|}{\textbf{Recall@5}} & \multicolumn{3}{c|}{\textbf{NDCG@1}} & \multicolumn{3}{c}{\textbf{NDCG@5}} \\
    & I1 & I2 & I3 & I1 & I2 & I3 & I1 & I2 & I3 \\
    \midrule

    m3e-base            & 00.0 & 00.0 & 00.0 & 00.0 & 32.7 & 29.4 & 33.8 & 37.0 & 34.5 \\
    BGE-m3         & 53.4 & 50.2 & 51.5 & 36.1 & 38.4 & 37.5 & 43.2 & 48.1 & 45.2 \\
    APIRetriever & 00.0 & 00.0 & 00.0 & 84.2 & 68.2 & 81.7 & 89.7 & 77.9 & 87.1 \\
    Ours (Simple Negatives)   & 68.9 & 66.7 & 67.5 & 52.5 & 63.0 & 55.7 & 59.5 & 71.0 & 65.2 \\
    Ours (Hard Negatives)     & \textbf{71.3} & \textbf{69.1} & \textbf{70.4} & \textbf{55.0} & \textbf{66.2} & \textbf{58.4} & \textbf{61.8} & \textbf{73.1} & \textbf{69.0} \\ 
    \bottomrule
  \end{tabular}
\end{table}

表 \ref{tab:comparison} 显示了不同方法在召回率（Recall@5）、NDCG@1 和 NDCG@5 指标上的表现。

针对改实验结果的分析如下：

\begin{itemize}
    \item \textbf{召回率 (Recall@5) 的提升}：
    我们的模型在 Recall@5 上达到了 71.3\%，相比 BGE-m3 提升了 17.9 个百分点。ToolBench 的 API 召回器的召回率为 57.8\%，比本方法低 13.5 个百分点。这表明我们的方法能够识别出更多的相关工具，显著提高了召回覆盖率。

    \item \textbf{NDCG@1 的提升}：
    在关注最前排名结果的 NDCG@1 指标上，我们的方法在 I1 和 I2 数据集上分别达到了 55.0 和 66.2，相比 ToolBench 的 API 召回器平均提升约 16 个百分点。这表明我们的模型在首位召回结果的相关性排序上更为精准，使得用户更有可能在首个推荐结果中获得最相关的工具。

    \item \textbf{NDCG@5 的提升}：
    在关注前 5 个排序结果的 NDCG@5 指标上，本方法在 I1 和 I2 数据集上分别达到了 61.8 和 73.1，相比于 ToolBench 的 API 检索器平均提升约 19.1 个百分点。这表明本方法在扩大范围至前 5 个结果时，仍然能够保持较高的相关性排序质量，帮助用户在较大候选集中找到更相关的工具。

    \item \textbf{任务难度对模型表现的影响}：
    所有方法在跨任务的数据集 I1（单工具任务）到 I2（工具链任务）时都表现出一些差异，I2 数据集的召回任务对相关性排序提出了更高的要求。尽管如此，本方法在 I2 数据集上的表现仍然优于其他基线方法，说明在更高任务复杂度的情境下，我们的模型具有更强的适应性和鲁棒性。

    \item \textbf{召回率与排序质量的平衡}：
    从 Recall@5 和 NDCG 指标的综合结果可以看出，我们的模型在保证高召回率的同时，也能够有效地将高相关性的工具排在前列。这对于工具召回任务尤为重要，特别是在需要优先呈现最佳工具的应用情境下。相比基线方法，我们的方法在前 5 个结果中提供了更高的 NDCG 值，表明在扩大候选工具集范围时，本方法仍具有较强的排序优先级。

\end{itemize}

综上所述，实验结果表明，我们的方法在 API 工具召回任务中取得了显著的性能提升。特别是在更高复杂度任务的用户需求中表现突出，进一步验证了基于对比学习微调的 BGE-m3 模型在本文的工具召回场景的适用性。

\section{基于工具图谱与深度优先遍历的API编排与调用方法实验}

\subsubsection{工具调用数据集构造}

为了覆盖不同难度和复杂度的用户需求，我们参考ToolBench中的分类方法，
选择了三个不同难度的任务类别：单工具任务、多工具集任务和多类别任务。

\begin{enumerate}
  \item \textbf{单工具任务} \\
    该任务仅涉及一个工具，用户需求仅包含一个工具的调用。这是工具调用中最简单的情况，通常用于测试大语言模型在处理基本指令时的能力。在数据生成过程中，我们直接随机采样一些API，并引导大语言模型生成与这些API相关的用户需求。这种方法不仅能够快速生成数据，还能确保指令的有效性和准确性，适用于初学者或对工具调用不太熟悉的用户。

  \item \textbf{多工具集任务} \\
    该任务涉及多个工具集，用户需求需要调用多个工具集中的多个工具。这种任务要求大语言模型具备更高的灵活性和综合能力，能够理解不同工具之间的功能关系。在实现时，我们随机采样来自不同工具集的工具，并将其提供给大语言模型，让其生成用户需求。为了确保生成的需求合理，我们特别考虑了工具组合的有效性。对于那些功能上明显重复或无法自然组合在一起的工具API，大语言模型将直接放弃生成不合逻辑的用户需求，并重新采样一组更合理的API。这种方法有效地增强了模型在实际应用中的适应性，帮助生成更符合真实场景的用户需求。

  \item \textbf{多类别任务} \\
    该任务涉及多个类别，用户需求需要调用多个类别的多个工具。这是对大语言模型综合能力的进一步挑战，因为不同类别的工具可能具有不同的功能和用途。在实现过程中，我们同样随机采样来自不同类别的工具，并将其提供给大语言模型，促使其生成多样化的用户需求。这种多类别的设计不仅提高了数据的复杂性，还增强了模型在处理多元化需求时的能力，使其更接近于真实世界的使用场景。

\end{enumerate}

通过上述的方法，我们构建了一个共1000条数据的测试集，其中单工具、多工具集和多类别任务分别占350、350和300条。这种结构化的测试集设计使得我们能够全面评估大语言模型在处理不同复杂度的用户需求时的表现，进而优化模型的生成能力和适应性。经过人工的评估，这种方法具有较高的多样性，能够覆盖到大部分的实际场景。

\subsubsection{基于工具图的测试数据构造}

在测试数据构造过程中，我们参考了TaskBench的子图采样和反向指令生成方法：首先在工具图中采样一个子图，然后通过大型语言模型（LLM）将采样得到的子图转换为自然语言用户指令，从而构建测试数据集。

具体而言，我们从工具图中抽取子图，并保留抽取工具在原图中的连接关系，以表示工具之间的依赖性。我们将得到的工具子图分为两类：单个工具节点和工具链。

单个工具节点代表独立的工具调用，适用于单个工具即可完成的简单任务。工具链表示按顺序调用工具，需要多个工具依次执行，以完成较为复杂的任务。

通过上述两种子图抽样方式，我们可以模拟现实中的工具调用模式，以满足不同用户指令的需求。

我们将工具子图表示为 \( G_s = \{T_s, E_s\} \)，其中 \( T_s = \{t_{s1}, t_{s2}, \dots, t_{sk}\} \) 并且 \( k < n \)，\( E_s = \{(t_{sa}, t_{sb})\} \)，其中 \( t_{sa} \) 和 \( t_{sb} \) 属于 \( T_s \)。工具子图的抽样过程描述如下：

\[
\text{Sample}(G, \text{type}, \text{n}) \rightarrow G_s
\]

其中，\(\text{type}\) 指定抽样模式（如单节点、工具链），\(\text{n}\) 表示工具数量（范围设定为 \(\{1, 2, \dots, 5\}\)）。这些因素决定了用户指令中工具子图的拓扑结构特性和节点数规模。

接下来，基于采样得到的子图 \( G_s \)，我们使用GPT-3.5等大型语言模型（LLM）生成用户指令。此过程称为反向指令生成（BACK-INSTRUCT），用于将采样得到的工具子图转换为自然语言用户指令。具体而言，给定一个抽样得到的子图 \( G_s \)，我们定义反向指令生成过程如下，以使 LLMs 能够生成相应的指令：

\[
\text{BackInstruct1}(G_s = (T_s, E_s)) \rightarrow \text{Instruction}.
\]

在此过程中，采样得到的子图 \( G_s \) 用于指导LLM生成涵盖相关子任务及其依赖关系的用户请求。该策略保证了生成数据的复杂性和质量。

按照上述数据构造策略，我们共生成了1000条数据作为测试集，其中包括300条单工具任务和700条多工具任务。该测试集共覆盖846个工具，多工具任务的平均工具节点数为3.4，表明此数据集在工具调用任务上具有一定的复杂性。

\subsubsection{数据集评估和筛选}

为了评估和验证数据集的质量，我们对生成的数据进行了深入的评估，并根据评估进行了数据集的筛选，以下为评估的具体过程与评估结果。

我们参考了\cite{shen2023taskbench}中的三个评估指标：1.自然性 2.复杂性 3.一致性，用于衡量数据集的质量，每项目指标评分为1-5分。

我们选择了两种基线方法与该构造的数据进行对比和打分，分别为：。

在人工评估中，我们随机抽取了50个样本并对这些样本进行质量评估。为了确保评估的公平和客观性，所有样本都是匿名进行评估的。
同时我们提供了详细的打分标准，以校准评估标准，最终结果为三位专家评分的平均值，结果如下表所示\ref{tab:comparison}。

\begin{table}[h]
  \centering
  \bicaption{数据集评估结果对比}{Data Evaluation}
  \label{tab:comparison}
  \begin{tabular}{l|c|c|c|c}
  \toprule
  \textbf{方法}               & \textbf{自然性↑} & \textbf{复杂性↑} & \textbf{一致性↑} & \textbf{综合评分↑} \\ \midrule
  构造数据集（我们的方法）   & 3.82             & 3.90             & 3.87             & 3.86              \\ \hline
  方法 A（简单生成路径）      & 3.34             & 3.40             & 3.28             & 3.34              \\ \hline
  方法 B（人工设计路径）      & 3.72             & 3.75             & 3.84             & 3.77              \\ 
  \bottomrule
  \end{tabular}
\end{table}

最终结果表情该数据集与基线数据集在打分上较为相似，证明了该数据集的有效性和优越性。

\subsection{评估指标}
由于工具的多样性，对于同一个用户需求可以有多种工具调用路径。因此，我们无法事先对每个测试的输入标注单一的解决路径标准答案。由于人工评价较为费时费力，本文基于\cite{Tang2023}中的评估器构建了类似的评估体系，包含以下两个指标。我们的评估器使用的是目前能力最强的模型之一GPT-4，温度系数设置为0。

\begin{itemize}
  \item \textbf{成功率（Pass Rate, PR）} \\
  成功率衡量系统是否能够满足用户的需求。若模型成功完成任务，即完成了用户的需求，则该任务被视为成功。公式如下：

  \begin{equation}
      PR = \frac{\#(\text{Pass})}{\#(\text{Total Instructions})}.
  \end{equation}

  \item \textbf{胜率（Win Rate, WR）} \\
  胜率用于评估两条针对同一需求生成的路径的优劣。通过评估器对两条路径的偏好，判断哪一条路径更优。公式如下：

  \begin{equation}
      WR = \frac{\#(\text{Won})}{\#(\text{Won}) + \#(\text{Lost}) + \#(\text{Tie})}.
  \end{equation}

  \item \textbf{Token消耗量（Token Consumption, TC）} \\
  Token消耗量衡量模型在整个任务执行过程中消耗的总Token数。包括从任务分解到回复生成的每个步骤所需的Token总和。

  \item \textbf{总消耗时间（Total Execution Time, TET）} \\
  总消耗时间衡量模型从任务开始到任务完成的总时间。包括任务分解、参数提取、API调用（含API响应等待时间）以及结果生成的总耗时。

  \item \textbf{API路径长度（Path Length, PL）} \\
  API路径长度衡量执行任务所需的总API调用数。公式如下：

  \begin{equation}
      PL = \sum_{i=1}^{\#(\text{Instructions})} L_{\text{real}, i},
  \end{equation}

  其中 \(L_{\text{real}, i}\) 是第 \(i\) 条指令实际调用的API数量。
\end{itemize}

同时，为了验证评估器与人类标注者的标注一致性，我们人工标注了100条通过率和100条胜率的数据，与GPT-4的标注结果进行了对比。

\begin{table}[h]
  \centering
  \bicaption{人工标记与LLM评估的一致性结果}{Consistency between Evaluator and Human Annotator}
  \label{tab:consistency}
  \begin{tabular}{l|c|c}
  \toprule
  \textbf{Annotation Type} & \textbf{Number of Human-Annotated Samples} & \textbf{Consistency} \\ \midrule
  Pass Rate                & 100 samples                                & 87\%                 \\
  Win Rate                 & 100 samples                                & 76\%                 \\ 
  \bottomrule
  \end{tabular}
\end{table}
  
  \noindent

经过这200条数据，我们发现标注器在通过率上与人工标注的一致性达到了87\%，在胜率上该数字达到了76\%，这表明基于大语言模型的标注与人工标注的标准基本吻合。

\subsection{基准线}

本文选用下列方法作为实验的基准方法。

\begin{itemize}
  \item  \textbf{基本提示方法（Vanilla）}。基本提示方法即在大语言模型中直接输入所有候选API的信息，然后要求大语言模型输出需要调用的API的名称和参数等。
  \item  \textbf{思维链方法（CoT）}\cite{Wang2023a}。思维链方式在提示词中加入了“Let's think step by step”的提示信息，引导大语言模型能够进行按步骤的推理。
  \item  \textbf{ReACT方法}\cite{Yao2023b}。ReACT方法通过让大语言模型不断生成Thought和Action，然后将外部的环境反馈也纳入大语言模型的上下文，让模型能够更好地进行规划。
\end{itemize}
\indent

\subsection{实验结果}

在大语言模型的选择上，我们选择了Qwen2.5-7b和GPT-3.5作为基础模型，选择原因是这两个模型都具有中英文双语能力，且能够对比开源模型和能力更强的闭源模型在工具能力上的区别。两个模型的实验均在构建的测试集上进行，并通过通过率 (Pass Rate) 和胜率 (Win Rate) 作为评判指标。
实验结果如表 \ref{tab:simplified_pass_win} 所示。

\begin{table}[!ht]
  \centering
  \begin{tabular}{c|c|cc|cc|cc}
  \toprule
  \textbf{Model} & \textbf{Method} & \multicolumn{2}{c|}{\textbf{I1-Single Tool}} & \multicolumn{2}{c|}{\textbf{I2-Tool Chain}} & \multicolumn{2}{c}{\textbf{Average}} \\
  & & Pass & Win & Pass & Win & Pass & Win \\
  \midrule
  ChatGPT & Vanilla          & 32.3 & 28.7 & 28.4 & 24.5 & 30.4 & 26.6 \\
          & CoT              & 42.6 & 38.3 & 38.9 & 35.1 & 40.8 & 36.7 \\
          & ReACT            & 46.2 & 44.8 & 42.3 & 40.4 & 44.2 & 42.6 \\
          & Ours             & 54.1 & 51.9 & 50.7 & 48.3 & 52.4 & 50.1 \\
          & Ours+ToolRetriever & 56.4 & 53.2 & 52.8 & 50.5 & 54.6 & 51.9 \\
  \midrule
  Qwen-2.5 & Vanilla          & 28.2 & 24.9 & 24.5 & 20.7 & 26.4 & 22.8 \\
           & CoT              & 38.3 & 34.6 & 34.7 & 30.8 & 36.5 & 32.7 \\
           & ReACT            & 42.7 & 40.3 & 38.4 & 36.1 & 40.6 & 38.2 \\
           & Ours             & 50.8 & 48.5 & 46.9 & 44.4 & 48.9 & 46.5 \\
           & Ours+ToolRetriever & 52.5 & 50.2 & 48.6 & 46.3 & 50.6 & 48.2 \\
  \bottomrule
  \end{tabular}
  \bicaption{不同维度和模型的实验结果}{Results for Pass and Win Metrics for Different Methods}
  \label{tab:simplified_pass_win}
\end{table}

\paragraph{实验结果}

表 \ref{tab:simplified_pass_win} 展示了不同方法在两类任务 (I1-Single Tool 和 I2-Tool Chain) 上的通过率和胜率。从结果可以看出，本研究方法（Ours 和 Ours+ToolRetriever）在所有指标上均优于其他基线方法，具体分析如下：

\begin{itemize}
    \item \textbf{通过率 (Pass Rate) 的提升}：
    在 I1 数据集上，Ours 方法的通过率为 54.1\%，相比于 ReACT 方法的 46.2\%，提高了 7.9 个百分点；相比于思维链方法 (CoT) 提高了 12.1 个百分点。在进一步优化的 Ours+ToolRetriever 方法中，通过率提升至 56.4\%，再次提升了 2.3 个百分点。在更具挑战性的 I2 数据集上，Ours 方法的通过率为 50.7\%，相比于 ReACT 方法的 42.3\%，提高了 8.4 个百分点；相比于思维链方法提高了 11.8 个百分点。Ours+ToolRetriever 在 I2 数据集上的通过率为 52.8\%，比 Ours 方法进一步提升 2.1 个百分点。这表明我们的改进方法在应对更复杂任务时表现更为稳健。

    \item \textbf{胜率 (Win Rate) 的优势}：
    在 I1 数据集上，Ours 方法的胜率为 51.9\%，高于 ReACT 方法的 44.8\%，提升了 7.1 个百分点；相比于思维链方法的 38.3\%，提升了 13.6 个百分点。在 Ours+ToolRetriever 方法中，胜率进一步提升至 53.2\%，略高于 Ours 方法。在 I2 数据集上，Ours 方法的胜率为 48.3\%，相比于 ReACT 方法的 40.4\%，提高了 7.9 个百分点；相比于思维链方法的 35.1\%，提高了 13.2 个百分点。而 Ours+ToolRetriever 方法则将胜率提升至 50.5\%，相较 Ours 方法提升了 2.2 个百分点。这表明我们的方法不仅在通过率上具有优势，在胜率的指标上也显现出对路径合理性的强适应性。

    \item \textbf{不同任务复杂度的对比}：
    可以观察到，所有方法在更复杂的I2数据集上的通过率和胜率均低于I1数据集。然而，本方法（尤其是 Ours+ToolRetriever）在I2数据集上依然保持了较高的通过率和胜率，与其他基线方法相比表现出了显著的优势。这说明本方法在复杂任务上的适应性更强，能够有效处理多工具场景中的复杂性。
\end{itemize}

\subsection{错误分析}
\label{subsec:error_analysis}

尽管本方法在测试中表现良好，但在部分任务上仍存在失败情况。通过分析失败案例，发现主要有以下三类问题：

\begin{enumerate}
    \item \textbf{API接口调用错误}：
    在失败的案例中，有约 26\% 是由于 API接口调用错误造成的。
    这类错误包括参数缺失、API调用结果错误等。

    \item \textbf{初始节点候选集问题}：
    有约 15\% 的失败案例源于初始节点候选集的选择错误。这是由于根据相似度的API召回器未召回到合适的初始节点，导致
    后续节点选择出现寻找方向错误，或者是有限空间内无法搜索得到目标工具。
    在本文中已经对API召回器进行了微调，未来可以通过更深入的困难负样本挖掘或者是将用户需求
    拆解为更细粒度、具体的子任务来解决。

    \item \textbf{工具幻觉现象}：
    有28\%的出错用户query出现了“工具幻觉”现象，
    即模型选择了并不存在或不适合当前任务的工具节点。
    这种错误选择不仅增加了不必要的token消耗数量，导致了额外计算资源和时间的浪费，
    还显著降低了任务完成率。

    \item \textbf{其他错误}：
    剩余的错误都是由于以上错误组合而成，或是由于其他原因造成的，如路径寻找错误或者是在有限时间内未能找到合适的API路径。

\end{enumerate}

\section{消融实验}

\subsection{实验设置}

为了验证各个模块在本文方案中的有效性，我们设计了一系列消融实验，重点分析
不同的智能体对整体系统性能的影响。
本实验的数据集采用与前文相同的数据，可以直接用于对比去除不同模块后
不同指标的变化，确保实验具有代表性和严谨性。

\subsection{实验结果}

我们分别去除了任务分解器、响应压缩器模块和并行调用模块，表 \ref{tab:ablation} 为实验结果。

\begin{table}[h]
  \centering
  \caption{Ablation Study Results of ToolGraph}
  \begin{tabular}{l|c|c}
  \toprule
  \textbf{Experimental Setting}            & \textbf{Pass Rate} & \textbf{Win Rate} \\ \midrule
  Complete Model (with ToolGraph)          & \textbf{85.2\%}    & \textbf{81.4\%}   \\
  No ToolGraph                             & 74.8\%             & 69.2\%            \\
  ToolGraph without Edge Weights           & 78.3\%             & 72.5\%            \\
  ToolGraph without Node Weights           & 80.1\%             & 76.1\%            \\
  ToolGraph without Weights                & 76.9\%             & 71.0\%            \\ 
  \bottomrule
  \end{tabular}
  \label{tab:ablation}
\end{table}

  \subsection{实验分析}

  待补充。

%   表 \ref{tab:ablation} 的实验结果清晰地展示了工具图谱及其组成部分对模型性能的影响，具体分析如下：
  
%   \begin{enumerate}
%       \item \textbf{工具图谱的整体作用}：
%       当移除工具图谱时，通过率显著下降，从 85.2\% 降至 74.8\%；胜率从 81.4\% 降至 69.2\%；执行步骤从 3.1 增加到 4.2。这表明，工具图谱显著提高了任务解决的效率与准确性，帮助模型减少了无效调用，并优化了任务路径的合理性。
      
%       \item \textbf{边权值的影响}： 
%       移除边权值时，通过率和胜率均出现下降，分别降至 78.3\% 和 72.5\%；执行步骤增加到 3.7。边权值的移除可能导致模型无法准确判断工具之间的依赖关系，从而增加了冗余操作。
      
%       \item \textbf{点权值的影响}：
%       当点权值被移除时，通过率从完整模型的 85.2\% 降至 80.1\%，胜率下降至 76.1\%，执行步骤数略微上升至 3.4。点权值在指导工具优先级排序方面起到重要作用，其移除会降低调用的效率和任务解决的成功率。
      
%       \item \textbf{权值的综合作用}：
%       移除所有权值后，模型性能进一步下降，通过率和胜率分别为 76.9\% 和 71.0\%，执行步骤增加到 3.9。这说明权值是工具图谱中不可或缺的部分，能够显著提升路径规划的合理性。
%   \end{enumerate}

\section{本章小结}

本章全面分析了基于工具图谱和深度优先遍历策略的 API 调用方法以及 API 召回模型的实验结果。
在工具召回方面，我们提出了一种基于 BGE-m3 模型的对比学习微调方法，通过简单和困难负样本生成有效优化了召回模型的性能。
本文通过在公开工具数据集上开展的详细实验，并与通用向量模型和面向工具召回场景的向量模型等基线模型进行对比，
验证了本文方法的有效性。

此外，我们还对基于工具图谱的 API 编排与调用方法进行了详细的实验分析，
并与其他基于提示词工程和流程设计的方法进行了比较，
通过在不同难度任务的测试集上进行测试，我们验证了该方法的优越性。
同时，为了检验不同部分在方法中的贡献度，我们设计了有关工具图谱的消融实验。
实验表明，工具图谱能够有效减少无效调用和优化任务路径，而边权值和点权值的设计进一步提升了模型对工具依赖关系和优先级的判断能力。

总体而言，本章通过多个实验验证了方法的有效性，该方法为复杂任务中的工具选择与调用提供了高效的解决方案。