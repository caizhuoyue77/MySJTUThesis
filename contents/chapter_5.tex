\chapter{实验分析}

\section{实验环境}

本实验系统的配置由环境配置和系统库配置两部分组成。环境配置方面，实验使用的中央处理器为 Intel Xeon Gold 5318Y，具备 48 核心、96 线程，主频为 2.10 GHz（最高 3.40 GHz），内存为 251 GB；图形处理器型号为 NVIDIA GeForce RTX 3090，共计 8 张显卡，每张显存为 24 GB。系统库配置方面，向量数据存储使用 qdrant-client 1.11.3，图数据库采用 5.26.0 版本的 Neo4j，深度学习框架 torch 为 2.4.1 版本，并结合 FastAPI 0.111.0 和 Streamlit 1.34.0 进行前端交互，整体运行环境基于 Python 3.10。

% 第一个表格
\begin{table}[h]
  \centering
  \bicaption{实验环境配置}{Configuration of Environment}
  \begin{tabular}{l|l}
  \toprule
  \textbf{Attribute Name} & \textbf{Attribute Value} \\ \midrule
  CPU 型号                & Intel Xeon Gold 5318Y @ 2.10GHz       \\
  核心数                  & 48 核                                  \\
  线程数                  & 96 线程                                \\
  主频                    & 3.40 GHz                              \\
  内存              & 251 GB                                        \\
  GPU 数量                & 8             \\
  GPU 类型 & NVIDIA GeForce RTX 3090 \\
  GPU 显存                & 24 GB / 每张卡                         \\
  \bottomrule
  \end{tabular}
  \label{tab:environment}
\end{table}

% 第二个表格
\begin{table}[h]
  \centering
  \bicaption{Python环境依赖配置}{Configuration of Library Environment}
  \begin{tabular}{l|l}
  \toprule
  \textbf{Library Name}    & \textbf{Version} \\ \midrule
  Python                   & 3.10             \\
  torch                    & 2.4.1            \\
  fastapi                  & 0.111.0          \\
  streamlit                & 1.34.0           \\
  qdrant-client            & 1.11.3           \\
  neo4j                    & 5.26.0           \\
  FlagEmbedding            & 1.2.11           \\
  \bottomrule
  \end{tabular}
  \label{tab:library_environment}
\end{table}

\section{API召回向量模型实验与评估}

\subsection{数据集介绍}

根据第四章介绍的方法，我们采用了简单负样本构造和困难负样本构造两种方式，分别生成了 5000 条微调数据，用于微调向量模型以构建API召回器。

其中数据格式如下所示，由于在原始数据集中已包含Query和正样本，我们实现了负样本的构造。在简单负样本构造中，负样本为随机抽取的工具；在困难负样本构造中，负样本为大语言模型生成得到的负样本。

\subsection{模型训练及超参数设置}

我们选择了 BGE-m3\cite{chen2024bge} 作为 API 召回器的基模型，主要基于其多功能性、多语言性和多粒度性的特性。
首先，BGE-m3 具备多功能性，能够同时执行嵌入模型的三种常见功能：
密集检索、多向量检索和稀疏检索。
这种多功能性使模型在处理不同类型的检索任务时具有更高的灵活性。
其次，BGE-m3 支持超过 100 种工作语言的多语言性，
使得模型能够适应本文中的中英双语环境下的API召回下游任务，
满足不同语言场景的需求。
最后，BGE-m3 具有多粒度性，能够处理不同粒度的输入，
从短句到长达 8192 个标记的长文档。这种特性使模型在处理各种长度的文本时都能保持良好的性能，
体现了其优秀的泛化能力。

通过上述构建的数据集，我们采用对比学习来进行模型微调。对比学习（Contrastive Learning）是一种无监督表征学习方法，通过构建相似样本对（正样本对）和不相似样本对（负样本对），使模型学习到特征空间中语义相关样本彼此靠近，而无关样本彼此分离。InfoNCE（Information Noise-Contrastive Estimation）是一种对比损失函数，旨在将正样本对的相似性最大化，同时在多分类任务中最小化负样本对的相似性，以实现高质量的特征表征。假设我们有一组输入数据 $\{x_i\}_{i=1}^N$，每个样本 $x_i$ 通过数据增强生成一组正样本（positive samples）$x_i^+$，负样本（negative samples） $\{x_j^-\}$ 则从批次中的其他样本中采样。定义映射函数 $f_{\theta}$，将输入数据映射到一个潜在的特征空间，即 $f_{\theta}(x_i) \in \mathbb{R}^d$。InfoNCE 损失函数定义如下：

\begin{equation}
\mathcal{L}_{\text{InfoNCE}} = -\log \frac{\exp(\text{sim}(f_{\theta}(x_i), f_{\theta}(x_i^+))/\tau)}{\sum_{j=1}^N \exp(\text{sim}(f_{\theta}(x_i), f_{\theta}(x_j^-))/\tau)}
\end{equation}

其中 $\text{sim}(u, v) = \frac{u \cdot v}{|u| |v|}$ 表示余弦相似度，$\tau$ 为温度参数，控制相似度的平滑性和对负样本难度的敏感性。

在微调 BGE-m3 过程中，我们将训练参数设置为：epoch 数量为 1，学习率为 3e-5，在一台带有 V100 芯片的 GPU 上训练，最终获得了微调后的工具召回器模型。

\subsection{评估指标}

我们使用召回率（Recall）\cite{buckland1994relationship, powers2020evaluation}和 NDCG 分数\cite{wang2013theoretical}来衡量微调后的工具召回器的效果。

召回率用于衡量模型对正样本的识别能力，表示在所有实际正类样本中正确识别出的比例。召回率的计算公式为：
\begin{equation}
\text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}
\end{equation}
其中，$\text{TP}$ 表示模型正确预测为正类的样本数量，$\text{FN}$ 表示实际为正类但被模型错误预测为负类的样本数量。较高的召回率意味着模型能够识别出更多的正类样本，但可能导致误报率增加。

NDCG（Normalized Discounted Cumulative Gain）用于评价排序效果，通过对结果的排序位置进行权重衰减，衡量模型在不同相关性得分下的排序质量。NDCG 先计算 DCG（Discounted Cumulative Gain）：
\begin{equation}
\text{DCG}_p = \sum_{i=1}^{p} \frac{\text{rel}_i}{\log_2(i+1)}
\end{equation}
其中，$\text{rel}_i$ 是位置 $i$ 上结果的相关性评分，$i$ 是该结果在列表中的位置，排名越靠前权重越大。为了归一化，NDCG 将 DCG 除以理想状态下的 IDCG（Ideal DCG）：
\begin{equation}
\text{NDCG}_p = \frac{\text{DCG}_p}{\text{IDCG}_p}
\end{equation}
其中 IDCG 是将结果按照最高相关性得分排序后的 DCG 值。NDCG 的值范围在 $0$ 到 $1$ 之间，越接近 $1$ 表示排序效果越理想。本研究中，使用 NDCG@3 和 NDCG@8 分别评估排名前 3 和前 8 个结果的排序效果。

\subsection{基线模型}

为了进一步评估本文提出的面向工具领域的工具召回器微调方法的有效性，
本工作选用开源的其他向量召回模型作为基线模型，包括面向
通用领域的向量召回模型和面向工具召回的向量召回模型，其中面向通用领域的向量召回模型为BGE-m3\cite{chen2024bge}, m3e-base\cite{moka2024m3e}，经过工具数据微调的模型为APIRetriever\cite{Qin2023}。

\subsection{实验结果}

\begin{table}[H]
  \centering
  \bicaption{API工具召回实验结果}{Experiment Results for ToolRetriever}
  \label{tab:comparison}
  \begin{tabular}{l|c|c|c}
    \toprule
    \textbf{方法} & \textbf{Recall@5} & \textbf{NDCG@1} & \textbf{NDCG@5} \\
    \midrule
    m3e-base                  & 64.9 & 62.7 & 71.8 \\
    BGE-m3                    & 63.4 & 66.1 & 73.2 \\
    APIRetriever              & 78.2 & 74.2 & 81.7 \\
    Ours (Simple Negatives)   & 74.9 & 66.7 & 76.5 \\
    Ours (Hard Negatives)     & \textbf{81.3} & \textbf{78.0} & \textbf{89.3} \\ 
    \bottomrule
  \end{tabular}
\end{table}

表 \ref{tab:comparison} 显示了不同方法在召回率（Recall@5）、NDCG@1 和 NDCG@5 指标上的表现。

实验结果显示，我们的方法在多个指标上均取得了显著的性能提升。
在召回率（Recall@5）方面，我们的方法达到了 81.3\%，在所有模型中排名第一。
这表明我们的模型能够更高效地识别出相关工具，在候选工具集合中大幅提高了召回覆盖率。

在关注相关工具排序准确性的 NDCG@1 指标上，我们的方法同样展现了不错的表现。
通过比较，可以发现我们的模型在优先级排序方面优于其他基线方法，这说明们的方法更有可能在首个推荐结果中找到最相关的工具。

对于更广泛的候选工具集范围，我们的方法在NDCG@5上也具有出色的表现，
达到了 89.3\%，相比于基线方法保持了较高的优势。

综上所述，实验结果表明，我们的方法在 API 工具召回任务中取得了显著的性能提升。
特别是在构造了复杂负样本的情况下，各指标有显著提升，该实验结果进一步验证了基于对比学习微调的 BGE-m3 模型在本文的工具召回场景的适用性。

\section{基于工具图谱与深度优先遍历的API编排与调用方法实验}

% \subsection{工具调用数据集构造}

% 为了覆盖不同难度和复杂度的用户需求，我们参考ToolBench中的分类方法，
% 选择了三个不同难度的任务类别：单工具任务、多工具集任务和多类别任务。

% \begin{enumerate}
%   \item \textbf{单工具任务} \\
%     该任务仅涉及一个工具，用户需求仅包含一个工具的调用。这是工具调用中最简单的情况，通常用于测试大语言模型在处理基本指令时的能力。在数据生成过程中，我们直接随机采样一些API，并引导大语言模型生成与这些API相关的用户需求。这种方法不仅能够快速生成数据，还能确保指令的有效性和准确性，适用于初学者或对工具调用不太熟悉的用户。

%   \item \textbf{多工具集任务} \\
%     该任务涉及多个工具集，用户需求需要调用多个工具集中的多个工具。这种任务要求大语言模型具备更高的灵活性和综合能力，能够理解不同工具之间的功能关系。在实现时，我们随机采样来自不同工具集的工具，并将其提供给大语言模型，让其生成用户需求。为了确保生成的需求合理，我们特别考虑了工具组合的有效性。对于那些功能上明显重复或无法自然组合在一起的工具API，大语言模型将直接放弃生成不合逻辑的用户需求，并重新采样一组更合理的API。这种方法有效地增强了模型在实际应用中的适应性，帮助生成更符合真实场景的用户需求。

%   \item \textbf{多类别任务} \\
%     该任务涉及多个类别，用户需求需要调用多个类别的多个工具。这是对大语言模型综合能力的进一步挑战，因为不同类别的工具可能具有不同的功能和用途。在实现过程中，我们同样随机采样来自不同类别的工具，并将其提供给大语言模型，促使其生成多样化的用户需求。这种多类别的设计不仅提高了数据的复杂性，还增强了模型在处理多元化需求时的能力，使其更接近于真实世界的使用场景。

% \end{enumerate}

% 通过上述的方法，我们构建了一个共1000条数据的测试集，其中单工具、多工具集和多类别任务分别占350、350和300条。这种结构化的测试集设计使得我们能够全面评估大语言模型在处理不同复杂度的用户需求时的表现，进而优化模型的生成能力和适应性。经过人工的评估，这种方法具有较高的多样性，能够覆盖到大部分的实际场景。

\subsection{基于工具图的测试数据构造}

由于在本文中我们的重点在于工具之间的依赖关系，那么我们需要针对工具依赖构建测试数据。
在TaskBench\cite{shen2023taskbench}中，作者针对工具图进行了子图采样和反向指令生成构建了丰富的测试数据集，能够区分不同难度的任务，以检测在不同难度任务上模型的效果。
然而，在TaskBench中，作者们使用的图谱较为简单，且多数为模拟工具/多模态工具，不符合本文的通用工具场景。
因此我们通过类似的方法构建了基于工具图的测试数据集，用于测试方法的有效性。

我们首先在工具知识图谱中采样一个工具子图，然后通过大型语言模型（LLM）将采样得到的子图转换为自然语言用户指令，从而构建测试数据集。

具体而言，我们从工具图中抽取子图，并保留抽取工具在原工具图谱中的依赖关系。

我们将得到的工具子图分为两类：简单工具子图和复杂工具子图。简单工具子图为1-2个工具节点组成的工具子图，用于模拟真实世界的简单任务。通过分析，我们发现大部分任务都可以在6个工具之内完成，因此对于复杂工具子图，我们设置为2-6个工具节点组成的工具子图，用于模拟真实世界的复杂任务。

我们将工具子图表示为 \( G_s = \{T_s, E_s\} \)，其中 \( T_s = \{t_{s1}, t_{s2}, \dots, t_{sk}\} \) 并且 \( k < n \)，\( E_s = \{(t_{sa}, t_{sb})\} \)，其中 \( t_{sa} \) 和 \( t_{sb} \) 属于 \( T_s \)。工具子图的抽样过程描述如下：

\[
\text{Sample}(G, \text{type}, \text{n}) \rightarrow G_s
\]

其中，\(\text{type}\) 指定抽样模式（如简单、复杂工具链），\(\text{n}\) 表示工具数量（范围设定为 \(\{1, 2, \dots, 6\}\)）。这些因素决定了用户指令中工具子图的拓扑结构特性和节点数规模。

接下来，基于采样得到的子图 \( G_s \)，我们使用GPT-4o等大型语言模型（LLM）生成用户指令。此过程称为反向指令生成（Back-Instruct)，用于将采样得到的工具子图转换为自然语言用户指令。具体而言，给定一个抽样得到的子图 \( G_s \)，我们定义反向指令生成过程如下，以使 LLMs 能够生成相应的指令：

\[
\text{BackInstruct}(G_s = (T_s, E_s)) \rightarrow \text{Instruction}.
\]

在此过程中，采样得到的子图 \( G_s \) 用于指导LLM生成涵盖相关子任务及其依赖关系的用户请求。该策略保证了生成数据的复杂性和质量。

按照上述数据构造策略，我们共生成了500条数据作为测试集，其中包括300条简单任务和200条复杂任务。


% \subsubsection{数据集评估和筛选}

% 为了评估和验证数据集的质量，我们对生成的数据进行了深入的评估，并根据评估进行了数据集的筛选，以下为评估的具体过程与评估结果。

% 我们参考了\cite{shen2023taskbench}中的三个评估指标：1.自然性 2.复杂性 3.一致性，用于衡量数据集的质量，每项目指标评分为1-5分。

% 我们选择了两种基线方法与该构造的数据进行对比和打分，分别为：。

% 在人工评估中，我们随机抽取了50个样本并对这些样本进行质量评估。为了确保评估的公平和客观性，所有样本都是匿名进行评估的。
% 同时我们提供了详细的打分标准，以校准评估标准，最终结果为三位专家评分的平均值，结果如下表所示\ref{tab:comparison}。

% \begin{table}[h]
%   \centering
%   \bicaption{数据集评估结果对比}{Data Evaluation}
%   \label{tab:comparison}
%   \begin{tabular}{l|c|c|c|c}
%   \toprule
%   \textbf{方法}               & \textbf{自然性↑} & \textbf{复杂性↑} & \textbf{一致性↑} & \textbf{综合评分↑} \\ \midrule
%   构造数据集（我们的方法）   & 3.82             & 3.90             & 3.87             & 3.86              \\ \hline
%   方法 A（简单生成路径）      & 3.34             & 3.40             & 3.28             & 3.34              \\ \hline
%   方法 B（人工设计路径）      & 3.72             & 3.75             & 3.84             & 3.77              \\ 
%   \bottomrule
%   \end{tabular}
% \end{table}

% 最终结果表情该数据集与基线数据集在打分上较为相似，证明了该数据集的有效性和优越性。

\subsection{评估指标}

\noindent \textbf{(1) 无关工具包含率（Irrelevant Tool Inclusion Rate, IR）}
\[
F(s_p) = 
\begin{cases} 
\text{true}, & \text{如果 } s_p \text{ 包含无关工具} \\ 
\text{false}, & \text{否则} 
\end{cases}
\]

\[
IR = \frac{\sum_{i} I(F(S_i^p))}{|S_p|}
\]

\( S_p \) 表示根据我们的方法得到的工具调用路径。  
此指标衡量工具调用路径中包含无关工具的比例。较高的 \( IR \) 值表明该方法更倾向于包含不必要的工具，从而可能引入噪声，导致任务执行失败。该指标用于评估方法在排除无关工具方面的表现。

\noindent \textbf{(2) 有效工具包含率（Necessary Tool Inclusion Rate, NR）}
\[
H(s_p) = 
\begin{cases} 
\text{true}, & \text{如果 } s_p \text{ 包含必要工具} \\ 
\text{false}, & \text{否则} 
\end{cases}
\]

\[
NR = \frac{\sum_{i} H(S_i^p)}{|S_p|}
\]

此指标衡量工具调用路径中是否包含任务所需的所有必要工具。它检查工具路径是否拥有能够解决用户需求的必要工具。较高的 \( NR \) 值表示该方法在工具编排和工具选择方面具有很强的能力。

\noindent \textbf{(3) 整体流程评估（Solution Evaluation, SE）}
\[
W(s_p) = 
\begin{cases} 
\text{true}, & \text{如果 } s_p \text{ 能解决任务} \\ 
\text{false}, & \text{否则} 
\end{cases}
\]

\[
SE = \frac{\sum_{i} I(W(S_i^p))}{|S_p|}
\]

此指标衡量工具执行结果的成功率。只要最终工具总结器的输出能够解决用户的问题，该任务就被视为成功，而不考虑工具调用路径是否包含无关工具、包含多少无关工具。该指标也不考虑参数配置等细节问题，因为该指标成功的前提就是参数配置正确。较高的 \( SE \) 值表明该方法能够为用户请求提供有效工具调用路径。
对于 SE 指标的评估，由于工具响应的实时性，系统输出会根据时间变化，因此不存在一个“Ground Truth”的模型回复。为了评判最终输出的有效性，我们引入了GPT-4o来对自然语言的输出结果进行判别。我们采用了与 \cite{Liu2023a} 中相同的提示词。

为了验证本文场景下该评估器与人类标注者之间的一致性，我们人工标注了 50 条数据并与模型的评估结果进行对比。

\begin{table}[h]
  \centering
  \bicaption{人工标记与 LLM 评估的一致性结果}{Consistency between Evaluator and Human Annotator}
  \label{tab:consistency}
  \begin{tabular}{l|c|c}
  \toprule
  \textbf{Annotation Type} & \textbf{Number of Human-Annotated Samples} & \textbf{Consistency} \\ \midrule
  Solution Evaluation               & 50 samples                                & 87\%                 \\
  \bottomrule
  \end{tabular}
\end{table}

通过对这 50 条标注数据的分析，我们发现评估器在工具调用路径评估（SE）上的结果与人工标注的一致性达到了 87\%。这表明，基于大语言模型的评估器在本文场景下的标注结果与人工标注标准基本一致，具有较高的参考价值。

\subsection{基准线}

本文选用下列方法作为实验的基准方法。

\begin{itemize}
  \item  \textbf{基本提示方法（Vanilla）}。基本提示方法即在大语言模型中直接输入所有候选API的信息，然后要求大语言模型输出需要调用的API的名称和参数等。
  \item  \textbf{思维链方法（CoT）}\cite{Wang2023a}。思维链方式在提示词中加入了“Let's think step by step”的提示信息，引导大语言模型能够进行按步骤的推理。
  \item  \textbf{ReACT方法}\cite{Yao2023b}。ReACT方法通过让大语言模型不断生成Thought和Action，然后将外部的环境反馈也纳入大语言模型的上下文，让模型能够更好地进行规划。
\end{itemize}
\indent

\subsection{实验结果}

在大语言模型的选择上，我们选择了Qwen2.5和GPT-4o作为基础模型，选择原因是这两个模型都具有中英文双语能力，且能够对比开源模型和能力更强的闭源模型在工具能力上的区别。
两个模型的实验均在构建的测试集上进行，并通过上述指标来评判。
实验结果如表 \ref{tab:detailed_evaluation} 所示。

\begin{table}[!ht]
  \centering
  \begin{tabular}{c|c|ccc|ccc}
  \toprule
  \textbf{Model} & \textbf{Method} & \multicolumn{3}{c|}{\textbf{I1-Simple Tasks}} & \multicolumn{3}{c}{\textbf{I2-Hard Tasks}} \\
  & & NR (\%) & IR (\%) & SE (\%) & NR (\%) & IR (\%) & SE (\%) \\
  \midrule
  Qwen2.5-14B & Vanilla          & 58.3 & 38.2 & 50.8 & 41.7 & 42.1 & 38.4 \\
              & CoT              & 65.0 & 32.7 & 62.6 & 44.3 & 39.4 & 41.2 \\
              & ReACT            & 68.4 & 34.3 & 61.4 & 47.2 & 38.3 & 45.1 \\
              & \textbf{Ours}    & \textbf{75.1} $\uparrow$ & \textbf{19.2} $\downarrow$  & \textbf{72.2} $\uparrow$ & \textbf{56.8} $\uparrow$ & \textbf{32.2} $\downarrow$ & \textbf{58.3} $\uparrow$ \\
  \midrule
  GPT-4o   & Vanilla          & 70.5 & 16.3 & 62.1 & 54.3 & 22.4 & 42.2 \\
           & CoT              & 82.9 & 14.6 & 74.2 & 64.8 & 18.5 & 62.3 \\
           & ReACT            & 81.2 & 15.8 & 79.5 & 69.5 & 14.7 & 67.9 \\
           & \textbf{Ours}    & \textbf{88.6} $\uparrow$ & \textbf{7.3} $\downarrow$  & \textbf{87.3} $\uparrow$ & \textbf{77.3} $\uparrow$ & \textbf{10.1} $\downarrow$ & \textbf{81.4} $\uparrow$ \\
  \bottomrule
  \end{tabular}
  \bicaption{不同维度和模型的实验结果}{Results for Pass and Win Metrics for Different Methods}
  \label{tab:detailed_evaluation}
\end{table}

\paragraph{实验结果}

表 \ref{tab:detailed_evaluation} 展示了在两种不同难度的任务上的实验结果。
实验表明，我们的方法在多个关键方面表现出色，具体来说
不管是在Qwen2.5-14B模型还是GPT-4o模型上，该方案的工具调用方案都拥有最低的无关工具包含率（IR）和最高的有效工具包含率（NR），
表明经过该流程得到的工具调用路径具有较高的准确性。在针对整体流程和执行结果方面，我们通过的方法也以最高的分数保持领先。
针对简单任务，我们的方法在Qwen2.5-14B获得了86.1\%的成功率，在GPT-4o获得了88.6\%的成功率。
而针对更多工具、更复杂的复杂任务，我们的方法也能够保持较好的成功率，其中在Qwen2.5-14B上获得了74.3\%的成功率和在GPT-4o上的81.4\%的成功率。

该实验也体现了GPT-4o相比Qwen2.5-14B具有明显的优势，在各指标上都表现更好。
同时，该实验也能明显体现工具调用数量和任务难度之间的区别，在复杂任务上的大部分指标都比简单任务低。

综上所述，以上实验结果验证了本文提出的基于工具图谱和多智能体系统的工具编排与调用方法的有效性。
该策略可以有效利用工具图谱中的信息注入大语言模型智能体，并有效提升其推理其解决复杂任务的能力。

% \subsection{错误分析}
% \label{subsec:error_analysis}

% 尽管本方法在测试中表现良好，但在部分任务上仍存在失败情况。通过分析失败案例，发现主要有以下三类问题：

% \begin{enumerate}
%     \item \textbf{API接口调用错误}：
%     在失败的案例中，有约 26\% 是由于 API接口调用错误造成的。
%     这类错误包括参数缺失、API调用结果错误等。

%     \item \textbf{初始节点候选集问题}：
%     有约 15\% 的失败案例源于初始节点候选集的选择错误。这是由于根据相似度的API召回器未召回到合适的初始节点，导致
%     后续节点选择出现寻找方向错误，或者是有限空间内无法搜索得到目标工具。
%     在本文中已经对API召回器进行了微调，未来可以通过更深入的困难负样本挖掘或者是将用户需求
%     拆解为更细粒度、具体的子任务来解决。

%     \item \textbf{工具幻觉现象}：
%     有28\%的出错用户query出现了“工具幻觉”现象，
%     即模型选择了并不存在或不适合当前任务的工具节点。
%     这种错误选择不仅增加了不必要的token消耗数量，导致了额外计算资源和时间的浪费，
%     还显著降低了任务完成率。

%     \item \textbf{其他错误}：
%     剩余的错误都是由于以上错误组合而成，或是由于其他原因造成的，如路径寻找错误或者是在有限时间内未能找到合适的API路径。

% \end{enumerate}

\section{消融实验}

\subsection{实验设置}

为了验证本文方案中各模块的有效性，我们设计了一系列基于GPT-4o的消融实验，重点分析不同模块对整体系统性能的影响。
实验采用与前文相同的数据集，通过对比去除各模块后的指标变化，全面评估其对系统表现的贡献。
这种设计能够确保实验的代表性与严谨性，同时揭示各模块在提升系统性能中的关键作用。

% 介绍一下每个部分

\subsection{实验结果}

我们依次去除了任务分解器、工具图谱搜索和响应压缩器模块，并记录了其对系统性能的影响。
实验结果如表 \ref{tab:ablation_simple} 和表 \ref{tab:ablation_hard} 所示。
为进一步验证响应压缩模块的作用，我们在此增加了 Token 消耗（Token Consumption）这一指标，以量化其在减少计算资源使用方面的效果。

\begin{table}[!ht]
  \centering
  \begin{tabular}{c|ccc|c}
  \toprule
  \textbf{Experiment Setting} & NR (\%) & IR (\%) & SE (\%) & \textbf{Token Consumption (\# Tokens)} \\
  \midrule
  Full System                   & 88.6 & 7.3  & 87.3  & 4783 \\
  w/o Task Decomposer           & 87.4 & 6.7  & 82.1  & 4520 \\
  w/o Tool Graph Search         & 82.2 & 13.3 & 86.5  & 5632 \\
  w/o Response Compressor       & 87.9 & 7.1  & 89.8  & 15821 \\
  \bottomrule
  \end{tabular}
  \bicaption{消融实验结果（简单任务）}{Ablation Study Results: Simple Tasks (I1)}
  \label{tab:ablation_simple}
\end{table}

\begin{table}[!ht]
  \centering
  \begin{tabular}{c|ccc|c}
  \toprule
  \textbf{Experiment Setting} & NR (\%) & IR (\%) & SE (\%) & \textbf{Token Consumption (\# Tokens)} \\
  \midrule
  Full System                    & 77.3 & 10.1  & 81.4 & 7532 \\
  w/o Task Decomposer            & 65.3 & 12.1  & 71.2 & 7198 \\
  w/o Tool Graph Search          & 56.2 & 10.3  & 68.4 & 8959 \\
  w/o Response Compressor        & 73.8 & 8.9   & 77.9 & 34053 \\
  \bottomrule
  \end{tabular}
  \bicaption{消融实验结果（复杂任务）}{Ablation Study Results: Hard Tasks (I2)}
  \label{tab:ablation_hard}
\end{table}

\subsection{实验分析}

从表 \ref{tab:ablation_simple} 和表 \ref{tab:ablation_hard} 中的实验结果可以看出，各模块对系统性能的贡献存在显著差异。以下是针对不同模块消融实验的详细分析：

去除任务分解器后，无论是简单任务还是复杂任务，在NR和SE均出现明显下降，复杂任务中的NR下降尤其显著（由77.3\%降至65.3\%）。这表明任务分解器在复杂任务中尤为重要，其能够有效拆解任务并明确工具调用逻辑。此外，IR（无关工具包含率）指标在去除任务分解器后略微上升，表明任务分解器对减少无关工具调用具有一定贡献。

去除工具图谱搜索后，简单任务和复杂任务中的NR均显著下降，复杂任务的NR由77.3\%降至56.2\%。这表明工具图谱搜索模块在工具选择的准确性上发挥了关键作用。尽管IR指标在复杂任务中变化不大，但SE指标的下降（由81.4\%降至68.4\%）表明，工具图谱搜索在整体流程的准确性上起到重要作用。

去除响应压缩模块后，Token的开销显著增加，尤其在复杂任务中由平均7532个Token升至34053个Token，这表明响应压缩模块在对API响应进行压缩上发挥了重要作用。此外，在去除了响应压缩模块后，简单任务中的SE略有上升（由87.3\%升至89.8\%），这可能是由于未进行响应压缩时，更多的详细信息被保留。然而在复杂任务中，Token长度的极大增加可能导致引入噪声，影响模型从中识别有效信息，导致SE由81.4\%降至77.9\%。

综上所述，我们发现任务分解器和工具图谱搜索对整体流程的准确性都有不同程度的贡献，而响应压缩模块在减少计算开销和提升响应速度方面有显著作用，同时也对消除噪音、提升准确率有一定作用。消融实验验证了任务分解器、工具图谱搜索和响应压缩器模块的协同作用，这三个模块共同提升了系统的工具调用效率和整体性能。

\section{本章小结}

本章全面分析了基于工具图谱和深度优先遍历策略的 API 调用方法以及 API 召回模型的实验结果。
在工具召回方面，我们提出了一种基于 BGE-m3 模型的对比学习微调方法，通过简单和困难负样本生成有效优化了召回模型的性能。
本文通过在公开工具数据集上开展的详细实验，并与通用向量模型和面向工具召回场景的向量模型等基线模型进行对比，
验证了本文方法的有效性。

此外，我们还对基于工具图谱和多智能系统的API编排与调用方法进行了详细的实验分析，
并与其他基于基线方法进行了比较，
通过在不同难度任务的测试集上进行测试，我们验证了该方法的优越性。
同时，为了检验不同部分在方法中的贡献度，我们设计了一系列消融实验。
实验表明，任务分解模块、工具图谱搜索和响应压缩模块都对整体系统的准确性有重要的作用。

总体而言，本章通过多个实验验证了方法的有效性，该方法为复杂任务中的工具编排与调用提供了高效的工具调用路径。