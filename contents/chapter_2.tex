% !TEX root = ../main.tex

\chapter{相关技术分析}

\section{传统服务编排}

随着互联网技术的快速发展，用户对软件系统需求日益增加。为平衡服务稳定性和需求灵活性，微服务架构应运而生。相比于面向服务的体系架构（Service Oriented Architecture，SOA），微服务架构更注重服务的独立性。每个微服务作为独立单元开发、部署、扩展，通过定义明确的接口提供服务。这种架构大幅提升了软件系统的灵活性与可扩展性。

\subsection{服务编排模式}
在微服务架构中，多个服务协作完成完整业务流程的过程称为服务编排。常见的编排方式有两种：
\begin{itemize}
    \item \textbf{服务编制}：中心化模式，控制中心定义服务的执行流程，各服务无需了解具体组合顺序。
    \begin{figure}[h]
        \centering
        \begin{tikzpicture}[node distance=2cm]
            % Nodes
            \node[draw, circle] (control) {控制中心};
            \node[draw, rectangle, below left of=control] (service1) {服务 1};
            \node[draw, rectangle, below of=control] (service2) {服务 2};
            \node[draw, rectangle, below right of=control] (service3) {服务 3};
            % Arrows
            \draw[->] (control) -- (service1);
            \draw[->] (control) -- (service2);
            \draw[->] (control) -- (service3);
        \end{tikzpicture}
        \bicaption{服务编制模型}{Service Compositon}
        \label{fig:service-composition}
    \end{figure}

    \item \textbf{服务编排}：去中心化模式，服务通过消息队列等机制相互通信，完成资源与信息的交换。
    \begin{figure}[h]
        \centering
        \begin{tikzpicture}[node distance=2cm]
            % Nodes
            \node[draw, rectangle] (service1) {服务 1};
            \node[draw, rectangle, right of=service1] (service2) {服务 2};
            \node[draw, rectangle, right of=service2] (service3) {服务 3};
            \node[draw, rectangle, below of=service2] (queue) {消息队列};
            % Arrows
            \draw[->] (service1) -- (queue);
            \draw[->] (queue) -- (service2);
            \draw[->] (service2) -- (queue);
            \draw[->] (queue) -- (service3);
        \end{tikzpicture}
        \bicaption{服务编排模型}{Service Orchestration}
        \label{fig:service-orchestration}
    \end{figure}
\end{itemize}

两种方式都旨在组合与协调微服务，提供复杂业务支持。

\subsection{服务编排实现方式}
微服务架构提出后，涌现了许多编排工具与语言，例如 BPEL 和 BPMN。
\begin{itemize}
    \item \textbf{BPEL}（Business Process Execution Language）：基于 XML 的标准服务编制语言，用于定义业务流程的抽象和可执行方案。
    \item \textbf{BPMN}（Business Process Model and Notation）：业务流程建模语言，简化了流程设计与实施的沟通，适合流程可视化建模。
\end{itemize}

此外，Netflix Conductor、Zeebe 等流程引擎，以及 Activiti、jBPM 等开源框架，提供了更多编排支持。实际应用中，许多项目采用 BPMN 或 BPEL 结合工作流框架构建微服务系统。

然而，传统方法面临以下挑战：
\begin{enumerate}
    \item \textbf{复杂性与适应性}：如 BPEL 需清晰接口定义，但许多现实 API 接口不规范，若要转为规范定义需人工参与。
    \item \textbf{快速迭代的需求}：由于持续集成等概念的流行，服务编排不仅需要能够静态地组合定义规范的服务，还需要支持快速组合新加入的服务。
    \item \textbf{高门槛与资源消耗}：对于众多且不断变化的业务需求，每次都需要开发人员全程参与，对微服务进行明确定义、对业务流程重新进行编排，需要耗费大量人力。
\end{enumerate}

本项目通过结合大语言模型（LLM）的语义解析能力与知识图谱技术，提出低门槛的服务编排方案。利用 LLM 对用户需求自动解析，结合知识图谱自动生成服务调用流程，减少开发者参与和人力成本。最终目标是实现用户需求驱动的智能化服务编排，提升效率与灵活性，同时降低学习和部署成本。

\section{知识图谱}

\subsection{知识图谱的简介与定义}

知识图谱是一种对现实世界中知识和概念进行建模的技术。虽然“知识图谱”这一术语早在1972年便已出现\cite{schneider1973course}，但现代意义上的知识图谱概念起源于谷歌在2012年发布的 Google Knowledge Graph\cite{singhal2012knowledge,zou2020survey}。
知识图谱采用基于图的数据模型，适用于需要整合、管理和从多样化的数据中提取价值的应用场景\cite{noy2019industry}。
最初，知识图谱旨在增强搜索引擎的理解能力，为用户提供更加智能化的搜索体验。
然而，随着技术的不断发展，知识图谱如今已被广泛应用于人工智能领域，包括语义搜索、推荐系统、大数据分析、智能问答系统等。

在知识图谱中，知识以结构化图的形式表示，其中节点用于表示实体，如人物、地点、事件或抽象概念，
而节点之间的边则表示实体间的语义关系或逻辑关联。
知识图谱的核心单元是三元组 (subject, predicate, object)，
即“头实体-关系-尾实体”。
这种形式化的表达方式使得知识可以在不同系统中共享、分析和推理，为各类人工智能应用提供支持。

\vspace{0.5em}

知识图谱可以形式化地定义为一个有向图 $G = (V, E, R)$，其中：
\begin{itemize}
    \item $V$ 是节点集合，表示知识图谱中的实体或概念；
    \item $E \subseteq V \times R \times V$ 是边集合，表示实体之间的关系；
    \item $R$ 是关系集合，定义了节点之间可能的语义或逻辑关系。
\end{itemize}

每条边 $(h, r, t) \in E$ 表示一个三元组，其中：
\begin{itemize}
    \item $h \in V$ 是头实体（head entity）；
    \item $r \in R$ 是实体之间的关系（relation）；
    \item $t \in V$ 是尾实体（tail entity）。
\end{itemize}

通过这种结构化的三元组表示，知识图谱能够捕获实体及其相互间的复杂关系，支持语义推理、知识查询和知识增强等应用。

\subsection{知识图谱的种类}
知识图谱的发展大致经历了四个阶段\cite{Jiang2023}：

\begin{enumerate}
  \item \textbf{静态知识图谱}: 早期的知识图谱大多都用于存储静态知识，其中的三元组不被更新或不常被更新。
  \item \textbf{动态知识图谱}: 为了保证知识的实时性，知识图谱需要定期被修改或更新。
  \item \textbf{时序知识图谱}: 时序知识图谱中加入了时序信息的表示，能够提供一种更全面的在时序上了解知识的方式。
  \item \textbf{事件知识图谱}: 事件知识图谱的重点在于如何表示和理解事件。事件会涉及不同的实体和关系，而且在特定的时间段发生，这让事件表达变得格外困难。事件知识图谱对图谱的结构进行了修改，加入了表示事件的节点和两种不同的关系形式（实体-事件关系和事件-事件关系）。
\end{enumerate}

\subsection{知识图谱的构建}

知识图谱的构建通常包括
知识抽取、知识融合、知识存储等步骤。

知识抽取是从数据中提取三元组以构建知识图谱的关键过程，直接影响图谱质量。任务包括实体、关系和属性的抽取。早期方法依赖规则模板，成本高且通用性差。深度学习的发展引入了神经网络技术，如卷积神经网络用于关系分类，或联合模型同时完成实体和关系的提取，显著提升了效率和效果。

知识融合整合不同来源的数据，解决重复与冲突问题，构建统一知识库。主要任务包括实体对齐、消歧和指代解析。实体对齐匹配不同数据中的相同实体并补全信息，消歧处理一词多义问题，

知识存储方式主要有关系数据库、RDF 数据库和图数据库。关系型数据库适合存储结构化数据，但对复杂关系查询效率低；RDF 数据库以三元组形式存储知识，表现灵活但占用空间大；图数据库通过高效查询和通过可视化清晰展示实体之间关系，成为目前知识图谱存储的主流选择。

\section{大语言模型}

\subsection{大语言模型的定义}

大语言模型（LLMs）主要指基于Transformer架构的语言模型，
通常具有数十亿到百亿个参数。
LLM通过在海量文本数据上进行预训练，
学习词汇、句法、语义和语境之间的关系，
能够生成和理解复杂的自然语言。
形式化定义如下：

设有一个语言模型 \( \mathcal{M} \)，它通过给定一个输入序列 \( x = (x_1, x_2, \dots, x_n) \) 来预测下一个词或生成输出序列 \( y = (y_1, y_2, \dots, y_m) \)。模型的目标是最大化给定上下文时生成词的联合概率分布 \( P(y_1, y_2, \dots, y_m | x_1, x_2, \dots, x_n) \)。这个联合概率可以通过链式法则表示为：

\[
P(y_1, y_2, \dots, y_m | x_1, x_2, \dots, x_n) = \prod_{i=1}^{m} P(y_i | y_1, \dots, y_{i-1}, x_1, x_2, \dots, x_n)
\]

其中，\( P(y_i | y_1, \dots, y_{i-1}, x_1, x_2, \dots, x_n) \) 是模型在给定先前上下文和输入序列时对 \( y_i \) 的条件概率预测。

随着大语言模型参数量和规模的提升、
以及训练文本量的增大，大语言模型展现出了小模型不具有的“涌现能力”。
比如：（1）上下文学习能力，大语言模型能够从提示词中提供的小规模样本中学习如何完成新任务。
（2）指令遵循能力，在经过指令微调后，大语言模型能够遵循新任务的指令。
（3）复杂推理能力，大语言模型能够通过将复杂任务分解为中间推理步骤来解决复杂任务。
大语言模型还可以通过外部知识和工具调用来增强，以便获得更强大的能力和提升任务的准确性和可靠性。

现有的大模型根据是否开源可以分为两种，第一种是闭源的商业大模型，如：GPT系列\cite{achiam2023gpt, OpenAI2023}，Claude系列\cite{anthropic2023claude3}，Gemini\cite{team2023gemini, team2024gemini}等等，
这些模型的权重不开放给开发者，因此只能通过官方提供的平台或者API接口来使用这些模型；
另一种是开源的大模型，比如：Baichuan\cite{Yang2023}，ChatGLM\cite{Zeng2023}，
Qwen\cite{yang2024qwen2}，LLaMA\cite{Touvron2023}等。
这类模型的效果一般比商业大模型的效果弱一些，但由于是开源的，开发者可以根据具体需求构建数据集对模型有监督的微调等进一步参数调整，也可以部署在本地GPU服务器上。

\subsection{大语言模型提示词工程}

提示词工程是通过创建自然语言指令（Prompt）来从大语言模型中提取知识的过程，已成为提升预训练大语言模型能力的重要技术之一。通过精心设计提示词，可以在不更改模型参数的情况下提高模型输出的表现。与传统方法相比，提示词工程无需对模型进行训练或微调即可实现特定任务上的性能提升，从而有效增强大语言模型在不同领域的适应性和可用性。

目前提示词工程的技术体系十分多样化，涵盖了从最基本的零样本提示（Zero-Shot Prompting）和少样本提示（Few-Shot Prompting）到更复杂的“思维链提示”（Chain of Thought Prompting）等多种方法。
我们可以根据是否提供自然语言文本的参考样本将提示词方法分为以下两种。

\begin{itemize}
    \item \textbf{零样本提示（Zero-Shot Prompting）}：在零样本提示设置（Zero-Shot，Radford等，2019）中，大语言模型完全依赖于在预训练过程中学到的知识，通过提示词中的指令直接执行任务，而无需任何额外的示例数据。该方法的优点在于操作简单，但在任务理解和推理复杂度上往往会受到限制。
    \item \textbf{少样本提示（Few-Shot Prompting）}：在少样本提示设置中（Few-Shot，Brown等，2020），为了更好地理解任务，除了提供任务指令，还会加入少量的示例数据点来帮助模型掌握上下文语境和任务要求。研究表明，精心设计的少样本提示能够显著提升模型的性能，但如果选取的示例不当，模型可能会对这些样本产生难以预料的偏差。少样本提示策略在提示词工程中被视为一种有效的方式，用于提升模型的规划和推理能力。
\end{itemize}

除了根据提示词中的样本数量分类，许多提示词会规定大语言模型用特定的模式来进行，以下是几种针对提升大语言模型在复杂推理任务中的能力而提出的提示策略：

\begin{itemize}
    \item \textbf{基本提示（Basic/Vanilla Prompting）}：基本提示是最基础和最简单的提示词策略，指的是直接向语言模型提供任务，而不进行任何提示词策略的优化。该方法的目标是评估模型在没有提供外部信息时的性能表现。在不同的研究中，基本提示也被称为“标准提示”或“原始提示”，常作为各类提示策略的基础对比。
    \item \textbf{思维链提示（Chain-of-Thought，CoT）}：\cite{Wang2023a}提出了一种思维链提示策略，该策略通过将复杂问题分解为更容易理解的子问题，然后逐步推理并整合各个子问题的解答来得出最终答案。这种方法模拟了人类在解决问题时的逐步推理过程，展示了显式推理链条对复杂任务的性能提升效果。
    \item \textbf{思维树提示（Tree-of-Thought，ToT）}：该提示词框架在思维链的基础上进行扩展，以树状结构管理中间推理步骤，进一步增强了大语言模型在面对复杂任务时的推理能力。思维树结合了模型生成和评估“思维”的能力，并使用了一些常见的搜索算法，如深度优先算法和广度优先算法来在树上进行搜索。在思维树框架下，模型可以系统化地对不同推理路径进行探索，并且在出现错误时能够及时回溯。
    \item \textbf{自我一致性提示（Self-Consistency）}：自我一致性提示通过生成多个回答并选择出现频率最高的答案来提高思维链的表现，有利于提升推理的准确性和一致性。
    \item \textbf{ReAct提示词}：该策略通过将复杂问题分解为更容易理解的子问题，然后逐步推理并整合各个子问题的解答来得出最终答案。在每一步，系统都会生成思维（Thought）、行为（Action）和观察（Observation）三部分的内容，并加入大语言模型的上下文来提示模型进行推理。
\end{itemize}

\subsection{大语言模型智能体}

大语言模型也可以作为“Agent”来为用户提供服务。智能体的概念的最早可以追溯到古希腊时期的哲学家亚里士多德和休谟等人\cite{Zalta2019}。从大体上来讲，智能体可以被定义为“含有欲望、信念、动机和行为能力的实体”\cite{Xi2023}。后来，计算机科学中也用到了智能体这个概念，在人工智能领域中的AI智能体就用来描述具有自主性、主动性、反应性和智能行为能力的实体\cite{Wooldridge1995}。
早期的AI智能体研究主要集中在增强智能体的特定能力上\cite{Sutton2018}，并通过改进相应算法和训练策略来提升它们的表现，而忽略了模型本身如记忆、推理能力的综合能力的提升。
然而，模型本身的能力很大程度上决定了智能体在任务上的表现。

近年来，随着大语言模型的出现，人们发现它们在许多任务上都取得了出色的成绩。大模型具有庞大的模型参数，并且经过在大量数据上的训练，这使得它们具有强大的知识获取能力、规划和推理能力以及泛化性，能够很流畅地与用户进行交互\cite{Wang2023c, TXJS202409001}。
这些能力在智能体中非常有用，因此衍生出了许多基于大模型的智能体研究\cite{Song2023, Ruan2023, JFYZ202411006, ZGXN202404059}，使用大语言模型作为智能体的中央控制器，通过感知环境的变化和不断做出决策，能够很好地解决多种复杂任务。为了使得大语言模型能够不断做出决策和感知环境的变化，搭建大语言模型智能体通常需要使用外部知识获取、工具调用等增强技术。
为了让大语言模型的能力在智能体中得到充分发挥，研究者们设计了不同的模块和架构。OpenAI科学家Lilian Weng在博客\cite{Weng2023}中提出了一个统一的大语言智能体的架构，包含记忆、任务编排和工具使用三个关键模块。

\begin{itemize}
    \item \textbf{记忆}：记忆模块是大模型的整体架构中非常重要的一部分。记忆包括从外界环境感知到的信息和记录在知识库中的记忆，能够指导大模型作出更准确、更快速和更具有一致性的行为。在进行模块设计时，研究者们参考了人类的记忆方式，因此大模型智能体的记忆方式类似人类的短期记忆和长期记忆：大模型智能体的“短期记忆”常常指的是Transformer\cite{Ge2024}架构的上下文窗口输入的内容；而“长期记忆”则用来表示大模型可以随时查询和获取的外界知识库。\cite{Wang2023c}中将大模型常用的记忆方式分为两种：仅使用短期记忆，和记忆混合方式。文中还提到了，由于大部分智能体都需要动态地感知环境的变化，并对环境做出连贯的反应，大部分智能体的实现都要使用短期记忆，因此本文不讨论仅使用长期记忆的模式。
    \item \textbf{任务编排与规划}：在处理复杂任务时，将其分解为更简单的子任务是一种有效的方式。大语言模型的规划模块就希望能够让大模型也具有这样的分解子任务的能力。本文将规划模块的实现方式根据是否有反馈分为两种。无反馈的规划模块一般通过不同的提示词工程技巧、或者不同的路径搜索算法来提升整体的任务规划能力。在复杂且多变的现实场景里，在没有反馈时很难直接生成正确可执行的计划，而在有反馈的规划方式中，智能体在行动后可以得到环境、人类及模型的反馈，并据此修改现有计划，以得到更好的执行结果。 
    \item \textbf{工具使用}：大模型本身具备丰富的内部知识，因此在行为部分，大语言模型既可以使用自身能力的理解任务、做出规划、完成任务，也可以通过外部加入的工具来进一步扩大模型的行为空间。大语言模型可以很好地理解外部工具的作用，并在合适的时候调用工具并对工具返回的结果进行处理，得到最终结果进行输出。
  \end{itemize}

\subsection{大语言模型检索增强生成}

检索增强生成（RAG）是一种通过结合外部知识库而提升大语言模型能力的一种技术\cite{fan2024survey, IGXN202410016}。检索增强技术一般用于知识密集型技术，能够通过相似度检索的方式从外部领域知识库进行检索，从而提升特定任务的准确性和可信度。通过这种方式，可以将模型内部的知识与庞大的、动态的外部知识库进行有机结合，扩大大语言模型的能力范围。

检索增强生成的流程一般有以下三个阶段：索引、检索和生成。索引阶段从对多种格式的原始数据进行清理和提取开始，随后将这些数据转换为统一的纯文本格式。为了适应大语言模型的上下文限制，文本会被划分成较小、易于处理的块。接下来，这些块通过嵌入模型被编码为向量表示，并存储在向量数据库中。这一步骤对于后续检索阶段的高效相似性搜索至关重要。

整个检索增强生成系统由两个核心模块组成：检索器和生成器。检索器从数据存储中搜索相关信息，生成器则生成所需内容。检索增强的过程如下所示：（1）检索器最初接收到输入查询，并搜索相关信息；（2）然后，原始查询和检索结果通过特定的增强方法输入到生成器中；（3）最后，由生成器生成所需的输出内容。

在不同的应用中，我们可以使用不同的生成器模块。在本文我们讨论的是基于大模型的任务，因此生成器为大语言模型。而检索器模块的作用是在给定需求信息的情况下识别并获取相关信息。主流的检索方法可以分为稀疏检索、密集检索两种。不管是稀疏检索还是密集检索，检索的过程可以分为两个阶段：（1）将每个对象编码为特定的表现形式（2）构建索引来对这些搜索对象进行高效检索。

检索的目的是在给定信息需求下识别并获取相关信息，可视为从键值存储中找到最相似的键并获取对应的值。检索方法主要分为稀疏检索和密集检索：

\begin{itemize}
    \item \textbf{稀疏检索}：常用于文档检索，利用词匹配度量（如TF-IDF、BM25）分析文本词频，构建倒排索引进行高效搜索。它也应用于知识图谱，通过关系连接实体，支持k跳邻居搜索或命名实体识别。
    \item \textbf{密集检索}：通过密集嵌入向量表示查询和键，使用近似最近邻（ANN）索引加速搜索，适用于文本、代码、音频、图像等多种数据模态。模型使用对比学习优化检索效果，并利用树结构、局部敏感哈希等索引技术提升搜索效率。
    \item \textbf{其他方法}：一些方法使用自然语言文本的编辑距离直接进行检索，而不计算嵌入表示。在知识图谱中，实体通过关系相连构成图，这些实体之间的关系也相当于预先构建的检索索引。因此，基于知识图谱的检索增强生成方法可以根据实体之间的关系来进行检索，如k跳邻居\cite{Ye2021, Shu2022}。
\end{itemize}

通过检索器的检索，系统得到了与输入信息最为相似的前K个块，这些块将作为扩展上下文用在大语言模型的提示词中。所提出的查询与检索得到的会被整合成一个连贯的提示，以便请求大语言模型生成响应。模型的回答方式可能根据特定任务的标准而有所不同，它可以依赖于自身的参数知识或限制其响应内容仅来自所提供文档。

\subsection{知识图谱与大语言模型相结合}

大语言模型是在大规模语料库上预训练得到的，它们在许多自然语言处理任务上都展示出不错的效果。随着模型的训练数据规模和参数规模的增大，大语言模型能够完成更多复杂的任务。
然而，大语言模型也有许多的局限性。它们的知识范围仅限于训练时用到的语料库\cite{AlKhamissi2022}，无法对知识进行及时的更新。并且大语言模型在很多时候会生成一些与事实不符的回答\cite{Ji2023}，即幻觉现象。在许多专业的领域，幻觉现象极大地限制了大模型的应用。
除此之外，由于计算资源和成本的考虑，大语言模型的上下文长度受限，对长输入的处理仍然是一个问题。

将知识图谱引入大模型能够帮助解决这些问题\cite{zou2020survey, Luo2023, KXTS202310006}，通过引入外部的知识图谱知识，
可以通过动态更新图谱的方式来引入最新知识。
此外，将庞大的知识库转化为结构化的知识图谱后，每次可以根据不同需求在图上进行搜索\cite{Ma2024, Ma2024}得到准确性知识。

将大语言模型和知识图谱联合起来的方式能够同时增强它们两者的能力。在知识图谱增强的大语言模型中，知识图谱既可以在预训练和推理的时候提供知识\cite{Zhang2019}，又可以增强大语言模型的可解释性\cite{Lin2019}。在大语言模型增强的知识图谱中，大语言模型可以用在知识图谱的不同任务中来辅助知识图谱的应用。而在大语言模型和知识图谱的融合系统中，研究者们将大语言模型和知识图谱的优点相结合，用于增强知识表达\cite{Yasunaga2022}和推理\cite{Choudhary2023}。

\section{工程技术}

\subsection{Neo4j图数据库}

Neo4j是一种高性能的NoSQL图数据库，最早于2003年开发，并于2007年发布。作为当前领先的图数据库之一，Neo4j基于属性图模型，能够以键值对的形式存储节点和节点之间的关系，极大地增强了图数据模型的表现能力。其专属查询语言Cypher具备直观、高效的特点，方便用户对图数据进行快速查询和操作。

Neo4j采用原生图形处理引擎（GPE），具备完整的ACID事务支持，确保了数据操作的原子性、一致性、隔离性和持久性。此外，它提供了REST API，使得用户能够通过多种编程语言方便地访问数据库。这使得Neo4j在处理连接密集型数据时具有显著优势，尤其适用于表示半结构化数据、快速检索和导航复杂关系网络。Neo4j的数据浏览器还支持将查询结果导出为JSON或XLS格式，为用户提供了灵活的操作和集成能力。 

\subsection{Qdrant向量数据库}

Qdrant是一款开源的高性能向量数据库，专为下一代AI应用而设计。它采用云原生架构，并通过RESTful和gRPC API支持向量的管理和检索。Qdrant的核心特点在于其高效的高维向量存储和查询能力，特别适用于语义搜索和推荐系统等场景。通过将向量嵌入与附加的元数据结合，Qdrant提供了更灵活的过滤和搜索选项。

该数据库能够支持数十亿个数据点的存储与查询，同时具备实时分析的能力。在性能方面，Qdrant采用先进的索引技术，例如HNSW来实现高效的近似最近邻搜索。用户可以根据具体需求选择多种相似度计算方式，包括欧式距离、余弦相似度和点积。

\subsection{LangChain}

LangChain是一个专为开发大语言模型（LLMs）驱动的应用程序而设计的框架，旨在简化应用程序的整个生命周期，从开发到生产化的各个环节。LangChain提供了一系列开源构建模块、组件及第三方集成，方便开发者构建应用。这些核心库包括基本抽象和LangChain表达语言，以及与第三方服务的集成，使开发者能够高效构建应用的认知架构。

LangChain的组件具有模块化和易用性，开发者可以选择是否使用整个框架。内置的现成链简化了入门过程，帮助开发者快速上手，同时也允许灵活自定义现有链或构建新的链，以满足特定的应用需求。

\subsection{LangGraph}

LangGraph 是一个灵活的库，在 LangChain 的基础上，通过引入图结构，使开发者可以设计更加复杂的工作流和多Agent架构。它的关键特点包括：它支持循环、分支控制和状态持久化，能够实现更复杂的代理工作流。LangGraph 的核心功能包括循环与条件分支的实现、自动状态保存、人机协作、以及流式输出支持。LangGraph 可与 LangChain 无缝集成，也可独立使用。

\subsection{本章小结}
本章主要介绍了与本课题相关的技术背景。首先阐述了知识图谱的起源与定义，并概述了不同类别的知识图谱及其应用方式。接着，介绍了大语言模型的基本概念、核心技术，以及其在智能体、提示词工程和检索增强生成中的具体应用。最后，讨论了如何将知识图谱与大语言模型相结合，以提升其在各类任务中的表现。