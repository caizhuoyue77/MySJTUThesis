% !TEX root = ../main.tex

\chapter{相关技术分析}

\section{知识图谱}

\subsection{知识图谱的概念}
知识图谱是一种对于现实世界中的知识和概念的建模。知识图谱的概念最早由谷歌于2012年提出，最初旨在用于构建更智能的搜索引擎。然而，如今知识图谱已经成为人工智能领域中常用的知识表达和存储技术，能够将大量的非结构化知识组织成结构化形式，并被广泛应用于搜索引擎、问答系统和推荐系统等人工智能应用中。

在知识图谱中，知识以图形、结构等可视化方式存储，其中图中的节点代表实体，用于描述真实世界中的物体或抽象概念，而节点之间的边则表示实体之间的语义或逻辑关系。知识图谱的基本组成单位是三元组，包括头实体、关系和尾实体。这种基本结构为知识图谱的构建和应用提供了坚实的基础。

\subsection{知识图谱的种类}
知识图谱的发展大致经历了四个阶段\cite{Jiang2023}：

\begin{enumerate}
  \item \textbf{静态知识图谱}: 早期的知识图谱大多都用于存储静态知识，其中的三元组不被更新或不常被更新。
  \item \textbf{动态知识图谱}: 为了保证知识的实时性，知识图谱需要定期被修改或更新。
  \item \textbf{时序知识图谱}: 时序知识图谱中加入了时序信息的表示，能够提供一种更全面的在时序上了解知识的方式。
  \item \textbf{事件知识图谱}: 事件知识图谱的重点在于如何表示和理解事件。事件会涉及不同的实体和关系，而且在特定的时间段发生，这让事件表达变得格外困难。事件知识图谱对图谱的结构进行了修改，加入了表示事件的节点和两种不同的关系形式（实体-事件关系和事件-事件关系）。
\end{enumerate}

\subsection{API知识图谱}

本研究主要针对的场景是通过将不同工具进行组合来完成特定任务。API有关的知识通常存在于不同信息源中，比如官方参考文档、问答网站等非结构化的文本中\cite{Ma}。同时，API之间的依赖关系属于过程性知识。过程性知识是一种关于“怎么做”的知识，是一种没有明确提取线索，只能借助某种活动形式间接推出来的知识。在本研究的场景中，我们需要把API有关知识提供给大语言模型，让模型针对任务描述选择合适的API和API调用顺序。

由于大语言模型上下文长度有限，难以把所有的API相关信息都以提示词的方式提供给大语言模型。而且大语言模型本质上还是一个黑盒，在输入了API有关信息之后，无法预测它的输出是否涵盖了我们需要的API知识，以及这些知识是否准确、全面。而且，API之间的依赖关系在任务编排时十分重要，如何正确表达并查询API的依赖关系是本研究的关键问题之一。

知识图谱能够结构化地表示信息之间的语义关联，能够用于API的知识表示。\cite{Liu2019}中，作者们从API参考文档和维基百科中提取相关知识，构建API知识图谱。\cite{Li2018}中从API参考文档和API教程中提取警告语句，构建API警告知识图谱。\cite{Ling2019}以开源项目中的API为实体，以API之间的调用、返回、实现等为关系，构建基于开源项目的API知识图谱。\cite{Wang2021}中，作者设计了一个仅包含三种实体的知识图谱，在图上使用随机游走等算法来实现API的推荐。

\section{大语言模型}

\subsection{大语言模型的定义}

大语言模型（LLMs）主要指基于Transformer架构的语言模型，这些模型包含数十亿到百亿个参数，并在海量的预训练文本数据上进行训练。相比起预训练语言模型（PLMs），大语言模型具有更大的模型规模，并具有更强的语言理解能力和生成能力。更重要的是，随着模型参数量和规模的提升、以及训练文本量的增大，大语言模型展现出了小模型不具有的“涌现能力”。比如：（1）上下文学习能力，大语言模型能够从提示词中提供的小规模样本中学习如何完成新任务。（2）指令遵循能力，在经过指令微调后，大语言模型能够遵循新任务的指令。（3）复杂推理能力，大语言模型能够通过将复杂任务分解为中间推理步骤来解决复杂任务。大语言模型还可以通过外部知识和工具调用来增强，以便获得更强大的能力和提升任务的准确性和可靠性。

现有的大模型基本分为两种，第一种是闭源的商业大模型，比如：ChatGPT，GPT-4\cite{OpenAI2023}，Claude-3.5，Gemini-2等等，用户和开发者可以通过官方提供的平台或者API接口来使用这些模型；另一种是开源的大模型，比如：Baichuan\cite{Yang2023}，ChatGLM\cite{Zeng2023}，Qwen，LLaMA\cite{Touvron2023}等。这类模型的效果一般比商业大模型的效果弱一些，但由于是开源的，开发者可以根据具体需求构建数据集对模型有监督的微调等进一步参数调整。

\subsection{大语言模型提示词工程}

提示词工程是通过创建自然语言指令（即提示词）来从大型语言模型中提取知识的过程，已成为提升预训练大型语言模型能力的重要技术之一。通过精心设计提示词，可以在不更改模型参数的情况下提高模型输出的表现。与传统方法相比，提示词工程无需对模型进行训练或微调即可实现特定任务上的性能提升，从而有效增强大型语言模型在不同领域的适应性和可用性。

目前提示词工程的技术体系十分多样化，涵盖了从最基本的零样本提示（Zero-Shot Prompting）和少样本提示（Few-Shot Prompting）到更复杂的“思维链提示”（Chain of Thought Prompting）等多种方法。

\begin{itemize}
    \item \textbf{零样本提示（Zero-Shot Prompting）}：在零样本提示设置（Zero-Shot，Radford等，2019）中，大型语言模型完全依赖于在预训练过程中学到的知识，通过提示词中的指令直接执行任务，而无需任何额外的示例数据。该方法的优点在于操作简单，但在任务理解和推理复杂度上往往会受到限制。
    \item \textbf{少样本提示（Few-Shot Prompting）}：在少样本提示设置中（Few-Shot，Brown等，2020），为了更好地理解任务，除了提供任务指令，还会加入少量的示例数据点来帮助模型掌握上下文语境和任务要求。研究表明，精心设计的少样本提示能够显著提升模型的性能，但如果选取的示例不当，模型可能会对这些样本产生难以预料的偏差。少样本提示策略在提示词工程中被视为一种有效的方式，用于提升模型的规划和推理能力。
\end{itemize}

以下是几种针对提升大型语言模型在复杂推理任务中的能力而提出的提示策略：

\begin{itemize}
    \item \textbf{基本提示（Basic/Vanilla Prompting）}：基本提示是最基础和最简单的提示词策略，指的是直接向语言模型提供任务，而不进行任何提示词策略的优化。该方法的目标是评估模型在没有提供外部信息时的性能表现。在不同的研究中，基本提示也被称为“标准提示”或“原始提示”，常作为各类提示策略的基础对比。
    \item \textbf{思维链提示（Chain-of-Thought，CoT）}：\cite{Wang2023a}提出了一种思维链提示策略，该策略通过将复杂问题分解为更容易理解的子问题，然后逐步推理并整合各个子问题的解答来得出最终答案。这种方法模拟了人类在解决问题时的逐步推理过程，展示了显式推理链条对复杂任务的性能提升效果。
    \item \textbf{思维树提示（Tree-of-Thought，ToT）}：该提示词框架在思维链的基础上进行扩展，以树状结构管理中间推理步骤，进一步增强了大语言模型在面对复杂任务时的推理能力。思维树结合了模型生成和评估“思维”的能力，并使用了一些常见的搜索算法，如深度优先算法和广度优先算法来在树上进行搜索。在思维树框架下，模型可以系统化地对不同推理路径进行探索，并且在出现错误时能够及时回溯。
    \item \textbf{自我一致性提示（Self-Consistency）}：自我一致性提示通过生成多个回答并选择出现频率最高的答案来提高思维链的表现，有利于提升推理的准确性和一致性。
    \item \textbf{ReAct提示词}：该策略通过将复杂问题分解为更容易理解的子问题，然后逐步推理并整合各个子问题的解答来得出最终答案。在每一步，系统都会生成思维（Thought）、行为（Action）和观察（Observation）三部分的内容，并加入大语言模型的上下文来提示模型进行推理。
\end{itemize}

\subsection{大语言模型智能体}

大语言模型也可以作为“智能体”来为用户提供服务。智能体的概念的最早可以追溯到古希腊时期的哲学家亚里士多德和休谟等人\cite{Zalta2019}。从大体上来讲，智能体可以被定义为“含有欲望、信念、动机和行为能力的实体”\cite{Xi2023}。后来，计算机科学中也用到了智能体这个概念，在人工智能领域中的AI智能体就用来描述具有自主性、主动性、反应性和智能行为能力的实体\cite{Wooldridge1995}。早期的AI智能体研究主要集中在增强智能体的特定能力上\cite{Sutton2018}，并通过改进相应算法和训练策略来提升它们的表现，而忽略了模型本身如记忆、推理能力的综合能力的提升。然而，模型本身的能力很大程度上决定了智能体在任务上的表现。

近年来，随着大语言模型的出现，人们发现它们在许多任务上都取得了出色的成绩。大模型具有庞大的模型参数，并且经过在大量数据上的训练，这使得它们具有强大的知识获取能力、规划和推理能力以及泛化性，能够很流畅地与用户进行交互\cite{Wang2023c}。这些能力在AI智能体中非常有用，因此衍生出了许多基于大模型的智能体研究，使用大语言模型作为智能体的中央控制器，通过感知环境的变化和不断做出决策，能够很好地解决多种复杂任务。为了使得大语言模型能够不断做出决策和感知环境的变化，搭建大语言模型智能体通常需要使用外部知识获取、工具调用等增强技术。为了让大语言模型的能力在智能体中得到充分发挥，研究者们设计了不同的模块和架构。OpenAI科学家Lilian Weng在博客\cite{Weng2023}中提出了一个统一的大语言智能体的架构，包含记忆、任务编排和工具使用三个关键模块。

\begin{itemize}
    \item \textbf{记忆}：记忆模块是大模型的整体架构中非常重要的一部分。记忆包括从外界环境感知到的信息和记录在知识库中的记忆，能够指导大模型作出更准确、更快速和更具有一致性的行为。在进行模块设计时，研究者们参考了人类的记忆方式，因此大模型智能体的记忆方式类似人类的短期记忆和长期记忆：大模型智能体的“短期记忆”常常指的是Transformer\cite{Ge2024}架构的上下文窗口输入的内容；而“长期记忆”则用来表示大模型可以随时查询和获取的外界知识库。\cite{Wang2023}中将大模型常用的记忆方式分为两种：仅使用短期记忆，和长短期记忆混合方式。文中还提到了，由于大部分智能体都需要动态地感知环境的变化，并对环境做出连贯的反应，大部分智能体的实现都要使用短期记忆，因此本文不讨论仅使用长期记忆的模式。
    \item \textbf{任务编排与规划}：在处理复杂任务时，将其分解为更简单的子任务是一种有效的方式。大语言模型的规划模块就希望能够让大模型也具有这样的分解子任务的能力。本文将规划模块的实现方式根据是否有反馈分为两种。无反馈的规划模块一般通过不同的提示词工程技巧、或者不同的路径搜索算法来提升整体的任务规划能力。在复杂且多变的现实场景里，在没有反馈时很难直接生成正确可执行的计划，而在有反馈的规划方式中，智能体在行动后可以得到环境、人类及模型的反馈，并据此修改现有计划，以得到更好的执行结果。 
    \item \textbf{工具使用}：大模型本身具备丰富的内部知识，因此在行为部分，大语言模型既可以使用自身能力的理解任务、做出规划、完成任务，也可以通过外部加入的工具来进一步扩大模型的行为空间。大语言模型可以很好地理解外部工具的作用，并在合适的时候调用工具并对工具返回的结果进行处理，得到最终结果进行输出。
  \end{itemize}

\subsection{大语言模型检索增强生成}
检索增强生成（RAG）是一种通过结合外部知识库而提升大语言模型能力的一种技术。检索增强技术一般用于知识密集型技术，能够通过相似度检索的方式从外部领域知识库进行检索，从而提升特定任务的准确性和可信度。通过这种方式，可以将模型内部的知识与庞大的、动态的外部知识库进行有机结合，扩大大语言模型的能力范围。

检索增强生成的流程一般有以下三个阶段：索引、检索和生成。索引阶段从对多种格式的原始数据进行清理和提取开始，随后将这些数据转换为统一的纯文本格式。为了适应大语言模型的上下文限制，文本会被划分成较小、易于处理的块。接下来，这些块通过嵌入模型被编码为向量表示，并存储在向量数据库中。这一步骤对于后续检索阶段的高效相似性搜索至关重要。

整个检索增强生成系统由两个核心模块组成：检索器和生成器。检索器从数据存储中搜索相关信息，生成器则生成所需内容。检索增强的过程如下所示：（1）检索器最初接收到输入查询，并搜索相关信息；（2）然后，原始查询和检索结果通过特定的增强方法输入到生成器中；（3）最后，由生成器生成所需的输出内容。

在不同的应用中，我们可以使用不同的生成器模块。在本文我们讨论的是基于大模型的任务，因此生成器为大语言模型。而检索器模块的作用是在给定需求信息的情况下识别并获取相关信息。主流的检索方法可以分为稀疏检索、密集检索两种。不管是稀疏检索还是密集检索，检索的过程可以分为两个阶段：（1）将每个对象编码为特定的表现形式（2）构建索引来对这些搜索对象进行高效检索。

检索的目的是在给定信息需求下识别并获取相关信息，可视为从键值存储中找到最相似的键并获取对应的值。检索方法主要分为稀疏检索和密集检索：

\begin{itemize}
    \item \textbf{稀疏检索}：常用于文档检索，利用词匹配度量（如TF-IDF、BM25）分析文本词频，构建倒排索引进行高效搜索。它也应用于知识图谱，通过关系连接实体，支持k跳邻居搜索或命名实体识别（NER）。
    \item \textbf{密集检索}：通过密集嵌入向量表示查询和键，使用近似最近邻（ANN）索引加速搜索，适用于文本、代码、音频、图像等多种数据模态。模型使用对比学习优化检索效果，并利用树结构、局部敏感哈希等索引技术提升搜索效率。
    \item \textbf{其他方法}：一些方法使用自然语言文本的编辑距离直接进行检索，而不计算嵌入表示。在知识图谱中，实体通过关系相连构成图，这些实体之间的关系也相当于预先构建的检索索引。因此，基于知识图谱的检索增强生成方法可以采用k跳邻居\cite{Ye2021, Shu2022}。
\end{itemize}

通过检索器的检索，系统得到了与输入信息最为相似的前K个块，这些块将作为扩展上下文用在大语言模型的提示词中。所提出的查询与检索得到的会被整合成一个连贯的提示，以便请求大型语言模型生成响应。模型的回答方式可能根据特定任务的标准而有所不同，它可以依赖于自身的参数知识或限制其响应内容仅来自所提供文档。

知识图谱也逐渐被集成到检索增强系统中。知识图谱以三元组的形式存储实体及其关系，能够以更紧凑的方式表达世界知识。相比于文档，知识图谱提供的知识更加结构化、明确，可以帮助减少冗余信息。在问答任务中，使用KG的检索增强生成实现可以显著提高最终结果的正确率，大语言模型可以很好地利用知识图谱中搜索得到的结构化准确知识，生成准确性、鲁棒性更高的回答。

\subsection{知识图谱与大语言模型相结合}

大语言模型是在大规模语料库上预训练得到的，它们在许多自然语言处理任务上都展示出不错的效果。随着模型的训练数据规模和参数规模的增大，大语言模型能够完成更多复杂的任务。然而，大语言模型也有许多的局限性。它们的知识范围仅限于训练时用到的语料库\cite{AlKhamissi2022}，无法对知识进行及时的更新。并且大语言模型在很多时候会生成一些与事实不符的回答\cite{Ji2023}，即幻觉现象。在许多专业的领域，幻觉现象极大地限制了大模型的应用。除此之外，由于计算资源和成本的考虑，大语言模型的上下文长度受限，对长输入的处理仍然是一个问题。

将知识图谱引入大模型能够帮助解决这些问题，通过引入外部的知识图谱知识，可以通过动态更新图谱的方式来引入最新知识。此外，将庞大的知识库转化为结构化的知识图谱后，每次可以根据不同需求进行搜索，得到，来保证准确可靠的领域知识。如何有效地对现实世界的事实进行建模是一个关键问题。现有的图谱构建方法通常由人工构建，缺乏足够的泛化能力，因此有必要利用大语言模型来辅助图谱的构建过程。

将大语言模型和知识图谱联合起来的方式能够同时增强它们两者的能力。在知识图谱增强的大语言模型中，知识图谱既可以在预训练和推理的时候提供知识\cite{Zhang2019}，又可以增强大语言模型的可解释性\cite{Lin2019}。在大语言模型增强的知识图谱中，大语言模型可以用在知识图谱的不同任务中来辅助知识图谱的应用。而在大语言模型和知识图谱的融合系统中，研究者们将大语言模型和知识图谱的优点相结合，用于增强知识表达\cite{Yasunaga2022}和推理\cite{Choudhary2023}。

\section{工程技术}

\subsection{Neo4j图数据库}

Neo4j是一种高性能的NoSQL图数据库，最早于2003年开发，并于2007年发布。作为当前领先的图数据库之一，Neo4j基于属性图模型，能够以键值对的形式存储节点和节点之间的关系，极大地增强了图数据模型的表现能力。其专属查询语言Cypher具备直观、高效的特点，方便用户对图数据进行快速查询和操作。

Neo4j采用原生图形处理引擎（GPE），具备完整的ACID事务支持，确保了数据操作的原子性、一致性、隔离性和持久性。此外，它提供了REST API，使得用户能够通过多种编程语言方便地访问数据库，支持两种Java API：Cypher API和原生Java API。这使得Neo4j在处理连接密集型数据时具有显著优势，尤其适用于表示半结构化数据、快速检索和导航复杂关系网络。Neo4j的数据浏览器还支持将查询结果导出为JSON或XLS格式，为用户提供了灵活的操作和集成能力。

\subsection{Qdrant向量数据库}

Qdrant是一款开源的高性能向量数据库，专为下一代AI应用而设计。它采用云原生架构，并通过RESTful和gRPC API支持向量的管理和检索。Qdrant的核心特点在于其高效的高维向量存储和查询能力，特别适用于语义搜索和推荐系统等场景。通过将向量嵌入与附加的元数据结合，Qdrant提供了更灵活的过滤和搜索选项。

该数据库能够支持数十亿个数据点的存储与查询，同时具备实时分析的能力。在性能方面，Qdrant采用先进的索引技术，例如层次式可导航小世界（HNSW），实现高效的近似最近邻搜索。用户可以根据具体需求选择多种相似度度量标准，包括欧式距离、余弦相似度和点积。这些度量标准确保了Qdrant在相似性搜索中既快速又准确，有效满足AI和机器学习应用的需求。

\subsection{LangChain}

LangChain是一个专为开发大型语言模型（LLMs）驱动的应用程序而设计的框架，旨在简化应用程序的整个生命周期，从开发到生产化的各个环节。LangChain提供了一系列开源构建模块、组件及第三方集成，方便开发者构建应用。这些核心库包括基本抽象和LangChain表达语言，以及与第三方服务的集成，使开发者能够高效构建应用的认知架构。

LangChain的组件具有模块化和易用性，开发者可以选择是否使用整个框架。内置的现成链简化了入门过程，帮助开发者快速上手，同时也允许灵活自定义现有链或构建新的链，以满足特定的应用需求。

\subsection{本章小结}
本章介绍了大语言模型的基本概念、相关技术与其在智能体、提示词工程、检索增强生成中的应用，并讨论了如何将知识图谱与大语言模型相结合来提升其在不同任务中的表现。