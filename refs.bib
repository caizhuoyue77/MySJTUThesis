@inproceedings{Li2018,
   author = {Hongwei Li and Sirui Li and Jiamou Sun and Zhenchang Xing and Xin Peng and Mingwei Liu and Xuejiao Zhao},
   booktitle = {2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
   pages = {183-193},
   title = {Improving api caveats accessibility by mining api caveats knowledge graph},
   year = {2018},
}

@article{Jiang2023,
   abstract = {Knowledge graphs (KGs) are structured representations of diversified knowledge. They are widely used in various intelligent applications. In this article, we provide a comprehensive survey on the evolution of various types of knowledge graphs (i.e., static KGs, dynamic KGs, temporal KGs, and event KGs) and techniques for knowledge extraction and reasoning. Furthermore, we introduce the practical applications of different types of KGs, including a case study in financial analysis. Finally, we propose our perspective on the future directions of knowledge engineering, including the potential of combining the power of knowledge graphs and large language models (LLMs), and the evolution of knowledge extraction, reasoning, and representation.},
   author = {Xuhui Jiang and Chengjin Xu and Yinghan Shen and Xun Sun and Lumingyuan Tang and Saizhuo Wang and Zhongwu Chen and Yuanzhuo Wang and Jian Guo},
   month = {10},
   title = {On the Evolution of Knowledge Graphs: A Survey and Perspective},
   year = {2023},
}

@article{hogan2021knowledge,
  title={Knowledge graphs},
  author={Hogan, Aidan and Blomqvist, Eva and Cochez, Michael and d’Amato, Claudia and Melo, Gerard De and Gutierrez, Claudio and Kirrane, Sabrina and Gayo, Jos{\'e} Emilio Labra and Navigli, Roberto and Neumaier, Sebastian and others},
  journal={ACM Computing Surveys (Csur)},
  volume={54},
  number={4},
  pages={1--37},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@inproceedings{schneider1973course,
  author    = {E. W. Schneider},
  title     = {Course modularization applied: The interface system and its implications for sequence control and data analysis},
  booktitle = {Proceedings of ADIS},
  year      = {1973}
}

@misc{singhal2012knowledge,
  author       = {A. Singhal},
  title        = {Introducing the Knowledge Graph: Things, not strings},
  howpublished = {Google Blog},
  year         = {2012},
  note         = {Retrieved from \url{https://www.blog.google/products/search/introducing-knowledge-graph-things-not/}}
}

@article{noy2019industry,
  title={Industry-scale Knowledge Graphs: Lessons and Challenges: Five diverse technology companies show how it’s done},
  author={Noy, Natasha and Gao, Yuqing and Jain, Anshu and Narayanan, Anant and Patterson, Alan and Taylor, Jamie},
  journal={Queue},
  volume={17},
  number={2},
  pages={48--75},
  year={2019},
  publisher={ACM New York, NY, USA}
}

@inproceedings{zou2020survey,
  title={A survey on application of knowledge graph},
  author={Zou, Xiaohan},
  booktitle={Journal of Physics: Conference Series},
  volume={1487},
  number={1},
  pages={012016},
  year={2020},
  organization={IOP Publishing}
}

@article{yang2024qwen2,
  title={Qwen2 technical report},
  author={Yang, An and Yang, Baosong and Hui, Binyuan and Zheng, Bo and Yu, Bowen and Zhou, Chang and Li, Chengpeng and Li, Chengyuan and Liu, Dayiheng and Huang, Fei and others},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{team2024gemini,
  title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context},
  author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
  journal={arXiv preprint arXiv:2403.05530},
  year={2024}
}

@misc{anthropic2023claude3,
  author       = {Anthropic},
  title        = {Claude 3 (Oct 8 version) [Large language model]},
  howpublished = {\url{https://www.anthropic.com/}},
  year         = {2023},
  note         = {Accessed: 2024-11-19},
  abstract     = {We introduce Claude 3, a new family of large multimodal models – Claude 3 Opus, our
most capable offering, Claude 3 Sonnet, which provides a combination of skills and speed,
and Claude 3 Haiku, our fastest and least expensive model. All new models have vision
capabilities that enable them to process and analyze image data. The Claude 3 family
demonstrates strong performance across benchmark evaluations and sets a new standard on
measures of reasoning, math, and coding. Claude 3 Opus achieves state-of-the-art results
on evaluations like GPQA, MMLU, MMMU, and many more. Claude 3 Haiku performs as well or better than Claude 2 on most pure-text tasks, while Sonnet and Opus significantly outperform it. Additionally, these models exhibit improved fluency in non-English languages, making them more versatile for a global audience. In this report, we provide an in-depth analysis of our evaluations, focusing on core capabilities, safety, societal impacts, and the catastrophic risk assessments we committed to in our Responsible Scaling Policy.}
}

@inproceedings{Liu2019,
   author = {Mingwei Liu and Xin Peng and Andrian Marcus and Zhenchang Xing and Wenkai Xie and Shuangshuang Xing and Yang Liu},
   booktitle = {Proceedings of the 2019 27th ACM joint meeting on European software engineering conference and symposium on the foundations of software engineering},
   pages = {120-130},
   title = {Generating query-specific class API summaries},
   year = {2019},
}

@inproceedings{fan2024survey,
  title={A survey on rag meeting llms: Towards retrieval-augmented large language models},
  author={Fan, Wenqi and Ding, Yujuan and Ning, Liangbo and Wang, Shijie and Li, Hengyun and Yin, Dawei and Chua, Tat-Seng and Li, Qing},
  booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={6491--6501},
  year={2024}
}

@article{shen2023taskbench,
  title={Taskbench: Benchmarking large language models for task automation},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Zhang, Wenqi and Ren, Kan and Yuan, Siyu and Lu, Weiming and Li, Dongsheng and Zhuang, Yueting},
  journal={arXiv preprint arXiv:2311.18760},
  year={2023}
}

@inproceedings{ma2025m,
  title={m \&m’s: A Benchmark to Evaluate Tool-Use for multi-step multi-modal Tasks},
  author={Ma, Zixian and Huang, Weikai and Zhang, Jieyu and Gupta, Tanmay and Krishna, Ranjay},
  booktitle={European Conference on Computer Vision},
  pages={18--34},
  year={2025},
  organization={Springer}
}

@article{Shen2023,
   abstract = {Solving complicated AI tasks with different domains and modalities is a key step toward artificial general intelligence. While there are numerous AI models available for various domains and modalities, they cannot handle complicated AI tasks autonomously. Considering large language models (LLMs) have exhibited exceptional abilities in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks, with language serving as a generic interface to empower this. Based on this philosophy, we present HuggingGPT, an LLM-powered agent that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., Hugging Face) to solve AI tasks. Specifically, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in Hugging Face, execute each subtask with the selected AI model, and summarize the response according to the execution results. By leveraging the strong language capability of ChatGPT and abundant AI models in Hugging Face, HuggingGPT can tackle a wide range of sophisticated AI tasks spanning different modalities and domains and achieve impressive results in language, vision, speech, and other challenging tasks, which paves a new way towards the realization of artificial general intelligence.},
   author = {Yongliang Shen and Kaitao Song and Xu Tan and Dongsheng Li and Weiming Lu and Yueting Zhuang and Zhejiang University and Microsoft Research Asia},
   month = {3},
   title = {HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face},
   url = {https://arxiv.org/abs/2303.17580v4},
   year = {2023},
}

@article{Tang2023,
   abstract = {Enabling large language models to utilize real-world tools effectively is crucial for achieving embodied intelligence. Existing approaches to tool learning have either primarily relied on extremely large language models, such as GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or utilized supervised learning to train limited scopes of tools on compact models. However, it remains uncertain whether smaller language models can achieve generalized tool-use abilities without tool-specific training. To address this question, this paper introduces ToolAlpaca, a novel framework designed to automatically generate a diverse tool-use corpus and learn generalized tool-use abilities on compact language models with minimal human intervention. Specifically, ToolAlpaca first automatically creates a highly diversified tool-use corpus by building a multi-agent simulation environment. The corpus contains 3938 tool-use instances from more than 400 real-world tool APIs spanning 50 distinct categories. Subsequently, the constructed corpus is employed to fine-tune compact language models, resulting in two models, namely ToolAlpaca-7B and ToolAlpaca-13B, respectively. Finally, we evaluate the ability of these models to utilize previously unseen tools without specific training. Experimental results demonstrate that ToolAlpaca achieves effective generalized tool-use capabilities comparable to those of extremely large language models like GPT-3.5, demonstrating that learning generalized tool-use ability is feasible for compact language models.},
   author = {Qiaoyu Tang and Ziliang Deng and Hongyu Lin and Xianpei Han and Qiao Liang and Boxi Cao and Le Sun},
   month = {6},
   title = {ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases},
   url = {https://arxiv.org/abs/2306.05301v2},
   year = {2023},
}

@article{qu2024tool,
  title={Tool Learning with Large Language Models: A Survey},
  author={Qu, Changle and Dai, Sunhao and Wei, Xiaochi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Xu, Jun and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2405.17935},
  year={2024}
}

@article{hao2024large,
  title={Large Language Models Can Plan Your Travels Rigorously with Formal Verification Tools},
  author={Hao, Yilun and Chen, Yongchao and Zhang, Yang and Fan, Chuchu},
  journal={arXiv preprint arXiv:2404.11891},
  year={2024}
}

@article{liu2023llm+,
  title={Llm+ p: Empowering large language models with optimal planning proficiency},
  author={Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter},
  journal={arXiv preprint arXiv:2304.11477},
  year={2023}
}

@article{guan2023leveraging,
  title={Leveraging pre-trained large language models to construct and utilize world models for model-based task planning},
  author={Guan, Lin and Valmeekam, Karthik and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={79081--79094},
  year={2023}
}

@inproceedings{chen2024scalable,
  title={Scalable multi-robot collaboration with large language models: Centralized or decentralized systems?},
  author={Chen, Yongchao and Arkin, Jacob and Zhang, Yang and Roy, Nicholas and Fan, Chuchu},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4311--4317},
  year={2024},
  organization={IEEE}
}

@article{hao2023reasoning,
  title={Reasoning with language model is planning with world model},
  author={Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
  journal={arXiv preprint arXiv:2305.14992},
  year={2023}
}

@article{Mekala2024,
   author = {Dheeraj Mekala and Jason Weston and Jack Lanchantin and Roberta Raileanu and Maria Lomeli and Jingbo Shang and Jane Dwivedi-Yu},
   journal = {arXiv preprint arXiv:2402.14158},
   title = {TOOLVERIFIER: Generalization to New Tools via Self-Verification},
   year = {2024},
}

@misc{Luo2023,
   abstract = {Large language models (LLMs) have demonstrated impressive reasoning abilities in complex tasks. However, they lack up-to-date knowledge and experience hallucinations during reasoning, which can lead to incorrect reasoning processes and diminish their performance and trustworthiness. Knowledge graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM reasoning methods only treat KGs as factual knowledge bases and overlook the importance of their structural information for reasoning. In this paper, we propose a novel method called reasoning on graphs (RoG) that synergizes LLMs with KGs to enable faithful and interpretable reasoning. Specifically, we present a planning-retrieval-reasoning framework, where RoG first generates relation paths grounded by KGs as faithful plans. These plans are then used to retrieve valid reasoning paths from the KGs for LLMs to conduct faithful reasoning. Furthermore, RoG not only distills knowledge from KGs to improve the reasoning ability of LLMs through training but also allows seamless integration with any arbitrary LLMs during inference. Extensive experiments on two benchmark KGQA datasets demonstrate that RoG achieves state-of-the-art performance on KG reasoning tasks and generates faithful and interpretable reasoning results.},
   author = {Linhao Luo and Yuan-Fang Li and Gholamreza Haffari and Shirui Pan},
   doi = {10.48550/arXiv.2310.01061},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
   month = {10},
   note = {Comment: 22 pages, 4 figures
arXiv:2310.01061 [cs]},
   publisher = {arXiv},
   title = {Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning},
   url = {http://arxiv.org/abs/2310.01061},
   year = {2023},
}

@misc{Wang2023a,
   abstract = {Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9\%), SVAMP (+11.0\%), AQuA (+12.2\%), StrategyQA (+6.4\%) and ARC-challenge (+3.9\%).},
   author = {Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
   doi = {10.48550/arXiv.2203.11171},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
   month = {3},
   note = {Comment: Published at ICLR 2023. V2: added PaLM results; V3: added UL2 results; V4: camera ready version at ICLR 2023
arXiv:2203.11171 [cs]},
   publisher = {arXiv},
   title = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
   url = {http://arxiv.org/abs/2203.11171},
   year = {2023},
}

@misc{Weng2023,
   author = {Lilian Weng},
   month = {6},
   title = {LLM Powered Autonomous Agents},
   url = {https://lilianweng.github.io/posts/2023-06-23-agent/},
   year = {2023},
}

@article{Ge2024,
   author = {Yingqiang Ge and Wenyue Hua and Kai Mei and Juntao Tan and Shuyuan Xu and Zelong Li and Yongfeng Zhang and others},
   journal = {Advances in Neural Information Processing Systems},
   title = {Openagi: When llm meets domain experts},
   volume = {36},
   year = {2024},
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{schick2024toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{huang2024understanding,
  title={Understanding the planning of LLM agents: A survey},
  author={Huang, Xu and Liu, Weiwen and Chen, Xiaolong and Wang, Xingmei and Wang, Hao and Lian, Defu and Wang, Yasheng and Tang, Ruiming and Chen, Enhong},
  journal={arXiv preprint arXiv:2402.02716},
  year={2024}
}

@article{huang2024planning,
  title={Planning, Creation, Usage: Benchmarking LLMs for Comprehensive Tool Utilization in Real-World Complex Scenarios},
  author={Huang, Shijue and Zhong, Wanjun and Lu, Jianqiao and Zhu, Qi and Gao, Jiahui and Liu, Weiwen and Hou, Yutai and Zeng, Xingshan and Wang, Yasheng and Shang, Lifeng and others},
  journal={arXiv preprint arXiv:2401.17167},
  year={2024}
}

@article{Wang2023c,
   abstract = {Autonomous agents have long been a prominent research focus in both academic and industry communities. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective. More specifically, we first discuss the construction of LLM-based autonomous agents, for which we propose a unified framework that encompasses a majority of the previous work. Then, we present a comprehensive overview of the diverse applications of LLM-based autonomous agents in the fields of social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository of relevant references at https://github.com/Paitesanshi/LLM-Agent-Survey.},
   author = {Lei Wang and Chen Ma and Xueyang Feng and Zeyu Zhang and Hao Yang and Jingsen Zhang and Zhiyuan Chen and Jiakai Tang and Xu Chen and Yankai Lin and Wayne Xin Zhao and Zhewei Wei and Ji-Rong Wen},
   month = {8},
   title = {A Survey on Large Language Model based Autonomous Agents},
   year = {2023},
}

@misc{Zalta2019,
   author = {E N Zalta Schlossera M.},
   publisher = {Metaphysics Research Lab, Stanford, Winter},
   title = {The Stanford Encyclopedia of Philosophy},
   year = {2019},
}

@article{Ye2021,
   abstract = {Existing KBQA approaches, despite achieving strong performance on i.i.d. test data, often struggle in generalizing to questions involving unseen KB schema items. Prior ranking-based approaches have shown some success in generalization, but suffer from the coverage issue. We present RnG-KBQA, a Rank-and-Generate approach for KBQA, which remedies the coverage issue with a generation model while preserving a strong generalization capability. Our approach first uses a contrastive ranker to rank a set of candidate logical forms obtained by searching over the knowledge graph. It then introduces a tailored generation model conditioned on the question and the top-ranked candidates to compose the final logical form. We achieve new state-of-the-art results on GrailQA and WebQSP datasets. In particular, our method surpasses the prior state-of-the-art by a large margin on the GrailQA leaderboard. In addition, RnG-KBQA outperforms all prior approaches on the popular WebQSP benchmark, even including the ones that use the oracle entity linking. The experimental results demonstrate the effectiveness of the interplay between ranking and generation, which leads to the superior performance of our proposed approach across all settings with especially strong improvements in zero-shot generalization.},
   author = {Xi Ye and Semih Yavuz and Kazuma Hashimoto and Yingbo Zhou and Caiming Xiong},
   doi = {10.18653/v1/2022.acl-long.417},
   isbn = {9781955917216},
   issn = {0736587X},
   journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
   month = {9},
   pages = {6032-6043},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {RnG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering},
   volume = {1},
   url = {https://arxiv.org/abs/2109.08678v2},
   year = {2021},
}

@article{Shu2022,
   abstract = {Pre-trained language models (PLMs) have shown their effectiveness in multiple scenarios. However, KBQA remains challenging, especially regarding coverage and generalization settings. This is due to two main factors: i) understanding the semantics of both questions and relevant knowledge from the KB; ii) generating executable logical forms with both semantic and syntactic correctness. In this paper, we present a new KBQA model, TIARA, which addresses those issues by applying multi-grained retrieval to help the PLM focus on the most relevant KB contexts, viz., entities, exemplary logical forms, and schema items. Moreover, constrained decoding is used to control the output space and reduce generation errors. Experiments over important benchmarks demonstrate the effectiveness of our approach. TIARA outperforms previous SOTA, including those using PLMs or oracle entity annotations, by at least 4.1 and 1.1 F1 points on GrailQA and WebQuestionsSP, respectively.},
   author = {Yiheng Shu and Zhiwei Yu and Yuhan Li and Börje F. Karlsson and Tingting Ma and Yuzhong Qu and Chin Yew Lin},
   doi = {10.18653/v1/2022.emnlp-main.555},
   journal = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022},
   month = {10},
   pages = {8108-8121},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {TIARA: Multi-grained Retrieval for Robust Question Answering over Large Knowledge Bases},
   url = {https://arxiv.org/abs/2210.12925v1},
   year = {2022},
}

@misc{AlKhamissi2022,
   abstract = {Recently, there has been a surge of interest in the NLP community on the use of pretrained Language Models (LMs) as Knowledge Bases (KBs). Researchers have shown that LMs trained on a sufficiently large (web) corpus will encode a significant amount of knowledge implicitly in its parameters. The resulting LM can be probed for different kinds of knowledge and thus acting as a KB. This has a major advantage over traditional KBs in that this method requires no human supervision. In this paper, we present a set of aspects that we deem a LM should have to fully act as a KB, and review the recent literature with respect to those aspects.},
   author = {Badr AlKhamissi and Millicent Li and Asli Celikyilmaz and Mona Diab and Marjan Ghazvininejad},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
   month = {4},
   note = {Comment: Preprint
arXiv:2204.06031 [cs]},
   publisher = {arXiv},
   title = {A Review on Language Models as Knowledge Bases},
   url = {http://arxiv.org/abs/2204.06031},
   year = {2022},
}

@article{Ji2023,
   author = {Ziwei Ji and Nayeon Lee and Rita Frieske and Tiezheng Yu and Dan Su and Yan Xu and Etsuko Ishii and Ye Jin Bang and Andrea Madotto and Pascale Fung},
   issue = {12},
   journal = {ACM Computing Surveys},
   pages = {1-38},
   publisher = {ACM New York, NY},
   title = {Survey of hallucination in natural language generation},
   volume = {55},
   year = {2023},
}

@misc{Wang2023b,
   abstract = {We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention. Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement. Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent's abilities rapidly and alleviates catastrophic forgetting. Empirically, Voyager shows strong in-context lifelong learning capability and exhibits exceptional proficiency in playing Minecraft. It obtains 3.3x more unique items, travels 2.3x longer distances, and unlocks key tech tree milestones up to 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill library in a new Minecraft world to solve novel tasks from scratch, while other techniques struggle to generalize. We open-source our full codebase and prompts at https://voyager.minedojo.org/.},
   author = {Guanzhi Wang and Yuqi Xie and Yunfan Jiang and Ajay Mandlekar and Chaowei Xiao and Yuke Zhu and Linxi Fan and Anima Anandkumar},
   doi = {10.48550/arXiv.2305.16291},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
   month = {10},
   note = {Comment: Project website and open-source codebase: https://voyager.minedojo.org/
arXiv:2305.16291 [cs]},
   publisher = {arXiv},
   title = {Voyager: An Open-Ended Embodied Agent with Large Language Models},
   url = {http://arxiv.org/abs/2305.16291},
   year = {2023},
}

@article{Huang2022,
   author = {Wenlong Huang and Fei Xia and Ted Xiao and Harris Chan and Jacky Liang and Pete Florence and Andy Zeng and Jonathan Tompson and Igor Mordatch and Yevgen Chebotar and others},
   journal = {arXiv preprint arXiv:2207.05608},
   title = {Inner monologue: Embodied reasoning through planning with language models},
   year = {2022},
}

@article{Du2024,
   author = {Yu Du and Fangyun Wei and Hongyang Zhang},
   journal = {arXiv preprint arXiv:2402.04253},
   title = {Anytool: Self-reflective, hierarchical agents for large-scale api calls},
   year = {2024},
}

@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{chen2024autotamp,
  title={Autotamp: Autoregressive task and motion planning with llms as translators and checkers},
  author={Chen, Yongchao and Arkin, Jacob and Dawson, Charles and Zhang, Yang and Roy, Nicholas and Fan, Chuchu},
  booktitle={2024 IEEE International conference on robotics and automation (ICRA)},
  pages={6695--6702},
  year={2024},
  organization={IEEE}
}

@article{xie2024travelplanner,
  title={Travelplanner: A benchmark for real-world planning with language agents},
  author={Xie, Jian and Zhang, Kai and Chen, Jiangjie and Zhu, Tinghui and Lou, Renze and Tian, Yuandong and Xiao, Yanghua and Su, Yu},
  journal={arXiv preprint arXiv:2402.01622},
  year={2024}
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{Zhang2019,
   abstract = {Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.},
   author = {Zhengyan Zhang and Xu Han and Zhiyuan Liu and Xin Jiang and Maosong Sun and Qun Liu},
   month = {5},
   title = {ERNIE: Enhanced Language Representation with Informative Entities},
   year = {2019},
}

@article{chen2024bge,
  title={Bge m3-embedding: Multi-lingual, multi-functionality, multi-granularity text embeddings through self-knowledge distillation},
  author={Chen, Jianlv and Xiao, Shitao and Zhang, Peitian and Luo, Kun and Lian, Defu and Liu, Zheng},
  journal={arXiv preprint arXiv:2402.03216},
  year={2024}
}

@article{Lin2019,
   abstract = {Commonsense reasoning aims to empower machines with the human ability to make presumptions about ordinary situations in our daily life. In this paper, we propose a textual inference framework for answering commonsense questions, which effectively utilizes external, structured commonsense knowledge graphs to perform explainable inferences. The framework first grounds a question-answer pair from the semantic space to the knowledge-based symbolic space as a schema graph, a related sub-graph of external knowledge graphs. It represents schema graphs with a novel knowledge-aware graph network module named KagNet, and finally scores answers with graph representations. Our model is based on graph convolutional networks and LSTMs, with a hierarchical path-based attention mechanism. The intermediate attention scores make it transparent and interpretable, which thus produce trustworthy inferences. Using ConceptNet as the only external resource for Bert-based models, we achieved state-of-the-art performance on the CommonsenseQA, a large-scale dataset for commonsense reasoning.},
   author = {Bill Yuchen Lin and Xinyue Chen and Jamin Chen and Xiang Ren},
   month = {9},
   title = {KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning},
   year = {2019},
}

@article{Yasunaga2022,
   abstract = {Pretraining a language model (LM) on text has been shown to help various downstream NLP tasks. Recent works show that a knowledge graph (KG) can complement text data, offering structured background knowledge that provides a useful scaffold for reasoning. However, these works are not pretrained to learn a deep fusion of the two modalities at scale, limiting the potential to acquire fully joint representations of text and KG. Here we propose DRAGON (Deep Bidirectional Language-Knowledge Graph Pretraining), a self-supervised approach to pretraining a deeply joint language-knowledge foundation model from text and KG at scale. Specifically, our model takes pairs of text segments and relevant KG subgraphs as input and bidirectionally fuses information from both modalities. We pretrain this model by unifying two self-supervised reasoning tasks, masked language modeling and KG link prediction. DRAGON outperforms existing LM and LM+KG models on diverse downstream tasks including question answering across general and biomedical domains, with +5\% absolute gain on average. In particular, DRAGON achieves notable performance on complex reasoning about language and knowledge (+10\% on questions involving long contexts or multi-step reasoning) and low-resource QA (+8\% on OBQA and RiddleSense), and new state-of-the-art results on various BioNLP tasks. Our code and trained models are available at https://github.com/michiyasunaga/dragon.},
   author = {Michihiro Yasunaga and Antoine Bosselut and Hongyu Ren and Xikun Zhang and Christopher D Manning and Percy Liang and Jure Leskovec},
   month = {10},
   title = {Deep Bidirectional Language-Knowledge Graph Pretraining},
   year = {2022},
}

@article{Xi2023,
   abstract = {For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent agents, but they mainly focus on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many researchers have leveraged LLMs as the foundation to build AI agents and have achieved significant progress. In this paper, we perform a comprehensive survey on LLM-based agents. We start by tracing the concept of agents from its philosophical origins to its development in AI, and explain why LLMs are suitable foundations for agents. Building upon this, we present a general framework for LLM-based agents, comprising three main components: brain, perception, and action, and the framework can be tailored for different applications. Subsequently, we explore the extensive applications of LLM-based agents in three aspects: single-agent scenarios, multi-agent scenarios, and human-agent cooperation. Following this, we delve into agent societies, exploring the behavior and personality of LLM-based agents, the social phenomena that emerge from an agent society, and the insights they offer for human society. Finally, we discuss several key topics and open problems within the field. A repository for the related papers at https://github.com/WooooDyy/LLM-Agent-Paper-List.},
   author = {Zhiheng Xi and Wenxiang Chen and Xin Guo and Wei He and Yiwen Ding and Boyang Hong and Ming Zhang and Junzhe Wang and Senjie Jin and Enyu Zhou and Rui Zheng and Xiaoran Fan and Xiao Wang and Limao Xiong and Yuhao Zhou and Weiran Wang and Changhao Jiang and Yicheng Zou and Xiangyang Liu and Zhangyue Yin and Shihan Dou and Rongxiang Weng and Wensen Cheng and Qi Zhang and Wenjuan Qin and Yongyan Zheng and Xipeng Qiu and Xuanjing Huang and Tao Gui},
   month = {9},
   title = {The Rise and Potential of Large Language Model Based Agents: A Survey},
   year = {2023},
}

@book{Sutton2018,
   author = {Richard S Sutton and Andrew G Barto},
   publisher = {MIT press},
   title = {Reinforcement learning: An introduction},
   year = {2018},
}

@article{Wooldridge1995,
   author = {Michael Wooldridge and Nicholas R Jennings},
   issue = {2},
   journal = {The knowledge engineering review},
   pages = {115-152},
   publisher = {Cambridge University Press},
   title = {Intelligent agents: Theory and practice},
   volume = {10},
   year = {1995},
}

@article{Choudhary2023,
   abstract = {Reasoning over knowledge graphs (KGs) is a challenging task that requires a deep understanding of the complex relationships between entities and the underlying logic of their relations. Current approaches rely on learning geometries to embed entities in vector space for logical query operations, but they suffer from subpar performance on complex queries and dataset-specific representations. In this paper, we propose a novel decoupled approach, Language-guided Abstract Reasoning over Knowledge graphs (LARK), that formulates complex KG reasoning as a combination of contextual KG search and logical query reasoning, to leverage the strengths of graph extraction algorithms and large language models (LLM), respectively. Our experiments demonstrate that the proposed approach outperforms state-of-the-art KG reasoning methods on standard benchmark datasets across several logical query constructs, with significant performance gain for queries of higher complexity. Furthermore, we show that the performance of our approach improves proportionally to the increase in size of the underlying LLM, enabling the integration of the latest advancements in LLMs for logical reasoning over KGs. Our work presents a new direction for addressing the challenges of complex KG reasoning and paves the way for future research in this area.},
   author = {Nurendra Choudhary and Chandan K. Reddy},
   month = {5},
   title = {Complex Logical Reasoning over Knowledge Graphs using Large Language Models},
   year = {2023},
}

@inproceedings{Raman2022,
   author = {Shreyas Sundara Raman and Vanya Cohen and Eric Rosen and Ifrah Idrees and David Paulius and Stefanie Tellex},
   booktitle = {NeurIPS 2022 Foundation Models for Decision Making Workshop},
   title = {Planning with large language models via corrective re-prompting},
   year = {2022},
}

@article{Yao2023a,
   abstract = {Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/ysymyth/tree-of-thought-llm.},
   author = {Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
   month = {5},
   title = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
   year = {2023},
}

@misc{Yao2023b,
   abstract = {While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples. Project site with code: https://react-lm.github.io},
   author = {Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao},
   doi = {10.48550/arXiv.2210.03629},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
   month = {3},
   note = {Comment: v3 is the ICLR camera ready version with some typos fixed. Project site with code: https://react-lm.github.io
arXiv:2210.03629 [cs]},
   publisher = {arXiv},
   title = {ReAct: Synergizing Reasoning and Acting in Language Models},
   url = {http://arxiv.org/abs/2210.03629},
   year = {2023},
}

@article{Besta2023,
   abstract = {We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information ("LLM thoughts") are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62\% over ToT, while simultaneously reducing costs by >31\%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinking or brain mechanisms such as recurrence, both of which form complex networks.},
   author = {Maciej Besta and Nils Blach and Ales Kubicek and Robert Gerstenberger and Lukas Gianinazzi and Joanna Gajda and Tomasz Lehmann and Michal Podstawski and Hubert Niewiadomski and Piotr Nyczyk and Torsten Hoefler},
   month = {8},
   title = {Graph of Thoughts: Solving Elaborate Problems with Large Language Models},
   url = {https://arxiv.org/abs/2308.09687v3},
   year = {2023},
}

@misc{Ma,
   author = {马展 and 王岩 and 王微微 and 赵瑞莲},
   title = {基于多源信息融合的API知识图谱构建},
   url = {http://cnjournals.com/view_abstract.aspx?aid=CFC3B0096A6D80B2BB9723DA2B12C510&jid=D4F6864C950C88FFCE5B6C948A639E39&pcid=5B3AB970F71A803DEACDC0559115BFCF0A068CD97DD29835&yid=9475FABC7A03F4AB},
}

@article{Wang2021,
   author = {Xin Wang and Xiao Liu and Jin Liu and Xiaomei Chen and Hao Wu},
   issue = {3},
   journal = {World Wide Web},
   pages = {869-894},
   publisher = {Springer},
   title = {A novel knowledge graph embedding based API recommendation method for Mashup development},
   volume = {24},
   year = {2021},
}

@article{OpenAI2023,
   abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
   author = {OpenAI},
   month = {3},
   title = {GPT-4 Technical Report},
   url = {https://arxiv.org/abs/2303.08774v3},
   year = {2023},
}

@article{Yang2023,
   abstract = {Large language models (LLMs) have demonstrated remarkable performance on a variety of natural language tasks based on just a few examples of natural language instructions, reducing the need for extensive feature engineering. However, most powerful LLMs are closed-source or limited in their capability for languages other than English. In this technical report, we present Baichuan 2, a series of large-scale multilingual language models containing 7 billion and 13 billion parameters, trained from scratch, on 2.6 trillion tokens. Baichuan 2 matches or outperforms other open-source models of similar size on public benchmarks like MMLU, CMMLU, GSM8K, and HumanEval. Furthermore, Baichuan 2 excels in vertical domains such as medicine and law. We will release all pre-training model checkpoints to benefit the research community in better understanding the training dynamics of Baichuan 2.},
   author = {Aiyuan Yang and Bin Xiao and Bingning Wang and Borong Zhang and Ce Bian and Chao Yin and Chenxu Lv and Da Pan and Dian Wang and Dong Yan and Fan Yang and Fei Deng and Feng Wang and Feng Liu and Guangwei Ai and Guosheng Dong and Haizhou Zhao and Hang Xu and Haoze Sun and Hongda Zhang and Hui Liu and Jiaming Ji and Jian Xie and JunTao Dai and Kun Fang and Lei Su and Liang Song and Lifeng Liu and Liyun Ru and Luyao Ma and Mang Wang and Mickel Liu and MingAn Lin and Nuolan Nie and Peidong Guo and Ruiyang Sun and Tao Zhang and Tianpeng Li and Tianyu Li and Wei Cheng and Weipeng Chen and Xiangrong Zeng and Xiaochuan Wang and Xiaoxi Chen and Xin Men and Xin Yu and Xuehai Pan and Yanjun Shen and Yiding Wang and Yiyu Li and Youxin Jiang and Yuchen Gao and Yupeng Zhang and Zenan Zhou and Zhiying Wu},
   month = {9},
   title = {Baichuan 2: Open Large-scale Language Models},
   year = {2023},
}

@article{Zeng2023,
   abstract = {Open large language models (LLMs) with great performance in various tasks have significantly advanced the development of LLMs. However, they are far inferior to commercial models such as ChatGPT and GPT-4 when acting as agents to tackle complex tasks in the real world. These agent tasks employ LLMs as the central controller responsible for planning, memorization, and tool utilization, necessitating both fine-grained prompting methods and robust LLMs to achieve satisfactory performance. Though many prompting methods have been proposed to complete particular agent tasks, there is lack of research focusing on improving the agent capabilities of LLMs themselves without compromising their general abilities. In this work, we present AgentTuning, a simple and general method to enhance the agent abilities of LLMs while maintaining their general LLM capabilities. We construct AgentInstruct, a lightweight instruction-tuning dataset containing high-quality interaction trajectories. We employ a hybrid instruction-tuning strategy by combining AgentInstruct with open-source instructions from general domains. AgentTuning is used to instruction-tune the Llama 2 series, resulting in AgentLM. Our evaluations show that AgentTuning enables LLMs' agent capabilities without compromising general abilities. The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent tasks, demonstrating generalized agent capabilities. We open source the AgentInstruct and AgentLM-7B, 13B, and 70B models at https://github.com/THUDM/AgentTuning, serving open and powerful alternatives to commercial LLMs for agent tasks.},
   author = {Aohan Zeng and Mingdao Liu and Rui Lu and Bowen Wang and Xiao Liu and Yuxiao Dong and Jie Tang},
   month = {10},
   title = {AgentTuning: Enabling Generalized Agent Abilities for LLMs},
   url = {https://arxiv.org/abs/2310.12823v2},
   year = {2023},
}

@article{Touvron2023,
   abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.},
   author = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
   month = {2},
   title = {LLaMA: Open and Efficient Foundation Language Models},
   url = {https://arxiv.org/abs/2302.13971v1},
   year = {2023},
}

@article{Ling2019,
   author = {Chun-Yang Ling and Yan-Zhen Zou and Ze-Qi Lin and Bing Xie},
   journal = {Journal of Computer Science and Technology},
   pages = {993-1006},
   publisher = {Springer},
   title = {Graph embedding based API graph search and recommendation},
   volume = {34},
   year = {2019},
}

@misc{Song2023,
   abstract = {Tool-augmented large language models (LLMs) have achieved remarkable progress in tackling a broad range of tasks. However, existing methods are mainly restricted to specifically designed tools and fail to fulfill complex instructions, having great limitations when confronted with real-world scenarios. In this paper, we explore a more realistic scenario by connecting LLMs with RESTful APIs, which adhere to the widely adopted REST software architectural style for web service development. To address the practical challenges of tackling complex instructions, we propose RestGPT, which exploits the power of LLMs and conducts a coarse-to-fine online planning mechanism to enhance the abilities of task decomposition and API selection. RestGPT also contains an API executor tailored for calling RESTful APIs, which can meticulously formulate parameters and parse API responses. To fully evaluate the performance of RestGPT, we propose RestBench, a high-quality benchmark which consists of two real-world scenarios and human-annotated instructions with gold solution paths. Experiments show that RestGPT is able to achieve impressive results in complex tasks and has strong robustness, which paves a new way towards AGI. RestGPT and RestBench is publicly available at https://restgpt.github.io/.},
   author = {Yifan Song and Weimin Xiong and Dawei Zhu and Wenhao Wu and Han Qian and Mingbo Song and Hailiang Huang and Cheng Li and Ke Wang and Rong Yao and Ye Tian and Sujian Li},
   doi = {10.48550/arXiv.2306.06624},
   keywords = {Computer Science - Computation and Language},
   month = {8},
   note = {Comment: Add RestBench to evaluate RestGPT
arXiv:2306.06624 [cs]},
   publisher = {arXiv},
   title = {RestGPT: Connecting Large Language Models with Real-World RESTful APIs},
   url = {http://arxiv.org/abs/2306.06624},
   year = {2023},
}

@article{Ruan2023,
   abstract = {With recent advancements in natural language processing, Large Language Models (LLMs) have emerged as powerful tools for various real-world applications. Despite their prowess, the intrinsic generative abilities of LLMs may prove insufficient for handling complex tasks which necessitate a combination of task planning and the usage of external tools. In this paper, we first propose a structured framework tailored for LLM-based AI Agents and discuss the crucial capabilities necessary for tackling intricate problems. Within this framework, we design two distinct types of agents (i.e., one-step agent and sequential agent) to execute the inference process. Subsequently, we instantiate the framework using various LLMs and evaluate their Task Planning and Tool Usage (TPTU) abilities on typical tasks. By highlighting key findings and challenges, our goal is to provide a helpful resource for researchers and practitioners to leverage the power of LLMs in their AI applications. Our study emphasizes the substantial potential of these models, while also identifying areas that need more investigation and improvement.},
   author = {Jingqing Ruan and Yihong Chen and Bin Zhang and Zhiwei Xu and Tianpeng Bao and Guoqing Du and Shiwei Shi and Hangyu Mao and Ziyue Li and Xingyu Zeng and Rui Zhao},
   month = {8},
   title = {TPTU: Large Language Model-based AI Agents for Task Planning and Tool Usage},
   year = {2023},
}

@article{Miao2023,
   abstract = {The recent progress in large language models (LLMs), especially the invention of chain-of-thought prompting, has made it possible to automatically answer questions by stepwise reasoning. However, when faced with more complicated problems that require non-linear thinking, even the strongest LLMs make mistakes. To address this, we explore whether LLMs are able to recognize errors in their own step-by-step reasoning, without resorting to external resources. To this end, we propose SelfCheck, a general-purpose zero-shot verification schema for recognizing such errors. We then use the results of these checks to improve question-answering performance by conducting weighted voting on multiple solutions to the question. We test SelfCheck on three datasets (GSM8K, MathQA, and MATH) and find that it successfully recognizes errors and, in turn, increases final answer accuracies.},
   author = {Ning Miao and Yee Whye Teh and Tom Rainforth},
   month = {8},
   title = {SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning},
   year = {2023},
}

@article{Liu2024,
   author = {Xukun Liu and Zhiyuan Peng and Xiaoyuan Yi and Xing Xie and Lirong Xiang and Yuchen Liu and Dongkuan Xu},
   journal = {arXiv preprint arXiv:2403.00839},
   title = {ToolNet: Connecting large language models with massive tools via tool graph},
   year = {2024},
}

@article{powers2020evaluation,
  title={Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation},
  author={Powers, David MW},
  journal={arXiv preprint arXiv:2010.16061},
  year={2020}
}

@inproceedings{wang2013theoretical,
  title={A theoretical analysis of NDCG type ranking measures},
  author={Wang, Yining and Wang, Liwei and Li, Yuanzhi and He, Di and Liu, Tie-Yan},
  booktitle={Conference on learning theory},
  pages={25--54},
  year={2013},
  organization={PMLR}
}

@article{buckland1994relationship,
  title={The relationship between recall and precision},
  author={Buckland, Michael and Gey, Fredric},
  journal={Journal of the American society for information science},
  volume={45},
  number={1},
  pages={12--19},
  year={1994},
  publisher={Wiley Online Library}
}

@article{Sun2023,
   author = {Jiashuo Sun and Chengjin Xu and Lumingyuan Tang and Saizhuo Wang and Chen Lin and Yeyun Gong and Heung-Yeung Shum and Jian Guo},
   journal = {arXiv preprint arXiv:2307.07697},
   title = {Think-on-graph: Deep and responsible reasoning of large language model with knowledge graph},
   year = {2023},
}

@article{Ma2024,
   author = {Shengjie Ma and Chengjin Xu and Xuhui Jiang and Muzhi Li and Huaren Qu and Jian Guo},
   journal = {arXiv preprint arXiv:2407.10805},
   title = {Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval},
   year = {2024},
}

@article{Liu2023a,
   author = {Zhaoyang Liu and Zeqiang Lai and Zhangwei Gao and Erfei Cui and Zhiheng Li and Xizhou Zhu and Lewei Lu and Qifeng Chen and Yu Qiao and Jifeng Dai and others},
   journal = {arXiv preprint arXiv:2310.17796},
   title = {Controlllm: Augment language models with tools by searching on graphs},
   year = {2023},
}

@article{Liu2023b,
   abstract = {Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments. We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting. Our extensive test over 27 API-based and open-sourced (OSS) LLMs shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and OSS competitors. We identify the typical reasons of failures in environments and LLMs, showing that poor long-term reasoning, decision-making, and instruction following abilities are the main obstacles for developing usable LLM agents. Training on code and high quality multi-turn alignment data could improve agent performance. Datasets, environments, and an integrated evaluation package for AgentBench are released at \url\{https://github.com/THUDM/AgentBench\}.},
   author = {Xiao Liu and Hao Yu and Hanchen Zhang and Yifan Xu and Xuanyu Lei and Hanyu Lai and Yu Gu and Hangliang Ding and Kaiwen Men and Kejuan Yang and Shudan Zhang and Xiang Deng and Aohan Zeng and Zhengxiao Du and Chenhui Zhang and Sheng Shen and Tianjun Zhang and Yu Su and Huan Sun and Minlie Huang and Yuxiao Dong and Jie Tang},
   month = {8},
   title = {AgentBench: Evaluating LLMs as Agents},
   year = {2023},
}

@article{Jones1972,
   author = {Karen Sparck Jones},
   issue = {1},
   journal = {Journal of documentation},
   pages = {11-21},
   publisher = {MCB UP Ltd},
   title = {A statistical interpretation of term specificity and its application in retrieval},
   volume = {28},
   year = {1972},
}

@misc{moka2024m3e,
  title = {{M3E-base}: Multilingual Embedding Model},
  author = {{Moka AI}},
  year = {2024},
  url = {https://huggingface.co/moka-ai/m3e-base},
  note = {Accessed: 2024-11-15}
}

@misc{netease2024BCEmbedding,
  title = {{BCEmbedding}: Bilingual Contextual Embedding for Cross-lingual Text Understanding},
  author = {{Netease Youdao Research Team}},
  year = {2024},
  url = {https://github.com/netease-youdao/BCEmbedding},
  note = {Accessed: 2024-11-15}
}

@article{ye2024tooleyes,
  title={Tooleyes: Fine-grained evaluation for tool learning capabilities of large language models in real-world scenarios},
  author={Ye, Junjie and Li, Guanyu and Gao, Songyang and Huang, Caishuang and Wu, Yilong and Li, Sixian and Fan, Xiaoran and Dou, Shihan and Zhang, Qi and Gui, Tao and others},
  journal={arXiv preprint arXiv:2401.00741},
  year={2024}
}

@article{Qin2023,
   abstract = {Despite the advancements of open-source large language models (LLMs), e.g., LLaMA, they remain significantly limited in tool-use capabilities, i.e., using external tools (APIs) to fulfill human instructions. The reason is that current instruction tuning largely focuses on basic language tasks but ignores the tool-use domain. This is in contrast to the excellent tool-use capabilities of state-of-the-art (SOTA) closed-source LLMs, e.g., ChatGPT. To bridge this gap, we introduce ToolLLM, a general tool-use framework encompassing data construction, model training, and evaluation. We first present ToolBench, an instruction-tuning dataset for tool use, which is constructed automatically using ChatGPT. Specifically, the construction can be divided into three stages: (i) API collection: we collect 16,464 real-world RESTful APIs spanning 49 categories from RapidAPI Hub; (ii) instruction generation: we prompt ChatGPT to generate diverse instructions involving these APIs, covering both single-tool and multi-tool scenarios; (iii) solution path annotation: we use ChatGPT to search for a valid solution path (chain of API calls) for each instruction. To enhance the reasoning capabilities of LLMs, we develop a novel depth-first search-based decision tree algorithm. It enables LLMs to evaluate multiple reasoning traces and expand the search space. Moreover, to evaluate the tool-use capabilities of LLMs, we develop an automatic evaluator: ToolEval. Based on ToolBench, we fine-tune LLaMA to obtain an LLM ToolLLaMA, and equip it with a neural API retriever to recommend appropriate APIs for each instruction. Experiments show that ToolLLaMA demonstrates a remarkable ability to execute complex instructions and generalize to unseen APIs, and exhibits comparable performance to ChatGPT. Our ToolLLaMA also demonstrates strong zero-shot generalization ability in an out-of-distribution tool-use dataset: APIBench.},
   author = {Yujia Qin and Shihao Liang and Yining Ye and Kunlun Zhu and Lan Yan and Yaxi Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Lauren Hong and Runchu Tian and Ruobing Xie and Jie Zhou and Mark Gerstein and Dahai Li and Zhiyuan Liu and Maosong Sun},
   month = {7},
   title = {ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs},
   year = {2023},
}

@article{Robertson2009,
   author = {Stephen Robertson and Hugo Zaragoza and others},
   issue = {4},
   journal = {Foundations and Trends® in Information Retrieval},
   pages = {333-389},
   publisher = {Now Publishers, Inc.},
   title = {The probabilistic relevance framework: BM25 and beyond},
   volume = {3},
   year = {2009},
}

@misc{Li2023c,
   abstract = {Recent research has demonstrated that Large Language Models (LLMs) can enhance their capabilities by utilizing external tools. However, three pivotal questions remain unanswered: (1) How effective are current LLMs in utilizing tools? (2) How can we enhance LLMs' ability to utilize tools? (3) What obstacles need to be overcome to leverage tools? To address these questions, we introduce API-Bank, a groundbreaking benchmark, specifically designed for tool-augmented LLMs. For the first question, we develop a runnable evaluation system consisting of 73 API tools. We annotate 314 tool-use dialogues with 753 API calls to assess the existing LLMs' capabilities in planning, retrieving, and calling APIs. For the second question, we construct a comprehensive training set containing 1,888 tool-use dialogues from 2,138 APIs spanning 1,000 distinct domains. Using this dataset, we train Lynx, a tool-augmented LLM initialized from Alpaca. Experimental results demonstrate that GPT-3.5 exhibits improved tool utilization compared to GPT-3, while GPT-4 excels in planning. However, there is still significant potential for further improvement. Moreover, Lynx surpasses Alpaca's tool utilization performance by more than 26 pts and approaches the effectiveness of GPT-3.5. Through error analysis, we highlight the key challenges for future research in this field to answer the third question.},
   author = {Minghao Li and Yingxiu Zhao and Bowen Yu and Feifan Song and Hangyu Li and Haiyang Yu and Zhoujun Li and Fei Huang and Yongbin Li},
   doi = {10.48550/arXiv.2304.08244},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
   month = {10},
   note = {Comment: EMNLP 2023
arXiv:2304.08244 [cs]},
   publisher = {arXiv},
   title = {API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs},
   url = {http://arxiv.org/abs/2304.08244},
   year = {2023},
}


% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").
@article{xie2024travelplanner,
  title={Travelplanner: A benchmark for real-world planning with language agents},
  author={Xie, Jian and Zhang, Kai and Chen, Jiangjie and Zhu, Tinghui and Lou, Renze and Tian, Yuandong and Xiao, Yanghua and Su, Yu},
  journal={arXiv preprint arXiv:2402.01622},
  year={2024}
}

@inproceedings{liang2023code,
  title={Code as policies: Language model programs for embodied control},
  author={Liang, Jacky and Huang, Wenlong and Xia, Fei and Xu, Peng and Hausman, Karol and Ichter, Brian and Florence, Pete and Zeng, Andy},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={9493--9500},
  year={2023},
  organization={IEEE}
}

@article{yao2022react,
  title={React: Synergizing reasoning and acting in language models},
  author={Yao, Shunyu and Zhao, Jeffrey and Yu, Dian and Du, Nan and Shafran, Izhak and Narasimhan, Karthik and Cao, Yuan},
  journal={arXiv preprint arXiv:2210.03629},
  year={2022}
}

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{valmeekam2022large,
  title={Large language models still can't plan (a benchmark for llms on planning and reasoning about change)},
  author={Valmeekam, Karthik and Olmo, Alberto and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={arXiv preprint arXiv:2206.10498},
  year={2022}
}

@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International Conference on Machine Learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}

@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Fu, Chuyuan and Gopalakrishnan, Keerthana and Hausman, Karol and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@inproceedings{song2023llm,
  title={Llm-planner: Few-shot grounded planning for embodied agents with large language models},
  author={Song, Chan Hee and Wu, Jiaman and Washington, Clayton and Sadler, Brian M and Chao, Wei-Lun and Su, Yu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2998--3009},
  year={2023}
}

@book{dechter2003constraint,
  title={Constraint processing},
  author={Dechter, Rina},
  year={2003},
  publisher={Morgan Kaufmann}
}

@inproceedings{lozano2014constraint,
  title={A constraint-based method for solving sequential manipulation planning problems},
  author={Lozano-P{\'e}rez, Tom{\'a}s and Kaelbling, Leslie Pack},
  booktitle={2014 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={3684--3691},
  year={2014},
  organization={IEEE}
}

@inproceedings{dantam2016incremental,
  title={Incremental task and motion planning: A constraint-based approach.},
  author={Dantam, Neil T and Kingston, Zachary K and Chaudhuri, Swarat and Kavraki, Lydia E},
  booktitle={Robotics: Science and systems},
  volume={12},
  pages={00052},
  year={2016},
  organization={Ann Arbor, MI, USA}
}

@inproceedings{barrett2010smt,
  title={The smt-lib standard: Version 2.0},
  author={Barrett, Clark and Stump, Aaron and Tinelli, Cesare and others},
  booktitle={Proceedings of the 8th international workshop on satisfiability modulo theories (Edinburgh, UK)},
  volume={13},
  pages={14},
  year={2010}
}

@article{de2011satisfiability,
  title={Satisfiability modulo theories: introduction and applications},
  author={De Moura, Leonardo and Bj{\o}rner, Nikolaj},
  journal={Communications of the ACM},
  volume={54},
  number={9},
  pages={69--77},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@inproceedings{de2008z3,
  title={Z3: An efficient SMT solver},
  author={De Moura, Leonardo and Bj{\o}rner, Nikolaj},
  booktitle={International conference on Tools and Algorithms for the Construction and Analysis of Systems},
  pages={337--340},
  year={2008},
  organization={Springer}
}

@inproceedings{barrett2011cvc4,
  title={cvc4},
  author={Barrett, Clark and Conway, Christopher L and Deters, Morgan and Hadarean, Liana and Jovanovi{\'c}, Dejan and King, Tim and Reynolds, Andrew and Tinelli, Cesare},
  booktitle={Computer Aided Verification: 23rd International Conference, CAV 2011, Snowbird, UT, USA, July 14-20, 2011. Proceedings 23},
  pages={171--177},
  year={2011},
  organization={Springer}
}

@inproceedings{kautz1999unifying,
  title={Unifying SAT-based and graph-based planning},
  author={Kautz, Henry and Selman, Bart},
  booktitle={IJCAI},
  volume={99},
  pages={318--325},
  year={1999}
}

@article{rintanen2012planning,
  title={Planning as satisfiability: Heuristics},
  author={Rintanen, Jussi},
  journal={Artificial intelligence},
  volume={193},
  pages={45--86},
  year={2012},
  publisher={Elsevier}
}

@inproceedings{dutertre2006fast,
  title={A fast linear-arithmetic solver for DPLL (T)},
  author={Dutertre, Bruno and De Moura, Leonardo},
  booktitle={International Conference on Computer Aided Verification},
  pages={81--94},
  year={2006},
  organization={Springer}
}

@book{ghallab2004automated,
  title={Automated Planning: theory and practice},
  author={Ghallab, Malik and Nau, Dana and Traverso, Paolo},
  year={2004},
  publisher={Elsevier}
}

@article{theuma2024equipping,
  title={Equipping Language Models with Tool Use Capability for Tabular Data Analysis in Finance},
  author={Theuma, Adrian and Shareghi, Ehsan},
  journal={arXiv preprint arXiv:2401.15328},
  year={2024}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{kojima2022large,
  title={Large language models are zero-shot reasoners},
  author={Kojima, Takeshi and Gu, Shixiang Shane and Reid, Machel and Matsuo, Yutaka and Iwasawa, Yusuke},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={22199--22213},
  year={2022}
}

@article{qin2023toolllm,
  title={Toolllm: Facilitating large language models to master 16000+ real-world apis},
  author={Qin, Yujia and Liang, Shihao and Ye, Yining and Zhu, Kunlun and Yan, Lan and Lu, Yaxi and Lin, Yankai and Cong, Xin and Tang, Xiangru and Qian, Bill and others},
  journal={arXiv preprint arXiv:2307.16789},
  year={2023}
}

@article{schick2024toolformer,
  title={Toolformer: Language models can teach themselves to use tools},
  author={Schick, Timo and Dwivedi-Yu, Jane and Dess{\`\i}, Roberto and Raileanu, Roberta and Lomeli, Maria and Hambro, Eric and Zettlemoyer, Luke and Cancedda, Nicola and Scialom, Thomas},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{shen2024hugginggpt,
  title={Hugginggpt: Solving ai tasks with chatgpt and its friends in hugging face},
  author={Shen, Yongliang and Song, Kaitao and Tan, Xu and Li, Dongsheng and Lu, Weiming and Zhuang, Yueting},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{wang2022self,
  title={Self-consistency improves chain of thought reasoning in language models},
  author={Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny},
  journal={arXiv preprint arXiv:2203.11171},
  year={2022}
}

@article{yao2024tree,
  title={Tree of thoughts: Deliberate problem solving with large language models},
  author={Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Tom and Cao, Yuan and Narasimhan, Karthik},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{zhao2024large,
  title={Large language models as commonsense knowledge for large-scale task planning},
  author={Zhao, Zirui and Lee, Wee Sun and Hsu, David},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@inproceedings{besta2024graph,
  title={Graph of thoughts: Solving elaborate problems with large language models},
  author={Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and others},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17682--17690},
  year={2024}
}

@article{hao2023reasoning,
  title={Reasoning with language model is planning with world model},
  author={Hao, Shibo and Gu, Yi and Ma, Haodi and Hong, Joshua Jiahua and Wang, Zhen and Wang, Daisy Zhe and Hu, Zhiting},
  journal={arXiv preprint arXiv:2305.14992},
  year={2023}
}

@article{shinn2024reflexion,
  title={Reflexion: Language agents with verbal reinforcement learning},
  author={Shinn, Noah and Cassano, Federico and Gopinath, Ashwin and Narasimhan, Karthik and Yao, Shunyu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{chen2023autotamp,
  title={Autotamp: Autoregressive task and motion planning with llms as translators and checkers},
  author={Chen, Yongchao and Arkin, Jacob and Zhang, Yang and Roy, Nicholas and Fan, Chuchu},
  journal={arXiv preprint arXiv:2306.06531},
  year={2023}
}

@article{chen2023scalable,
  title={Scalable multi-robot collaboration with large language models: Centralized or decentralized systems?},
  author={Chen, Yongchao and Arkin, Jacob and Zhang, Yang and Roy, Nicholas and Fan, Chuchu},
  journal={arXiv preprint arXiv:2309.15943},
  year={2023}
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{huang2024understanding,
  title={Understanding the planning of LLM agents: A survey},
  author={Huang, Xu and Liu, Weiwen and Chen, Xiaolong and Wang, Xingmei and Wang, Hao and Lian, Defu and Wang, Yasheng and Tang, Ruiming and Chen, Enhong},
  journal={arXiv preprint arXiv:2402.02716},
  year={2024}
}

@article{liu2023llm+,
  title={Llm+ p: Empowering large language models with optimal planning proficiency},
  author={Liu, Bo and Jiang, Yuqian and Zhang, Xiaohan and Liu, Qiang and Zhang, Shiqi and Biswas, Joydeep and Stone, Peter},
  journal={arXiv preprint arXiv:2304.11477},
  year={2023}
}

@article{guan2023leveraging,
  title={Leveraging pre-trained large language models to construct and utilize world models for model-based task planning},
  author={Guan, Lin and Valmeekam, Karthik and Sreedharan, Sarath and Kambhampati, Subbarao},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={79081--79094},
  year={2023}
}

@article{aeronautiques1998pddl,
  title={Pddl| the planning domain definition language},
  author={Aeronautiques, Constructions and Howe, Adele and Knoblock, Craig and McDermott, ISI Drew and Ram, Ashwin and Veloso, Manuela and Weld, Daniel and Sri, David Wilkins and Barrett, Anthony and Christianson, Dave and others},
  journal={Technical Report, Tech. Rep.},
  year={1998}
}

@book{haslum2019introduction,
  title={An introduction to the planning domain definition language},
  author={Haslum, Patrik and Lipovetzky, Nir and Magazzeni, Daniele and Muise, Christian and Brachman, Ronald and Rossi, Francesca and Stone, Peter},
  volume={13},
  year={2019},
  publisher={Springer}
}

@article{press2022measuring,
  title={Measuring and narrowing the compositionality gap in language models},
  author={Press, Ofir and Zhang, Muru and Min, Sewon and Schmidt, Ludwig and Smith, Noah A and Lewis, Mike},
  journal={arXiv preprint arXiv:2210.03350},
  year={2022}
}

@inproceedings{singh2023progprompt,
  title={Progprompt: Generating situated robot task plans using large language models},
  author={Singh, Ishika and Blukis, Valts and Mousavian, Arsalan and Goyal, Ankit and Xu, Danfei and Tremblay, Jonathan and Fox, Dieter and Thomason, Jesse and Garg, Animesh},
  booktitle={2023 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={11523--11530},
  year={2023},
  organization={IEEE}
}

@article{peng2023check,
  title={Check your facts and try again: Improving large language models with external knowledge and automated feedback},
  author={Peng, Baolin and Galley, Michel and He, Pengcheng and Cheng, Hao and Xie, Yujia and Hu, Yu and Huang, Qiuyuan and Liden, Lars and Yu, Zhou and Chen, Weizhu and others},
  journal={arXiv preprint arXiv:2302.12813},
  year={2023}
}

@article{huang2022inner,
  title={Inner monologue: Embodied reasoning through planning with language models},
  author={Huang, Wenlong and Xia, Fei and Xiao, Ted and Chan, Harris and Liang, Jacky and Florence, Pete and Zeng, Andy and Tompson, Jonathan and Mordatch, Igor and Chebotar, Yevgen and others},
  journal={arXiv preprint arXiv:2207.05608},
  year={2022}
}

@misc{claude,
  title = {Introducing the next generation of Claude},
  howpublished = {\url{https://www.anthropic.com/news/claude-3-family}},
  note = {Accessed: 2024-03-04}
}

@misc{mistral,
  title = {Au Large},
  howpublished = {\url{https://mistral.ai/news/mistral-large/}},
  note = {Accessed: 2024-02-26}
}

@misc{gpt-4o,
  title = {Hello GPT-4o},
  howpublished = {\url{https://openai.com/index/hello-gpt-4o/}},
  note = {Accessed: 2024-05-13}
}



@article{helmert2006fast,
  title={The fast downward planning system},
  author={Helmert, Malte},
  journal={Journal of Artificial Intelligence Research},
  volume={26},
  pages={191--246},
  year={2006}
}

@article{hoffmann2001ff,
  title={The FF planning system: Fast plan generation through heuristic search},
  author={Hoffmann, J{\"o}rg and Nebel, Bernhard},
  journal={Journal of Artificial Intelligence Research},
  volume={14},
  pages={253--302},
  year={2001}
}

@article{vidal2014yahsp3,
  title={YAHSP3 and YAHSP3-MT in the 8th international planning competition},
  author={Vidal, Vincent},
  journal={Proceedings of the 8th International Planning Competition (IPC-2014)},
  pages={64--65},
  year={2014}
}

@article{rintanen2014madagascar,
  title={Madagascar: Scalable planning with SAT},
  author={Rintanen, Jussi},
  journal={Proceedings of the 8th International Planning Competition (IPC-2014)},
  volume={21},
  pages={1--5},
  year={2014}
}

@inproceedings{kambhampatiposition,
  title={Position: LLMs Can’t Plan, But Can Help Planning in LLM-Modulo Frameworks},
  author={Kambhampati, Subbarao and Valmeekam, Karthik and Guan, Lin and Verma, Mudit and Stechly, Kaya and Bhambri, Siddhant and Saldyt, Lucas Paul and Murthy, Anil B},
  booktitle={Forty-first International Conference on Machine Learning}
}

@article{wang2023promptagent,
  title={Promptagent: Strategic planning with language models enables expert-level prompt optimization},
  author={Wang, Xinyuan and Li, Chenxi and Wang, Zhen and Bai, Fan and Luo, Haotian and Zhang, Jiayou and Jojic, Nebojsa and Xing, Eric P and Hu, Zhiting},
  journal={arXiv preprint arXiv:2310.16427},
  year={2023}
}

@article{fernando2023promptbreeder,
  title={Promptbreeder: Self-referential self-improvement via prompt evolution},
  author={Fernando, Chrisantha and Banarse, Dylan and Michalewski, Henryk and Osindero, Simon and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2309.16797},
  year={2023}
}

@article{chen2024prompt,
  title={Prompt optimization in multi-step tasks (promst): Integrating human feedback and preference alignment},
  author={Chen, Yongchao and Arkin, Jacob and Hao, Yilun and Zhang, Yang and Roy, Nicholas and Fan, Chuchu},
  journal={arXiv preprint arXiv:2402.08702},
  year={2024}
}

@article{li2023large,
  title={Large language models for supply chain optimization},
  author={Li, Beibin and Mellou, Konstantina and Zhang, Bo and Pathuri, Jeevan and Menache, Ishai},
  journal={arXiv preprint arXiv:2307.03875},
  year={2023}
}

@article{gundawar2024robust,
  title={Robust Planning with LLM-Modulo Framework: Case Study in Travel Planning},
  author={Gundawar, Atharva and Verma, Mudit and Guan, Lin and Valmeekam, Karthik and Bhambri, Siddhant and Kambhampati, Subbarao},
  journal={arXiv preprint arXiv:2405.20625},
  year={2024}
}

@misc{o1preview,
  title = {Introducing OpenAI o1-preview},
  howpublished = {\url{https://openai.com/index/introducing-openai-o1-preview/}},
  note = {Accessed: 2024-09-12}
}



@Comment{jabref-meta: databaseType:biblatex;}
