@misc{,
   title = {AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation},
   url = {https://arxiv.org/abs/2308.08155},
}
@misc{Hong2023,
   abstract = {Remarkable progress has been made on automated problem solving through societies of agents based on large language models (LLMs). Existing LLM-based multi-agent systems can already solve simple dialogue tasks. Solutions to more complex tasks, however, are complicated through logic inconsistencies due to cascading hallucinations caused by naively chaining LLMs. Here we introduce MetaGPT, an innovative meta-programming framework incorporating efficient human workflows into LLM-based multi-agent collaborations. MetaGPT encodes Standardized Operating Procedures (SOPs) into prompt sequences for more streamlined workflows, thus allowing agents with human-like domain expertise to verify intermediate results and reduce errors. MetaGPT utilizes an assembly line paradigm to assign diverse roles to various agents, efficiently breaking down complex tasks into subtasks involving many agents working together. On collaborative software engineering benchmarks, MetaGPT generates more coherent solutions than previous chat-based multi-agent systems. Our project can be found at https://github.com/geekan/MetaGPT},
   author = {Sirui Hong and Mingchen Zhuge and Jonathan Chen and Xiawu Zheng and Yuheng Cheng and Ceyao Zhang and Jinlin Wang and Zili Wang and Steven Ka Shing Yau and Zijuan Lin and Liyang Zhou and Chenyu Ran and Lingfeng Xiao and Chenglin Wu and Jürgen Schmidhuber},
   doi = {10.48550/arXiv.2308.00352},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Multiagent Systems,agent,llm,multi-agent},
   month = {11},
   note = {arXiv:2308.00352 [cs]},
   publisher = {arXiv},
   title = {MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework},
   url = {http://arxiv.org/abs/2308.00352},
   year = {2023},
}
@misc{Wu2023,
   abstract = {AutoGen is an open-source framework that allows developers to build LLM applications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable, conversable, and can operate in various modes that employ combinations of LLMs, human inputs, and tools. Using AutoGen, developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic infrastructure to build diverse applications of various complexities and LLM capacities. Empirical studies demonstrate the effectiveness of the framework in many example applications, with domains ranging from mathematics, coding, question answering, operations research, online decision-making, entertainment, etc.},
   author = {Qingyun Wu and Gagan Bansal and Jieyu Zhang and Yiran Wu and Beibin Li and Erkang Zhu and Li Jiang and Xiaoyun Zhang and Shaokun Zhang and Jiale Liu and Ahmed Hassan Awadallah and Ryen W White and Doug Burger and Chi Wang},
   doi = {10.48550/arXiv.2308.08155},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
   month = {10},
   note = {Comment: 43 pages (10 pages for the main text, 3 pages for references, and 30 pages for appendices)
arXiv:2308.08155 [cs]},
   publisher = {arXiv},
   title = {AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation},
   url = {http://arxiv.org/abs/2308.08155},
   year = {2023},
}
@misc{Li2023,
   abstract = {The rapid advancement of chat-based language models has led to remarkable progress in complex task-solving. However, their success heavily relies on human input to guide the conversation, which can be challenging and time-consuming. This paper explores the potential of building scalable techniques to facilitate autonomous cooperation among communicative agents, and provides insight into their "cognitive" processes. To address the challenges of achieving autonomous cooperation, we propose a novel communicative agent framework named role-playing. Our approach involves using inception prompting to guide chat agents toward task completion while maintaining consistency with human intentions. We showcase how role-playing can be used to generate conversational data for studying the behaviors and capabilities of a society of agents, providing a valuable resource for investigating conversational language models. In particular, we conduct comprehensive studies on instruction-following cooperation in multi-agent settings. Our contributions include introducing a novel communicative agent framework, offering a scalable approach for studying the cooperative behaviors and capabilities of multi-agent systems, and open-sourcing our library to support research on communicative agents and beyond: https://github.com/camel-ai/camel.},
   author = {Guohao Li and Hasan Abed Al Kader Hammoud and Hani Itani and Dmitrii Khizbullin and Bernard Ghanem},
   doi = {10.48550/arXiv.2303.17760},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computers and Society,Computer Science - Machine Learning,Computer Science - Multiagent Systems},
   month = {11},
   note = {Comment: Accepted at NeurIPS'2023, 77 pages, project website: https://www.camel-ai.org, github repository: https://github.com/camel-ai/camel
arXiv:2303.17760 [cs]},
   publisher = {arXiv},
   title = {CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society},
   url = {http://arxiv.org/abs/2303.17760},
   year = {2023},
}
@misc{Ouyang2022,
   abstract = {Making language models bigger does not inherently make them better at following a user's intent. For example, large language models can generate outputs that are untruthful, toxic, or simply not helpful to the user. In other words, these models are not aligned with their users. In this paper, we show an avenue for aligning language models with user intent on a wide range of tasks by fine-tuning with human feedback. Starting with a set of labeler-written prompts and prompts submitted through the OpenAI API, we collect a dataset of labeler demonstrations of the desired model behavior, which we use to fine-tune GPT-3 using supervised learning. We then collect a dataset of rankings of model outputs, which we use to further fine-tune this supervised model using reinforcement learning from human feedback. We call the resulting models InstructGPT. In human evaluations on our prompt distribution, outputs from the 1.3B parameter InstructGPT model are preferred to outputs from the 175B GPT-3, despite having 100x fewer parameters. Moreover, InstructGPT models show improvements in truthfulness and reductions in toxic output generation while having minimal performance regressions on public NLP datasets. Even though InstructGPT still makes simple mistakes, our results show that fine-tuning with human feedback is a promising direction for aligning language models with human intent.},
   author = {Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
   doi = {10.48550/arXiv.2203.02155},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
   month = {3},
   note = {arXiv:2203.02155 [cs]},
   publisher = {arXiv},
   title = {Training language models to follow instructions with human feedback},
   url = {http://arxiv.org/abs/2203.02155},
   year = {2022},
}
@misc{Schick2021,
   abstract = {To obtain high-quality sentence embeddings from pretrained language models (PLMs), they must either be augmented with additional pretraining objectives or finetuned on a large set of labeled text pairs. While the latter approach typically outperforms the former, it requires great human effort to generate suitable datasets of sufficient size. In this paper, we show how PLMs can be leveraged to obtain high-quality sentence embeddings without the need for labeled data, finetuning or modifications to the pretraining objective: We utilize the generative abilities of large and high-performing PLMs to generate entire datasets of labeled text pairs from scratch, which we then use for finetuning much smaller and more efficient models. Our fully unsupervised approach outperforms strong baselines on several semantic textual similarity datasets.},
   author = {Timo Schick and Hinrich Schütze},
   doi = {10.48550/arXiv.2104.07540},
   keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
   month = {10},
   note = {Comment: Accepted at EMNLP2021
arXiv:2104.07540 [cs]},
   publisher = {arXiv},
   title = {Generating Datasets with Pretrained Language Models},
   url = {http://arxiv.org/abs/2104.07540},
   year = {2021},
}
@misc{Chan2023,
   abstract = {Text evaluation has historically posed significant challenges, often demanding substantial labor and time cost. With the emergence of large language models (LLMs), researchers have explored LLMs' potential as alternatives for human evaluation. While these single-agent-based approaches show promise, experimental results suggest that further advancements are needed to bridge the gap between their current effectiveness and human-level evaluation quality. Recognizing that best practices of human evaluation processes often involve multiple human annotators collaborating in the evaluation, we resort to a multi-agent debate framework, moving beyond single-agent prompting strategies. The multi-agent-based approach enables a group of LLMs to synergize with an array of intelligent counterparts, harnessing their distinct capabilities and expertise to enhance efficiency and effectiveness in handling intricate tasks. In this paper, we construct a multi-agent referee team called ChatEval to autonomously discuss and evaluate the quality of generated responses from different models on open-ended questions and traditional natural language generation (NLG) tasks. Our analysis shows that ChatEval transcends mere textual scoring, offering a human-mimicking evaluation process for reliable assessments. Our code is available at https://github.com/chanchimin/ChatEval.},
   author = {Chi-Min Chan and Weize Chen and Yusheng Su and Jianxuan Yu and Wei Xue and Shanghang Zhang and Jie Fu and Zhiyuan Liu},
   doi = {10.48550/arXiv.2308.07201},
   keywords = {Computer Science - Computation and Language},
   month = {8},
   note = {arXiv:2308.07201 [cs]},
   publisher = {arXiv},
   title = {ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate},
   url = {http://arxiv.org/abs/2308.07201},
   year = {2023},
}
@misc{Du2023,
   abstract = {Large language models (LLMs) have demonstrated remarkable capabilities in language generation, understanding, and few-shot learning in recent years. An extensive body of work has explored how their performance may be further improved through the tools of prompting, ranging from verification, self-consistency, or intermediate scratchpads. In this paper, we present a complementary approach to improve language responses where multiple language model instances propose and debate their individual responses and reasoning processes over multiple rounds to arrive at a common final answer. Our findings indicate that this approach significantly enhances mathematical and strategic reasoning across a number of tasks. We also demonstrate that our approach improves the factual validity of generated content, reducing fallacious answers and hallucinations that contemporary models are prone to. Our approach may be directly applied to existing black-box models and uses identical procedure and prompts for all tasks we investigate. Overall, our findings suggest that such "society of minds" approach has the potential to significantly advance the capabilities of LLMs and pave the way for further breakthroughs in language generation and understanding.},
   author = {Yilun Du and Shuang Li and Antonio Torralba and Joshua B Tenenbaum and Igor Mordatch},
   doi = {10.48550/arXiv.2305.14325},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
   month = {5},
   note = {Comment: Project Webpage and Code: https://composable-models.github.io/llm_debate/
arXiv:2305.14325 [cs]},
   publisher = {arXiv},
   title = {Improving Factuality and Reasoning in Language Models through Multiagent Debate},
   url = {http://arxiv.org/abs/2305.14325},
   year = {2023},
}
@misc{Li2023,
   abstract = {Recent research has demonstrated that Large Language Models (LLMs) can enhance their capabilities by utilizing external tools. However, three pivotal questions remain unanswered: (1) How effective are current LLMs in utilizing tools? (2) How can we enhance LLMs' ability to utilize tools? (3) What obstacles need to be overcome to leverage tools? To address these questions, we introduce API-Bank, a groundbreaking benchmark, specifically designed for tool-augmented LLMs. For the first question, we develop a runnable evaluation system consisting of 73 API tools. We annotate 314 tool-use dialogues with 753 API calls to assess the existing LLMs' capabilities in planning, retrieving, and calling APIs. For the second question, we construct a comprehensive training set containing 1,888 tool-use dialogues from 2,138 APIs spanning 1,000 distinct domains. Using this dataset, we train Lynx, a tool-augmented LLM initialized from Alpaca. Experimental results demonstrate that GPT-3.5 exhibits improved tool utilization compared to GPT-3, while GPT-4 excels in planning. However, there is still significant potential for further improvement. Moreover, Lynx surpasses Alpaca's tool utilization performance by more than 26 pts and approaches the effectiveness of GPT-3.5. Through error analysis, we highlight the key challenges for future research in this field to answer the third question.},
   author = {Minghao Li and Yingxiu Zhao and Bowen Yu and Feifan Song and Hangyu Li and Haiyang Yu and Zhoujun Li and Fei Huang and Yongbin Li},
   doi = {10.48550/arXiv.2304.08244},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
   month = {10},
   note = {Comment: EMNLP 2023
arXiv:2304.08244 [cs]},
   publisher = {arXiv},
   title = {API-Bank: A Comprehensive Benchmark for Tool-Augmented LLMs},
   url = {http://arxiv.org/abs/2304.08244},
   year = {2023},
}
@misc{Zhao2023,
   abstract = {Language is essentially a complex, intricate system of human expressions governed by grammatical rules. It poses a significant challenge to develop capable AI algorithms for comprehending and grasping a language. As a major approach, language modeling has been widely studied for language understanding and generation in the past two decades, evolving from statistical language models to neural language models. Recently, pre-trained language models (PLMs) have been proposed by pre-training Transformer models over large-scale corpora, showing strong capabilities in solving various NLP tasks. Since researchers have found that model scaling can lead to performance improvement, they further study the scaling effect by increasing the model size to an even larger size. Interestingly, when the parameter scale exceeds a certain level, these enlarged language models not only achieve a significant performance improvement but also show some special abilities that are not present in small-scale language models. To discriminate the difference in parameter scale, the research community has coined the term large language models (LLM) for the PLMs of significant size. Recently, the research on LLMs has been largely advanced by both academia and industry, and a remarkable progress is the launch of ChatGPT, which has attracted widespread attention from society. The technical evolution of LLMs has been making an important impact on the entire AI community, which would revolutionize the way how we develop and use AI algorithms. In this survey, we review the recent advances of LLMs by introducing the background, key findings, and mainstream techniques. In particular, we focus on four major aspects of LLMs, namely pre-training, adaptation tuning, utilization, and capacity evaluation. Besides, we also summarize the available resources for developing LLMs and discuss the remaining issues for future directions.},
   author = {Wayne Xin Zhao and Kun Zhou and Junyi Li and Tianyi Tang and Xiaolei Wang and Yupeng Hou and Yingqian Min and Beichen Zhang and Junjie Zhang and Zican Dong and Yifan Du and Chen Yang and Yushuo Chen and Zhipeng Chen and Jinhao Jiang and Ruiyang Ren and Yifan Li and Xinyu Tang and Zikang Liu and Peiyu Liu and Jian-Yun Nie and Ji-Rong Wen},
   doi = {10.48550/arXiv.2303.18223},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
   month = {11},
   note = {Comment: ongoing work; 124 pages, 946 citations
arXiv:2303.18223 [cs]},
   publisher = {arXiv},
   title = {A Survey of Large Language Models},
   url = {http://arxiv.org/abs/2303.18223},
   year = {2023},
}
@misc{Song2023,
   abstract = {Tool-augmented large language models (LLMs) have achieved remarkable progress in tackling a broad range of tasks. However, existing methods are mainly restricted to specifically designed tools and fail to fulfill complex instructions, having great limitations when confronted with real-world scenarios. In this paper, we explore a more realistic scenario by connecting LLMs with RESTful APIs, which adhere to the widely adopted REST software architectural style for web service development. To address the practical challenges of tackling complex instructions, we propose RestGPT, which exploits the power of LLMs and conducts a coarse-to-fine online planning mechanism to enhance the abilities of task decomposition and API selection. RestGPT also contains an API executor tailored for calling RESTful APIs, which can meticulously formulate parameters and parse API responses. To fully evaluate the performance of RestGPT, we propose RestBench, a high-quality benchmark which consists of two real-world scenarios and human-annotated instructions with gold solution paths. Experiments show that RestGPT is able to achieve impressive results in complex tasks and has strong robustness, which paves a new way towards AGI. RestGPT and RestBench is publicly available at https://restgpt.github.io/.},
   author = {Yifan Song and Weimin Xiong and Dawei Zhu and Wenhao Wu and Han Qian and Mingbo Song and Hailiang Huang and Cheng Li and Ke Wang and Rong Yao and Ye Tian and Sujian Li},
   doi = {10.48550/arXiv.2306.06624},
   keywords = {Computer Science - Computation and Language},
   month = {8},
   note = {Comment: Add RestBench to evaluate RestGPT
arXiv:2306.06624 [cs]},
   publisher = {arXiv},
   title = {RestGPT: Connecting Large Language Models with Real-World RESTful APIs},
   url = {http://arxiv.org/abs/2306.06624},
   year = {2023},
}
@misc{Meyer2023,
   abstract = {Knowledge Graphs (KG) provide us with a structured, flexible, transparent, cross-system, and collaborative way of organizing our knowledge and data across various domains in society and industrial as well as scientific disciplines. KGs surpass any other form of representation in terms of effectiveness. However, Knowledge Graph Engineering (KGE) requires in-depth experiences of graph structures, web technologies, existing models and vocabularies, rule sets, logic, as well as best practices. It also demands a significant amount of work. Considering the advancements in large language models (LLMs) and their interfaces and applications in recent years, we have conducted comprehensive experiments with ChatGPT to explore its potential in supporting KGE. In this paper, we present a selection of these experiments and their results to demonstrate how ChatGPT can assist us in the development and management of KGs.},
   author = {Lars-Peter Meyer and Claus Stadler and Johannes Frey and Norman Radtke and Kurt Junghanns and Roy Meissner and Gordian Dziwis and Kirill Bulert and Michael Martin},
   doi = {10.48550/arXiv.2307.06917},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Databases},
   month = {7},
   note = {Comment: to appear in conference proceedings of AI-Tomorrow-23, 29.+30.6.2023 in Leipzig, Germany
arXiv:2307.06917 [cs]},
   publisher = {arXiv},
   title = {LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT},
   url = {http://arxiv.org/abs/2307.06917},
   year = {2023},
}
@misc{Wang2020,
   abstract = {This paper shows how to construct knowledge graphs (KGs) from pre-trained language models (e.g., BERT, GPT-2/3), without human supervision. Popular KGs (e.g, Wikidata, NELL) are built in either a supervised or semi-supervised manner, requiring humans to create knowledge. Recent deep language models automatically acquire knowledge from large-scale corpora via pre-training. The stored knowledge has enabled the language models to improve downstream NLP tasks, e.g., answering questions, and writing code and articles. In this paper, we propose an unsupervised method to cast the knowledge contained within language models into KGs. We show that KGs are constructed with a single forward pass of the pre-trained language models (without fine-tuning) over the corpora. We demonstrate the quality of the constructed KGs by comparing to two KGs (Wikidata, TAC KBP) created by humans. Our KGs also provide open factual knowledge that is new in the existing KGs. Our code and KGs will be made publicly available.},
   author = {Chenguang Wang and Xiao Liu and Dawn Song},
   doi = {10.48550/arXiv.2010.11967},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
   month = {10},
   note = {Comment: 30 pages, 32 figures, 3 tables
arXiv:2010.11967 [cs]},
   publisher = {arXiv},
   title = {Language Models are Open Knowledge Graphs},
   url = {http://arxiv.org/abs/2010.11967},
   year = {2020},
}
@misc{Agarwal2021,
   abstract = {Prior work on Data-To-Text Generation, the task of converting knowledge graph (KG) triples into natural text, focused on domain-specific benchmark datasets. In this paper, however, we verbalize the entire English Wikidata KG, and discuss the unique challenges associated with a broad, open-domain, large-scale verbalization. We further show that verbalizing a comprehensive, encyclopedic KG like Wikidata can be used to integrate structured KGs and natural language corpora. In contrast to the many architectures that have been developed to integrate these two sources, our approach converts the KG into natural text, allowing it to be seamlessly integrated into existing language models. It carries the further advantages of improved factual accuracy and reduced toxicity in the resulting language model. We evaluate this approach by augmenting the retrieval corpus in a retrieval language model and showing significant improvements on the knowledge intensive tasks of open domain QA and the LAMA knowledge probe.},
   author = {Oshin Agarwal and Heming Ge and Siamak Shakeri and Rami Al-Rfou},
   doi = {10.48550/arXiv.2010.12688},
   keywords = {Computer Science - Computation and Language},
   month = {3},
   note = {Comment: Accepted at NAACL 2021
arXiv:2010.12688 [cs]},
   publisher = {arXiv},
   title = {Knowledge Graph Based Synthetic Corpus Generation for Knowledge-Enhanced Language Model Pre-training},
   url = {http://arxiv.org/abs/2010.12688},
   year = {2021},
}
@misc{Wang2022,
   abstract = {Knowledge graph completion (KGC) aims to reason over known facts and infer the missing links. Text-based methods such as KGBERT (Yao et al., 2019) learn entity representations from natural language descriptions, and have the potential for inductive KGC. However, the performance of text-based methods still largely lag behind graph embedding-based methods like TransE (Bordes et al., 2013) and RotatE (Sun et al., 2019b). In this paper, we identify that the key issue is efficient contrastive learning. To improve the learning efficiency, we introduce three types of negatives: in-batch negatives, pre-batch negatives, and self-negatives which act as a simple form of hard negatives. Combined with InfoNCE loss, our proposed model SimKGC can substantially outperform embedding-based methods on several benchmark datasets. In terms of mean reciprocal rank (MRR), we advance the state-of-the-art by +19\% on WN18RR, +6.8\% on the Wikidata5M transductive setting, and +22\% on the Wikidata5M inductive setting. Thorough analyses are conducted to gain insights into each component. Our code is available at https://github.com/intfloat/SimKGC .},
   author = {Liang Wang and Wei Zhao and Zhuoyu Wei and Jingming Liu},
   doi = {10.48550/arXiv.2203.02167},
   keywords = {Computer Science - Computation and Language},
   month = {3},
   note = {Comment: ACL 2022, 14 pages
arXiv:2203.02167 [cs]},
   publisher = {arXiv},
   title = {SimKGC: Simple Contrastive Knowledge Graph Completion with Pre-trained Language Models},
   url = {http://arxiv.org/abs/2203.02167},
   year = {2022},
}
@misc{hao2023,
   abstract = {Accurately recommending candidate news articles to users is a basic challenge faced by personalized news recommendation systems. Traditional methods are usually difficult to grasp the complex semantic information in news texts, resulting in unsatisfactory recommendation results. Besides, these traditional methods are more friendly to active users with rich historical behaviors. However, they can not effectively solve the "long tail problem" of inactive users. To address these issues, this research presents a novel general framework that combines Large Language Models (LLM) and Knowledge Graphs (KG) into semantic representations of traditional methods. In order to improve semantic understanding in complex news texts, we use LLMs' powerful text understanding ability to generate news representations containing rich semantic information. In addition, our method combines the information about news entities and mines high-order structural information through multiple hops in KG, thus alleviating the challenge of long tail distribution. Experimental results demonstrate that compared with various traditional models, the framework significantly improves the recommendation effect. The successful integration of LLM and KG in our framework has established a feasible path for achieving more accurate personalized recommendations in the news field. Our code is available at https://github.com/Xuan-ZW/LKPNR.},
   author = {Chen hao and Xie Runfeng and Cui Xiangyang and Yan Zhou and Wang Xin and Xuan Zhanwei and Zhang Kai},
   doi = {10.48550/arXiv.2308.12028},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Information Retrieval},
   month = {8},
   note = {arXiv:2308.12028 [cs]},
   publisher = {arXiv},
   title = {LKPNR: LLM and KG for Personalized News Recommendation Framework},
   url = {http://arxiv.org/abs/2308.12028},
   year = {2023},
}
@misc{Hao2023,
   abstract = {Augmenting large language models (LLMs) with external tools has emerged as a promising approach to solving complex problems. However, traditional methods, which finetune LLMs with tool demonstration data, can be both costly and restricted to a predefined set of tools. Recent in-context learning paradigm alleviates these issues, but the limited context length only allows for a few shots of demonstrations, leading to suboptimal understandings of the tools. Moreover, when there are numerous tools to choose from, in-context learning could completely fail to work. In this paper, we propose an alternative approach, \$\{\textbackslash\}textbf\{ToolkenGPT\}$, which combines the benefits of both sides. Our approach represents each \$\{\textbackslash\}underline\{tool\}$ as a to\$\{\textbackslash\}underline\{ken\}$ (\$\{\textbackslash\}textit\{toolken\}$) and learns an embedding for it, enabling tool calls in the same way as generating a regular word token. Once a toolken is triggered, the LLM is prompted to complete arguments for the tool to execute. ToolkenGPT offers the flexibility to plug in an arbitrary number of tools by expanding the set of toolkens on the fly. In addition, it improves tool use by allowing extensive demonstration data for learning the toolken embeddings. In diverse domains, including numerical reasoning, knowledge-based question answering, and embodied plan generation, our approach effectively augments LLMs with tools and substantially outperforms various latest baselines. ToolkenGPT demonstrates the promising ability to use relevant tools from a large tool set in complex scenarios.},
   author = {Shibo Hao and Tianyang Liu and Zhen Wang and Zhiting Hu},
   doi = {10.48550/arXiv.2305.11554},
   keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
   month = {10},
   note = {Comment: NeurIPS 2023 (oral). Code: https://github.com/Ber666/ToolkenGPT
arXiv:2305.11554 [cs]},
   publisher = {arXiv},
   title = {ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings},
   url = {http://arxiv.org/abs/2305.11554},
   year = {2023},
}
@article{Gutierrez2021,
   abstract = {Tracking the historical events that lead to the interweaving of data and knowledge.},
   author = {Claudio Gutierrez and Juan F Sequeda},
   doi = {10.1145/3418294},
   issn = {0001-0782},
   issue = {3},
   journal = {Communications of the ACM},
   month = {2},
   pages = {96-104},
   title = {Knowledge graphs},
   volume = {64},
   url = {https://doi.org/10.1145/3418294},
   year = {2021},
}
@inproceedings{Yang2015,
   abstract = {Many search engine users attempt to satisfy an information need by issuing multiple queries, with the expectation that each result will contribute some portion of the required information. Previous research has shown that structured or semi-structured descriptive knowledge bases (such as Wikipedia) can be used to improve search quality and experience for general or entity-centric queries. However, such resources do not have sufficient coverage of procedural knowledge, i.e. what actions should be performed and what factors should be considered to achieve some goal; such procedural knowledge is crucial when responding to task-oriented search queries. This paper provides a first attempt to bridge the gap between two evolving research areas: development of procedural knowledge bases (such as wikiHow) and task-oriented search. We investigate whether task-oriented search can benefit from existing procedural knowledge (search task suggestion) and whether automatic procedural knowledge construction can benefit from users' search activities (automatic procedural knowledge base construction). We propose to create a three-way parallel corpus of queries, query contexts, and task descriptions, and reduce both problems to sequence labeling tasks. We propose a set of textual features and structural features to identify key search phrases from task descriptions, and then adapt similar features to extract wikiHow-style procedural knowledge descriptions from search queries and relevant text snippets. We compare our proposed solution with baseline algorithms, commercial search engines, and the (manually-curated) wikiHow procedural knowledge; experimental results show an improvement of +0.28 to +0.41 in terms of Precision@8 and mean average precision (MAP).},
   author = {Zi Yang and Eric Nyberg},
   city = {New York, NY, USA},
   doi = {10.1145/2766462.2767744},
   isbn = {978-1-4503-3621-5},
   booktitle = {Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
   keywords = {procedural knowledge base,query suggestion,search intent,search log,wikihow},
   month = {8},
   pages = {513-522},
   publisher = {Association for Computing Machinery},
   title = {Leveraging Procedural Knowledge for Task-oriented Search},
   url = {https://doi.org/10.1145/2766462.2767744},
   year = {2015},
}
@article{Guan2023,
   abstract = {Besides entity-centric knowledge, usually organized as Knowledge Graph (KG), events are also an essential kind of knowledge in the world, which trigger the spring up of event-centric knowledge representation form like Event KG (EKG). It plays an increasingly important role in many downstream applications, such as search, question-answering, recommendation, financial quantitative investments, and text generation. This paper provides a comprehensive survey of EKG from history, ontology, instance, and application views. Specifically, to characterize EKG thoroughly, we focus on its history, definition, schema induction, acquisition, related representative graphs/systems, and applications. The development processes and trends are studied therein. We further summarize prospective directions to facilitate future research on EKG.},
   author = {Saiping Guan and Xueqi Cheng and Long Bai and Fujun Zhang and Zixuan Li and Yutao Zeng and Xiaolong Jin and Jiafeng Guo},
   doi = {10.1109/TKDE.2022.3180362},
   issn = {1558-2191},
   issue = {7},
   journal = {IEEE Transactions on Knowledge and Data Engineering},
   month = {7},
   note = {Conference Name: IEEE Transactions on Knowledge and Data Engineering},
   pages = {7569-7589},
   title = {What is Event Knowledge Graph: A Survey},
   volume = {35},
   url = {https://ieeexplore.ieee.org/abstract/document/9792280},
   year = {2023},
}
@misc{Luo2023,
   abstract = {Logical rules are essential for uncovering the logical connections between relations, which could improve the reasoning performance and provide interpretable results on knowledge graphs (KGs). Although there have been many efforts to mine meaningful logical rules over KGs, existing methods suffer from the computationally intensive searches over the rule space and a lack of scalability for large-scale KGs. Besides, they often ignore the semantics of relations which is crucial for uncovering logical connections. Recently, large language models (LLMs) have shown impressive performance in the field of natural language processing and various applications, owing to their emergent ability and generalizability. In this paper, we propose a novel framework, ChatRule, unleashing the power of large language models for mining logical rules over knowledge graphs. Specifically, the framework is initiated with an LLM-based rule generator, leveraging both the semantic and structural information of KGs to prompt LLMs to generate logical rules. To refine the generated rules, a rule ranking module estimates the rule quality by incorporating facts from existing KGs. Last, a rule validator harnesses the reasoning ability of LLMs to validate the logical correctness of ranked rules through chain-of-thought reasoning. ChatRule is evaluated on four large-scale KGs, w.r.t. different rule quality metrics and downstream tasks, showing the effectiveness and scalability of our method.},
   author = {Linhao Luo and Jiaxin Ju and Bo Xiong and Yuan-Fang Li and Gholamreza Haffari and Shirui Pan},
   doi = {10.48550/arXiv.2309.01538},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
   month = {9},
   note = {Comment: 11 pages, 4 figures
arXiv:2309.01538 [cs]},
   publisher = {arXiv},
   title = {ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning},
   url = {http://arxiv.org/abs/2309.01538},
   year = {2023},
}
@misc{Luo2023,
   abstract = {Large language models (LLMs) have demonstrated impressive reasoning abilities in complex tasks. However, they lack up-to-date knowledge and experience hallucinations during reasoning, which can lead to incorrect reasoning processes and diminish their performance and trustworthiness. Knowledge graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM reasoning methods only treat KGs as factual knowledge bases and overlook the importance of their structural information for reasoning. In this paper, we propose a novel method called reasoning on graphs (RoG) that synergizes LLMs with KGs to enable faithful and interpretable reasoning. Specifically, we present a planning-retrieval-reasoning framework, where RoG first generates relation paths grounded by KGs as faithful plans. These plans are then used to retrieve valid reasoning paths from the KGs for LLMs to conduct faithful reasoning. Furthermore, RoG not only distills knowledge from KGs to improve the reasoning ability of LLMs through training but also allows seamless integration with any arbitrary LLMs during inference. Extensive experiments on two benchmark KGQA datasets demonstrate that RoG achieves state-of-the-art performance on KG reasoning tasks and generates faithful and interpretable reasoning results.},
   author = {Linhao Luo and Yuan-Fang Li and Gholamreza Haffari and Shirui Pan},
   doi = {10.48550/arXiv.2310.01061},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
   month = {10},
   note = {Comment: 22 pages, 4 figures
arXiv:2310.01061 [cs]},
   publisher = {arXiv},
   title = {Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning},
   url = {http://arxiv.org/abs/2310.01061},
   year = {2023},
}
@misc{Zhen2022,
   abstract = {Natural Language Processing (NLP) has been revolutionized by the use of Pre-trained Language Models (PLMs) such as BERT. Despite setting new records in nearly every NLP task, PLMs still face a number of challenges including poor interpretability, weak reasoning capability, and the need for a lot of expensive annotated data when applied to downstream tasks. By integrating external knowledge into PLMs, \textit\\{\{\textbackslash\}underline\{K\}nowledge-\underline\{E\}nhanced \underline\{P\}re-trained \underline\{L\}anguage \underline\{M\}odels\} (KEPLMs) have the potential to overcome the above-mentioned limitations. In this paper, we examine KEPLMs systematically through a series of studies. Specifically, we outline the common types and different formats of knowledge to be integrated into KEPLMs, detail the existing methods for building and evaluating KEPLMS, present the applications of KEPLMs in downstream tasks, and discuss the future research directions. Researchers will benefit from this survey by gaining a quick and comprehensive overview of the latest developments in this field.},
   author = {Chaoqi Zhen and Yanlei Shang and Xiangyu Liu and Yifei Li and Yong Chen and Dell Zhang},
   keywords = {Computer Science - Computation and Language},
   month = {12},
   note = {Comment: 19 pages, 12 figures, 192 references
arXiv:2212.13428 [cs]},
   publisher = {arXiv},
   title = {A Survey on Knowledge-Enhanced Pre-trained Language Models},
   url = {http://arxiv.org/abs/2212.13428},
   year = {2022},
}
@misc{AlKhamissi2022,
   abstract = {Recently, there has been a surge of interest in the NLP community on the use of pretrained Language Models (LMs) as Knowledge Bases (KBs). Researchers have shown that LMs trained on a sufficiently large (web) corpus will encode a significant amount of knowledge implicitly in its parameters. The resulting LM can be probed for different kinds of knowledge and thus acting as a KB. This has a major advantage over traditional KBs in that this method requires no human supervision. In this paper, we present a set of aspects that we deem a LM should have to fully act as a KB, and review the recent literature with respect to those aspects.},
   author = {Badr AlKhamissi and Millicent Li and Asli Celikyilmaz and Mona Diab and Marjan Ghazvininejad},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
   month = {4},
   note = {Comment: Preprint
arXiv:2204.06031 [cs]},
   publisher = {arXiv},
   title = {A Review on Language Models as Knowledge Bases},
   url = {http://arxiv.org/abs/2204.06031},
   year = {2022},
}
@misc{Ye2023,
   abstract = {Generative Knowledge Graph Construction (KGC) refers to those methods that leverage the sequence-to-sequence framework for building knowledge graphs, which is flexible and can be adapted to widespread tasks. In this study, we summarize the recent compelling progress in generative knowledge graph construction. We present the advantages and weaknesses of each paradigm in terms of different generation targets and provide theoretical insight and empirical analysis. Based on the review, we suggest promising research directions for the future. Our contributions are threefold: (1) We present a detailed, complete taxonomy for the generative KGC methods; (2) We provide a theoretical and empirical analysis of the generative KGC methods; (3) We propose several research directions that can be developed in the future.},
   author = {Hongbin Ye and Ningyu Zhang and Hui Chen and Huajun Chen},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Databases,Computer Science - Information Retrieval,Computer Science - Machine Learning},
   month = {9},
   note = {Comment: Accepted to EMNLP 2022 (oral) and a public repository is available in https://github.com/zjunlp/Generative_KG_Construction_Papers
arXiv:2210.12714 [cs]},
   publisher = {arXiv},
   title = {Generative Knowledge Graph Construction: A Review},
   url = {http://arxiv.org/abs/2210.12714},
   year = {2023},
}
@misc{Wei2021,
   abstract = {Pretrained Language Models (PLM) have established a new paradigm through learning informative contextualized representations on large-scale text corpus. This new paradigm has revolutionized the entire field of natural language processing, and set the new state-of-the-art performance for a wide variety of NLP tasks. However, though PLMs could store certain knowledge/facts from training corpus, their knowledge awareness is still far from satisfactory. To address this issue, integrating knowledge into PLMs have recently become a very active research area and a variety of approaches have been developed. In this paper, we provide a comprehensive survey of the literature on this emerging and fast-growing field - Knowledge Enhanced Pretrained Language Models (KE-PLMs). We introduce three taxonomies to categorize existing work. Besides, we also survey the various NLU and NLG applications on which KE-PLM has demonstrated superior performance over vanilla PLMs. Finally, we discuss challenges that face KE-PLMs and also promising directions for future research.},
   author = {Xiaokai Wei and Shen Wang and Dejiao Zhang and Parminder Bhatia and Andrew Arnold},
   keywords = {Computer Science - Computation and Language},
   month = {10},
   note = {arXiv:2110.08455 [cs]},
   publisher = {arXiv},
   title = {Knowledge Enhanced Pretrained Language Models: A Compreshensive Survey},
   url = {http://arxiv.org/abs/2110.08455},
   year = {2021},
}
@misc{Wang2023,
   abstract = {Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9\%), SVAMP (+11.0\%), AQuA (+12.2\%), StrategyQA (+6.4\%) and ARC-challenge (+3.9\%).},
   author = {Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc Le and Ed Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
   doi = {10.48550/arXiv.2203.11171},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
   month = {3},
   note = {Comment: Published at ICLR 2023. V2: added PaLM results; V3: added UL2 results; V4: camera ready version at ICLR 2023
arXiv:2203.11171 [cs]},
   publisher = {arXiv},
   title = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
   url = {http://arxiv.org/abs/2203.11171},
   year = {2023},
}
@article{Wei2022,
   author = {Jason Wei and Xuezhi Wang and Dale Schuurmans and Maarten Bosma and Brian Ichter and Fei Xia and Ed Chi and Quoc V Le and Denny Zhou},
   journal = {Advances in Neural Information Processing Systems},
   month = {12},
   pages = {24824-24837},
   title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
   volume = {35},
   url = {https://proceedings.neurips.cc/paper_files/paper/2022/hash/9d5609613524ecf4f15af0f7b31abca4-Abstract-Conference.html},
   year = {2022},
}
@misc{Yao2023,
   abstract = {While large language models (LLMs) have demonstrated impressive capabilities across tasks in language understanding and interactive decision making, their abilities for reasoning (e.g. chain-of-thought prompting) and acting (e.g. action plan generation) have primarily been studied as separate topics. In this paper, we explore the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner, allowing for greater synergy between the two: reasoning traces help the model induce, track, and update action plans as well as handle exceptions, while actions allow it to interface with external sources, such as knowledge bases or environments, to gather additional information. We apply our approach, named ReAct, to a diverse set of language and decision making tasks and demonstrate its effectiveness over state-of-the-art baselines, as well as improved human interpretability and trustworthiness over methods without reasoning or acting components. Concretely, on question answering (HotpotQA) and fact verification (Fever), ReAct overcomes issues of hallucination and error propagation prevalent in chain-of-thought reasoning by interacting with a simple Wikipedia API, and generates human-like task-solving trajectories that are more interpretable than baselines without reasoning traces. On two interactive decision making benchmarks (ALFWorld and WebShop), ReAct outperforms imitation and reinforcement learning methods by an absolute success rate of 34\% and 10\% respectively, while being prompted with only one or two in-context examples. Project site with code: https://react-lm.github.io},
   author = {Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik Narasimhan and Yuan Cao},
   doi = {10.48550/arXiv.2210.03629},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
   month = {3},
   note = {Comment: v3 is the ICLR camera ready version with some typos fixed. Project site with code: https://react-lm.github.io
arXiv:2210.03629 [cs]},
   publisher = {arXiv},
   title = {ReAct: Synergizing Reasoning and Acting in Language Models},
   url = {http://arxiv.org/abs/2210.03629},
   year = {2023},
}
@misc{Shridhar2021,
   abstract = {Given a simple request like Put a washed apple in the kitchen fridge, humans can reason in purely abstract terms by imagining action sequences and scoring their likelihood of success, prototypicality, and efficiency, all without moving a muscle. Once we see the kitchen in question, we can update our abstract plans to fit the scene. Embodied agents require the same abilities, but existing work does not yet provide the infrastructure necessary for both reasoning abstractly and executing concretely. We address this limitation by introducing ALFWorld, a simulator that enables agents to learn abstract, text based policies in TextWorld (C\ot\'e et al., 2018) and then execute goals from the ALFRED benchmark (Shridhar et al., 2020) in a rich visual environment. ALFWorld enables the creation of a new BUTLER agent whose abstract knowledge, learned in TextWorld, corresponds directly to concrete, visually grounded actions. In turn, as we demonstrate empirically, this fosters better agent generalization than training only in the visually grounded environment. BUTLER's simple, modular design factors the problem to allow researchers to focus on models for improving every piece of the pipeline (language understanding, planning, navigation, and visual scene understanding).},
   author = {Mohit Shridhar and Xingdi Yuan and Marc-Alexandre Côté and Yonatan Bisk and Adam Trischler and Matthew Hausknecht},
   doi = {10.48550/arXiv.2010.03768},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Robotics},
   month = {3},
   note = {Comment: ICLR 2021; Data, code, and videos are available at alfworld.github.io
arXiv:2010.03768 [cs]},
   publisher = {arXiv},
   title = {ALFWorld: Aligning Text and Embodied Environments for Interactive Learning},
   url = {http://arxiv.org/abs/2010.03768},
   year = {2021},
}
@misc{Wang2023,
   abstract = {We introduce Voyager, the first LLM-powered embodied lifelong learning agent in Minecraft that continuously explores the world, acquires diverse skills, and makes novel discoveries without human intervention. Voyager consists of three key components: 1) an automatic curriculum that maximizes exploration, 2) an ever-growing skill library of executable code for storing and retrieving complex behaviors, and 3) a new iterative prompting mechanism that incorporates environment feedback, execution errors, and self-verification for program improvement. Voyager interacts with GPT-4 via blackbox queries, which bypasses the need for model parameter fine-tuning. The skills developed by Voyager are temporally extended, interpretable, and compositional, which compounds the agent's abilities rapidly and alleviates catastrophic forgetting. Empirically, Voyager shows strong in-context lifelong learning capability and exhibits exceptional proficiency in playing Minecraft. It obtains 3.3x more unique items, travels 2.3x longer distances, and unlocks key tech tree milestones up to 15.3x faster than prior SOTA. Voyager is able to utilize the learned skill library in a new Minecraft world to solve novel tasks from scratch, while other techniques struggle to generalize. We open-source our full codebase and prompts at https://voyager.minedojo.org/.},
   author = {Guanzhi Wang and Yuqi Xie and Yunfan Jiang and Ajay Mandlekar and Chaowei Xiao and Yuke Zhu and Linxi Fan and Anima Anandkumar},
   doi = {10.48550/arXiv.2305.16291},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
   month = {10},
   note = {Comment: Project website and open-source codebase: https://voyager.minedojo.org/
arXiv:2305.16291 [cs]},
   publisher = {arXiv},
   title = {Voyager: An Open-Ended Embodied Agent with Large Language Models},
   url = {http://arxiv.org/abs/2305.16291},
   year = {2023},
}
@misc{Yao2023,
   abstract = {Existing benchmarks for grounding language in interactive environments either lack real-world linguistic elements, or prove difficult to scale up due to substantial human involvement in the collection of data or feedback signals. To bridge this gap, we develop WebShop – a simulated e-commerce website environment with $1.18$ million real-world products and $12,087$ crowd-sourced text instructions. Given a text instruction specifying a product requirement, an agent needs to navigate multiple types of webpages and issue diverse actions to find, customize, and purchase an item. WebShop provides several challenges for language grounding including understanding compositional instructions, query (re-)formulation, comprehending and acting on noisy text in webpages, and performing strategic exploration. We collect over $1,600$ human demonstrations for the task, and train and evaluate a diverse range of agents using reinforcement learning, imitation learning, and pre-trained image and language models. Our best model achieves a task success rate of $29\%$, which outperforms rule-based heuristics ($9.6\%$) but is far lower than human expert performance ($59\%$). We also analyze agent and human trajectories and ablate various model components to provide insights for developing future agents with stronger language understanding and decision making abilities. Finally, we show that agents trained on WebShop exhibit non-trivial sim-to-real transfer when evaluated on amazon.com and ebay.com, indicating the potential value of WebShop in developing practical web-based agents that can operate in the wild.},
   author = {Shunyu Yao and Howard Chen and John Yang and Karthik Narasimhan},
   doi = {10.48550/arXiv.2207.01206},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
   month = {2},
   note = {Comment: Project page with code, data, demos: https://webshop-pnlp.github.io. v3 is NeurIPS camera ready version. v4 fixes the choice oracle result as per https://github.com/princeton-nlp/WebShop/issues/15
arXiv:2207.01206 [cs]},
   publisher = {arXiv},
   title = {WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents},
   url = {http://arxiv.org/abs/2207.01206},
   year = {2023},
}
@misc{Zhou2023,
   abstract = {With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41\%, significantly lower than the human performance of 78.24\%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.},
   author = {Shuyan Zhou and Frank F Xu and Hao Zhu and Xuhui Zhou and Robert Lo and Abishek Sridhar and Xianyi Cheng and Tianyue Ou and Yonatan Bisk and Daniel Fried and Uri Alon and Graham Neubig},
   doi = {10.48550/arXiv.2307.13854},
   keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
   month = {10},
   note = {Comment: Our code, data, environment reproduction resources, and video demonstrations are publicly available at https://webarena.dev/
arXiv:2307.13854 [cs]},
   publisher = {arXiv},
   title = {WebArena: A Realistic Web Environment for Building Autonomous Agents},
   url = {http://arxiv.org/abs/2307.13854},
   year = {2023},
}
@article{Xi2023,
   abstract = {For a long time, humanity has pursued artificial intelligence (AI) equivalent to or surpassing the human level, with AI agents considered a promising vehicle for this pursuit. AI agents are artificial entities that sense their environment, make decisions, and take actions. Many efforts have been made to develop intelligent agents, but they mainly focus on advancement in algorithms or training strategies to enhance specific capabilities or performance on particular tasks. Actually, what the community lacks is a general and powerful model to serve as a starting point for designing AI agents that can adapt to diverse scenarios. Due to the versatile capabilities they demonstrate, large language models (LLMs) are regarded as potential sparks for Artificial General Intelligence (AGI), offering hope for building general AI agents. Many researchers have leveraged LLMs as the foundation to build AI agents and have achieved significant progress. In this paper, we perform a comprehensive survey on LLM-based agents. We start by tracing the concept of agents from its philosophical origins to its development in AI, and explain why LLMs are suitable foundations for agents. Building upon this, we present a general framework for LLM-based agents, comprising three main components: brain, perception, and action, and the framework can be tailored for different applications. Subsequently, we explore the extensive applications of LLM-based agents in three aspects: single-agent scenarios, multi-agent scenarios, and human-agent cooperation. Following this, we delve into agent societies, exploring the behavior and personality of LLM-based agents, the social phenomena that emerge from an agent society, and the insights they offer for human society. Finally, we discuss several key topics and open problems within the field. A repository for the related papers at https://github.com/WooooDyy/LLM-Agent-Paper-List.},
   author = {Zhiheng Xi and Wenxiang Chen and Xin Guo and Wei He and Yiwen Ding and Boyang Hong and Ming Zhang and Junzhe Wang and Senjie Jin and Enyu Zhou and Rui Zheng and Xiaoran Fan and Xiao Wang and Limao Xiong and Yuhao Zhou and Weiran Wang and Changhao Jiang and Yicheng Zou and Xiangyang Liu and Zhangyue Yin and Shihan Dou and Rongxiang Weng and Wensen Cheng and Qi Zhang and Wenjuan Qin and Yongyan Zheng and Xipeng Qiu and Xuanjing Huang and Tao Gui},
   month = {9},
   title = {The Rise and Potential of Large Language Model Based Agents: A Survey},
   year = {2023},
}
@article{Wang2023,
   abstract = {Autonomous agents have long been a prominent research focus in both academic and industry communities. Previous research in this field often focuses on training agents with limited knowledge within isolated environments, which diverges significantly from human learning processes, and thus makes the agents hard to achieve human-like decisions. Recently, through the acquisition of vast amounts of web knowledge, large language models (LLMs) have demonstrated remarkable potential in achieving human-level intelligence. This has sparked an upsurge in studies investigating LLM-based autonomous agents. In this paper, we present a comprehensive survey of these studies, delivering a systematic review of the field of LLM-based autonomous agents from a holistic perspective. More specifically, we first discuss the construction of LLM-based autonomous agents, for which we propose a unified framework that encompasses a majority of the previous work. Then, we present a comprehensive overview of the diverse applications of LLM-based autonomous agents in the fields of social science, natural science, and engineering. Finally, we delve into the evaluation strategies commonly used for LLM-based autonomous agents. Based on the previous studies, we also present several challenges and future directions in this field. To keep track of this field and continuously update our survey, we maintain a repository of relevant references at https://github.com/Paitesanshi/LLM-Agent-Survey.},
   author = {Lei Wang and Chen Ma and Xueyang Feng and Zeyu Zhang and Hao Yang and Jingsen Zhang and Zhiyuan Chen and Jiakai Tang and Xu Chen and Yankai Lin and Wayne Xin Zhao and Zhewei Wei and Ji-Rong Wen},
   month = {8},
   title = {A Survey on Large Language Model based Autonomous Agents},
   year = {2023},
}
@article{Yao2023,
   abstract = {Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4\% of tasks, our method achieved a success rate of 74\%. Code repo with all prompts: https://github.com/ysymyth/tree-of-thought-llm.},
   author = {Shunyu Yao and Dian Yu and Jeffrey Zhao and Izhak Shafran and Thomas L. Griffiths and Yuan Cao and Karthik Narasimhan},
   month = {5},
   title = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
   year = {2023},
}
@article{Schick2023,
   abstract = {Language models (LMs) exhibit remarkable abilities to solve new tasks from just a few examples or textual instructions, especially at scale. They also, paradoxically, struggle with basic functionality, such as arithmetic or factual lookup, where much simpler and smaller models excel. In this paper, we show that LMs can teach themselves to use external tools via simple APIs and achieve the best of both worlds. We introduce Toolformer, a model trained to decide which APIs to call, when to call them, what arguments to pass, and how to best incorporate the results into future token prediction. This is done in a self-supervised way, requiring nothing more than a handful of demonstrations for each API. We incorporate a range of tools, including a calculator, a Q\&A system, two different search engines, a translation system, and a calendar. Toolformer achieves substantially improved zero-shot performance across a variety of downstream tasks, often competitive with much larger models, without sacrificing its core language modeling abilities.},
   author = {Timo Schick and Jane Dwivedi-Yu and Roberto Dessì and Roberta Raileanu and Maria Lomeli and Luke Zettlemoyer and Nicola Cancedda and Thomas Scialom},
   month = {2},
   title = {Toolformer: Language Models Can Teach Themselves to Use Tools},
   url = {https://arxiv.org/abs/2302.04761v1},
   year = {2023},
}
@article{Tang2023,
   abstract = {Enabling large language models to utilize real-world tools effectively is crucial for achieving embodied intelligence. Existing approaches to tool learning have either primarily relied on extremely large language models, such as GPT-4, to attain generalized tool-use abilities in a zero-shot manner, or utilized supervised learning to train limited scopes of tools on compact models. However, it remains uncertain whether smaller language models can achieve generalized tool-use abilities without tool-specific training. To address this question, this paper introduces ToolAlpaca, a novel framework designed to automatically generate a diverse tool-use corpus and learn generalized tool-use abilities on compact language models with minimal human intervention. Specifically, ToolAlpaca first automatically creates a highly diversified tool-use corpus by building a multi-agent simulation environment. The corpus contains 3938 tool-use instances from more than 400 real-world tool APIs spanning 50 distinct categories. Subsequently, the constructed corpus is employed to fine-tune compact language models, resulting in two models, namely ToolAlpaca-7B and ToolAlpaca-13B, respectively. Finally, we evaluate the ability of these models to utilize previously unseen tools without specific training. Experimental results demonstrate that ToolAlpaca achieves effective generalized tool-use capabilities comparable to those of extremely large language models like GPT-3.5, demonstrating that learning generalized tool-use ability is feasible for compact language models.},
   author = {Qiaoyu Tang and Ziliang Deng and Hongyu Lin and Xianpei Han and Qiao Liang and Boxi Cao and Le Sun},
   month = {6},
   title = {ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases},
   url = {https://arxiv.org/abs/2306.05301v2},
   year = {2023},
}
@article{Zeng2023,
   abstract = {Open large language models (LLMs) with great performance in various tasks have significantly advanced the development of LLMs. However, they are far inferior to commercial models such as ChatGPT and GPT-4 when acting as agents to tackle complex tasks in the real world. These agent tasks employ LLMs as the central controller responsible for planning, memorization, and tool utilization, necessitating both fine-grained prompting methods and robust LLMs to achieve satisfactory performance. Though many prompting methods have been proposed to complete particular agent tasks, there is lack of research focusing on improving the agent capabilities of LLMs themselves without compromising their general abilities. In this work, we present AgentTuning, a simple and general method to enhance the agent abilities of LLMs while maintaining their general LLM capabilities. We construct AgentInstruct, a lightweight instruction-tuning dataset containing high-quality interaction trajectories. We employ a hybrid instruction-tuning strategy by combining AgentInstruct with open-source instructions from general domains. AgentTuning is used to instruction-tune the Llama 2 series, resulting in AgentLM. Our evaluations show that AgentTuning enables LLMs' agent capabilities without compromising general abilities. The AgentLM-70B is comparable to GPT-3.5-turbo on unseen agent tasks, demonstrating generalized agent capabilities. We open source the AgentInstruct and AgentLM-7B, 13B, and 70B models at https://github.com/THUDM/AgentTuning, serving open and powerful alternatives to commercial LLMs for agent tasks.},
   author = {Aohan Zeng and Mingdao Liu and Rui Lu and Bowen Wang and Xiao Liu and Yuxiao Dong and Jie Tang},
   month = {10},
   title = {AgentTuning: Enabling Generalized Agent Abilities for LLMs},
   url = {https://arxiv.org/abs/2310.12823v2},
   year = {2023},
}
@article{OpenAI2023,
   abstract = {We report the development of GPT-4, a large-scale, multimodal model which can accept image and text inputs and produce text outputs. While less capable than humans in many real-world scenarios, GPT-4 exhibits human-level performance on various professional and academic benchmarks, including passing a simulated bar exam with a score around the top 10\% of test takers. GPT-4 is a Transformer-based model pre-trained to predict the next token in a document. The post-training alignment process results in improved performance on measures of factuality and adherence to desired behavior. A core component of this project was developing infrastructure and optimization methods that behave predictably across a wide range of scales. This allowed us to accurately predict some aspects of GPT-4's performance based on models trained with no more than 1/1,000th the compute of GPT-4.},
   author = {OpenAI},
   month = {3},
   title = {GPT-4 Technical Report},
   url = {https://arxiv.org/abs/2303.08774v3},
   year = {2023},
}
@misc{,
   title = {Introducing ChatGPT},
   url = {https://openai.com/blog/chatgpt},
}
@article{Touvron2023,
   abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.},
   author = {Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
   month = {2},
   title = {LLaMA: Open and Efficient Foundation Language Models},
   url = {https://arxiv.org/abs/2302.13971v1},
   year = {2023},
}
@article{Zhang2023,
   abstract = {While large language models (LLMs) have demonstrated remarkable capabilities across a range of downstream tasks, a significant concern revolves around their propensity to exhibit hallucinations: LLMs occasionally generate content that diverges from the user input, contradicts previously generated context, or misaligns with established world knowledge. This phenomenon poses a substantial challenge to the reliability of LLMs in real-world scenarios. In this paper, we survey recent efforts on the detection, explanation, and mitigation of hallucination, with an emphasis on the unique challenges posed by LLMs. We present taxonomies of the LLM hallucination phenomena and evaluation benchmarks, analyze existing approaches aiming at mitigating LLM hallucination, and discuss potential directions for future research.},
   author = {Yue Zhang and Yafu Li and Leyang Cui and Deng Cai and Lemao Liu and Tingchen Fu and Xinting Huang and Enbo Zhao and Yu Zhang and Yulong Chen and Longyue Wang and Anh Tuan Luu and Wei Bi and Freda Shi and Shuming Shi},
   month = {9},
   title = {Siren's Song in the AI Ocean: A Survey on Hallucination in Large Language Models},
   year = {2023},
}
@article{Ziems2023,
   abstract = {Large Language Models (LLMs) like ChatGPT are capable of successfully performing many language processing tasks zero-shot (without the need for training data). If this capacity also applies to the coding of social phenomena like persuasiveness and political ideology, then LLMs could effectively transform Computational Social Science (CSS). This work provides a road map for using LLMs as CSS tools. Towards this end, we contribute a set of prompting best practices and an extensive evaluation pipeline to measure the zero-shot performance of 13 language models on 24 representative CSS benchmarks. On taxonomic labeling tasks (classification), LLMs fail to outperform the best fine-tuned models but still achieve fair levels of agreement with humans. On free-form coding tasks (generation), LLMs produce explanations that often exceed the quality of crowdworkers' gold references. We conclude that today's LLMs can radically augment the CSS research pipeline in two ways: (1) serving as zero-shot data annotators on human annotation teams, and (2) bootstrapping challenging creative generation tasks (e.g., explaining the hidden meaning behind text). In summary, LLMs can significantly reduce costs and increase efficiency of social science analysis in partnership with humans.},
   author = {Caleb Ziems and William Held and Omar Shaikh and Jiaao Chen and Zhehao Zhang and Diyi Yang},
   month = {4},
   title = {Can Large Language Models Transform Computational Social Science?},
   year = {2023},
}
@article{Liu2023,
   abstract = {Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments. We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting. Our extensive test over 27 API-based and open-sourced (OSS) LLMs shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and OSS competitors. We identify the typical reasons of failures in environments and LLMs, showing that poor long-term reasoning, decision-making, and instruction following abilities are the main obstacles for developing usable LLM agents. Training on code and high quality multi-turn alignment data could improve agent performance. Datasets, environments, and an integrated evaluation package for AgentBench are released at \url\{https://github.com/THUDM/AgentBench\}.},
   author = {Xiao Liu and Hao Yu and Hanchen Zhang and Yifan Xu and Xuanyu Lei and Hanyu Lai and Yu Gu and Hangliang Ding and Kaiwen Men and Kejuan Yang and Shudan Zhang and Xiang Deng and Aohan Zeng and Zhengxiao Du and Chenhui Zhang and Sheng Shen and Tianjun Zhang and Yu Su and Huan Sun and Minlie Huang and Yuxiao Dong and Jie Tang},
   month = {8},
   title = {AgentBench: Evaluating LLMs as Agents},
   year = {2023},
}
@article{Chiang2023,
   author = {Wei-Lin Chiang and Zhuohan Li and Zi Lin and Ying Sheng and Zhanghao Wu and Hao Zhang and Lianmin Zheng and Siyuan Zhuang and Yonghao Zhuang and Joseph E Gonzalez and others},
   journal = {See https://vicuna. lmsys. org (accessed 14 April 2023)},
   title = {Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
   year = {2023},
}
@article{Yang2023,
   abstract = {Large language models (LLMs) have demonstrated remarkable performance on a variety of natural language tasks based on just a few examples of natural language instructions, reducing the need for extensive feature engineering. However, most powerful LLMs are closed-source or limited in their capability for languages other than English. In this technical report, we present Baichuan 2, a series of large-scale multilingual language models containing 7 billion and 13 billion parameters, trained from scratch, on 2.6 trillion tokens. Baichuan 2 matches or outperforms other open-source models of similar size on public benchmarks like MMLU, CMMLU, GSM8K, and HumanEval. Furthermore, Baichuan 2 excels in vertical domains such as medicine and law. We will release all pre-training model checkpoints to benefit the research community in better understanding the training dynamics of Baichuan 2.},
   author = {Aiyuan Yang and Bin Xiao and Bingning Wang and Borong Zhang and Ce Bian and Chao Yin and Chenxu Lv and Da Pan and Dian Wang and Dong Yan and Fan Yang and Fei Deng and Feng Wang and Feng Liu and Guangwei Ai and Guosheng Dong and Haizhou Zhao and Hang Xu and Haoze Sun and Hongda Zhang and Hui Liu and Jiaming Ji and Jian Xie and JunTao Dai and Kun Fang and Lei Su and Liang Song and Lifeng Liu and Liyun Ru and Luyao Ma and Mang Wang and Mickel Liu and MingAn Lin and Nuolan Nie and Peidong Guo and Ruiyang Sun and Tao Zhang and Tianpeng Li and Tianyu Li and Wei Cheng and Weipeng Chen and Xiangrong Zeng and Xiaochuan Wang and Xiaoxi Chen and Xin Men and Xin Yu and Xuehai Pan and Yanjun Shen and Yiding Wang and Yiyu Li and Youxin Jiang and Yuchen Gao and Yupeng Zhang and Zenan Zhou and Zhiying Wu},
   month = {9},
   title = {Baichuan 2: Open Large-scale Language Models},
   year = {2023},
}
@article{Zeng2022,
   abstract = {We introduce GLM-130B, a bilingual (English and Chinese) pre-trained language model with 130 billion parameters. It is an attempt to open-source a 100B-scale model at least as good as GPT-3 (davinci) and unveil how models of such a scale can be successfully pre-trained. Over the course of this effort, we face numerous unexpected technical and engineering challenges, particularly on loss spikes and divergence. In this paper, we introduce the training process of GLM-130B including its design choices, training strategies for both efficiency and stability, and engineering efforts. The resultant GLM-130B model offers significant outperformance over GPT-3 175B (davinci) on a wide range of popular English benchmarks while the performance advantage is not observed in OPT-175B and BLOOM-176B. It also consistently and significantly outperforms ERNIE TITAN 3.0 260B -- the largest Chinese language model -- across related benchmarks. Finally, we leverage a unique scaling property of GLM-130B to reach INT4 quantization without post training, with almost no performance loss, making it the first among 100B-scale models and more importantly, allowing its effective inference on 4$\times$RTX 3090 (24G) or 8$\times$RTX 2080 Ti (11G) GPUs, the most affordable GPUs required for using 100B-scale models. The GLM-130B model weights are publicly accessible and its code, training logs, related toolkit, and lessons learned are open-sourced at \url\{https://github.com/THUDM/GLM-130B/\}.},
   author = {Aohan Zeng and Xiao Liu and Zhengxiao Du and Zihan Wang and Hanyu Lai and Ming Ding and Zhuoyi Yang and Yifan Xu and Wendi Zheng and Xiao Xia and Weng Lam Tam and Zixuan Ma and Yufei Xue and Jidong Zhai and Wenguang Chen and Peng Zhang and Yuxiao Dong and Jie Tang},
   month = {10},
   title = {GLM-130B: An Open Bilingual Pre-trained Model},
   year = {2022},
}
@article{Qin2023,
   abstract = {Despite the advancements of open-source large language models (LLMs), e.g., LLaMA, they remain significantly limited in tool-use capabilities, i.e., using external tools (APIs) to fulfill human instructions. The reason is that current instruction tuning largely focuses on basic language tasks but ignores the tool-use domain. This is in contrast to the excellent tool-use capabilities of state-of-the-art (SOTA) closed-source LLMs, e.g., ChatGPT. To bridge this gap, we introduce ToolLLM, a general tool-use framework encompassing data construction, model training, and evaluation. We first present ToolBench, an instruction-tuning dataset for tool use, which is constructed automatically using ChatGPT. Specifically, the construction can be divided into three stages: (i) API collection: we collect 16,464 real-world RESTful APIs spanning 49 categories from RapidAPI Hub; (ii) instruction generation: we prompt ChatGPT to generate diverse instructions involving these APIs, covering both single-tool and multi-tool scenarios; (iii) solution path annotation: we use ChatGPT to search for a valid solution path (chain of API calls) for each instruction. To enhance the reasoning capabilities of LLMs, we develop a novel depth-first search-based decision tree algorithm. It enables LLMs to evaluate multiple reasoning traces and expand the search space. Moreover, to evaluate the tool-use capabilities of LLMs, we develop an automatic evaluator: ToolEval. Based on ToolBench, we fine-tune LLaMA to obtain an LLM ToolLLaMA, and equip it with a neural API retriever to recommend appropriate APIs for each instruction. Experiments show that ToolLLaMA demonstrates a remarkable ability to execute complex instructions and generalize to unseen APIs, and exhibits comparable performance to ChatGPT. Our ToolLLaMA also demonstrates strong zero-shot generalization ability in an out-of-distribution tool-use dataset: APIBench.},
   author = {Yujia Qin and Shihao Liang and Yining Ye and Kunlun Zhu and Lan Yan and Yaxi Lu and Yankai Lin and Xin Cong and Xiangru Tang and Bill Qian and Sihan Zhao and Lauren Hong and Runchu Tian and Ruobing Xie and Jie Zhou and Mark Gerstein and Dahai Li and Zhiyuan Liu and Maosong Sun},
   month = {7},
   title = {ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs},
   year = {2023},
}
@article{Wooldridge1995,
   author = {Michael Wooldridge and Nicholas R Jennings},
   issue = {2},
   journal = {The knowledge engineering review},
   pages = {115-152},
   publisher = {Cambridge University Press},
   title = {Intelligent agents: Theory and practice},
   volume = {10},
   year = {1995},
}
@book{Sutton2018,
   author = {Richard S Sutton and Andrew G Barto},
   publisher = {MIT press},
   title = {Reinforcement learning: An introduction},
   year = {2018},
}
@misc{Zalta2019,
   author = {E N Zalta Schlossera M.},
   publisher = {Metaphysics Research Lab, Stanford, Winter},
   title = {The Stanford Encyclopedia of Philosophy},
   year = {2019},
}
@article{Lin2023,
   abstract = {With ChatGPT-like large language models (LLM) prevailing in the community, how to evaluate the ability of LLMs is an open question. Existing evaluation methods suffer from following shortcomings: (1) constrained evaluation abilities, (2) vulnerable benchmarks, (3) unobjective metrics. We suggest that task-based evaluation, where LLM agents complete tasks in a simulated environment, is a one-for-all solution to solve above problems. We present AgentSims, an easy-to-use infrastructure for researchers from all disciplines to test the specific capacities they are interested in. Researchers can build their evaluation tasks by adding agents and buildings on an interactive GUI or deploy and test new support mechanisms, i.e. memory, planning and tool-use systems, by a few lines of codes. Our demo is available at https://agentsims.com .},
   author = {Jiaju Lin and Haoran Zhao and Aochi Zhang and Yiting Wu and Huqiuyue Ping and Qin Chen},
   month = {8},
   title = {AgentSims: An Open-Source Sandbox for Large Language Model Evaluation},
   year = {2023},
}
@article{Ma2023,
   abstract = {Conversational agents powered by large language models (LLM) have increasingly been utilized in the realm of mental well-being support. However, the implications and outcomes associated with their usage in such a critical field remain somewhat ambiguous and unexplored. We conducted a qualitative analysis of 120 posts, encompassing 2917 user comments, drawn from the most popular subreddit focused on mental health support applications powered by large language models (u/Replika). This exploration aimed to shed light on the advantages and potential pitfalls associated with the integration of these sophisticated models in conversational agents intended for mental health support. We found the app (Replika) beneficial in offering on-demand, non-judgmental support, boosting user confidence, and aiding self-discovery. Yet, it faced challenges in filtering harmful content, sustaining consistent communication, remembering new information, and mitigating users' overdependence. The stigma attached further risked isolating users socially. We strongly assert that future researchers and designers must thoroughly evaluate the appropriateness of employing LLMs for mental well-being support, ensuring their responsible and effective application.},
   author = {Zilin Ma and Yiyang Mei and Zhaoyuan Su},
   month = {7},
   title = {Understanding the Benefits and Challenges of Using Large Language Model-based Conversational Agents for Mental Well-being Support},
   year = {2023},
}
@article{Boiko2023,
   abstract = {Transformer-based large language models are rapidly advancing in the field of machine learning research, with applications spanning natural language, biology, chemistry, and computer programming. Extreme scaling and reinforcement learning from human feedback have significantly improved the quality of generated text, enabling these models to perform various tasks and reason about their choices. In this paper, we present an Intelligent Agent system that combines multiple large language models for autonomous design, planning, and execution of scientific experiments. We showcase the Agent's scientific research capabilities with three distinct examples, with the most complex being the successful performance of catalyzed cross-coupling reactions. Finally, we discuss the safety implications of such systems and propose measures to prevent their misuse.},
   author = {Daniil A. Boiko and Robert MacKnight and Gabe Gomes},
   month = {4},
   title = {Emergent autonomous scientific research capabilities of large language models},
   year = {2023},
}
@article{Bran2023,
   abstract = {Over the last decades, excellent computational chemistry tools have been developed. Integrating them into a single platform with enhanced accessibility could help reaching their full potential by overcoming steep learning curves. Recently, large-language models (LLMs) have shown strong performance in tasks across domains, but struggle with chemistry-related problems. Moreover, these models lack access to external knowledge sources, limiting their usefulness in scientific applications. In this study, we introduce ChemCrow, an LLM chemistry agent designed to accomplish tasks across organic synthesis, drug discovery, and materials design. By integrating 18 expert-designed tools, ChemCrow augments the LLM performance in chemistry, and new capabilities emerge. Our agent autonomously planned and executed the syntheses of an insect repellent, three organocatalysts, and guided the discovery of a novel chromophore. Our evaluation, including both LLM and expert assessments, demonstrates ChemCrow's effectiveness in automating a diverse set of chemical tasks. Surprisingly, we find that GPT-4 as an evaluator cannot distinguish between clearly wrong GPT-4 completions and Chemcrow's performance. Our work not only aids expert chemists and lowers barriers for non-experts, but also fosters scientific advancement by bridging the gap between experimental and computational chemistry.},
   author = {Andres M Bran and Sam Cox and Oliver Schilter and Carlo Baldassari and Andrew D White and Philippe Schwaller},
   month = {4},
   title = {ChemCrow: Augmenting large-language models with chemistry tools},
   year = {2023},
}
@article{Cui2023,
   abstract = {Large Language Models (LLMs) have shown the potential to revolutionize natural language processing tasks in various domains, sparking great interest in vertical-specific large models. However, unlike proprietary models such as BloombergGPT and FinGPT, which have leveraged their unique data accumulations to make strides in the finance domain, there hasn't not many similar large language models in the Chinese legal domain to facilitate its digital transformation. In this paper, we propose an open-source legal large language model named ChatLaw. Due to the importance of data quality, we carefully designed a legal domain fine-tuning dataset. Additionally, to overcome the problem of model hallucinations in legal data screening during reference data retrieval, we introduce a method that combines vector database retrieval with keyword retrieval to effectively reduce the inaccuracy of relying solely on vector database retrieval. Furthermore, we propose a self-attention method to enhance the ability of large models to overcome errors present in reference data, further optimizing the issue of model hallucinations at the model level and improving the problem-solving capabilities of large models. We also open-sourced our model and part of the data at https://github.com/PKU-YuanGroup/ChatLaw.},
   author = {Jiaxi Cui and Zongjian Li and Yang Yan and Bohua Chen and Li Yuan},
   month = {6},
   title = {ChatLaw: Open-Source Legal Large Language Model with Integrated External Knowledge Bases},
   year = {2023},
}
@article{Liffiton2023,
   abstract = {Computing educators face significant challenges in providing timely support to students, especially in large class settings. Large language models (LLMs) have emerged recently and show great promise for providing on-demand help at a large scale, but there are concerns that students may over-rely on the outputs produced by these models. In this paper, we introduce CodeHelp, a novel LLM-powered tool designed with guardrails to provide on-demand assistance to programming students without directly revealing solutions. We detail the design of the tool, which incorporates a number of useful features for instructors, and elaborate on the pipeline of prompting strategies we use to ensure generated outputs are suitable for students. To evaluate CodeHelp, we deployed it in a first-year computer and data science course with 52 students and collected student interactions over a 12-week period. We examine students' usage patterns and perceptions of the tool, and we report reflections from the course instructor and a series of recommendations for classroom use. Our findings suggest that CodeHelp is well-received by students who especially value its availability and help with resolving errors, and that for instructors it is easy to deploy and complements, rather than replaces, the support that they provide to students.},
   author = {Mark Liffiton and Brad Sheese and Jaromir Savelka and Paul Denny},
   month = {8},
   title = {CodeHelp: Using Large Language Models with Guardrails for Scalable Support in Programming Classes},
   year = {2023},
}
@article{Vaswani2017,
   abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
   author = {Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Łukasz Kaiser and Illia Polosukhin},
   isbn = {1706.03762v7},
   issn = {10495258},
   journal = {Advances in Neural Information Processing Systems},
   month = {6},
   pages = {5999-6009},
   publisher = {Neural information processing systems foundation},
   title = {Attention Is All You Need},
   volume = {2017-December},
   url = {https://arxiv.org/abs/1706.03762v7},
   year = {2017},
}
@inproceedings{Shinn2023,
   author = {Noah Shinn and Federico Cassano and Ashwin Gopinath and Karthik R Narasimhan and Shunyu Yao},
   booktitle = {Thirty-seventh Conference on Neural Information Processing Systems},
   title = {Reflexion: Language agents with verbal reinforcement learning},
   year = {2023},
}
@article{Besta2023,
   abstract = {We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information ("LLM thoughts") are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62\% over ToT, while simultaneously reducing costs by >31\%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinking or brain mechanisms such as recurrence, both of which form complex networks.},
   author = {Maciej Besta and Nils Blach and Ales Kubicek and Robert Gerstenberger and Lukas Gianinazzi and Joanna Gajda and Tomasz Lehmann and Michal Podstawski and Hubert Niewiadomski and Piotr Nyczyk and Torsten Hoefler},
   month = {8},
   title = {Graph of Thoughts: Solving Elaborate Problems with Large Language Models},
   url = {https://arxiv.org/abs/2308.09687v3},
   year = {2023},
}
@article{Shen2023,
   abstract = {Solving complicated AI tasks with different domains and modalities is a key step toward artificial general intelligence. While there are numerous AI models available for various domains and modalities, they cannot handle complicated AI tasks autonomously. Considering large language models (LLMs) have exhibited exceptional abilities in language understanding, generation, interaction, and reasoning, we advocate that LLMs could act as a controller to manage existing AI models to solve complicated AI tasks, with language serving as a generic interface to empower this. Based on this philosophy, we present HuggingGPT, an LLM-powered agent that leverages LLMs (e.g., ChatGPT) to connect various AI models in machine learning communities (e.g., Hugging Face) to solve AI tasks. Specifically, we use ChatGPT to conduct task planning when receiving a user request, select models according to their function descriptions available in Hugging Face, execute each subtask with the selected AI model, and summarize the response according to the execution results. By leveraging the strong language capability of ChatGPT and abundant AI models in Hugging Face, HuggingGPT can tackle a wide range of sophisticated AI tasks spanning different modalities and domains and achieve impressive results in language, vision, speech, and other challenging tasks, which paves a new way towards the realization of artificial general intelligence.},
   author = {Yongliang Shen and Kaitao Song and Xu Tan and Dongsheng Li and Weiming Lu and Yueting Zhuang and Zhejiang University and Microsoft Research Asia},
   month = {3},
   title = {HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face},
   url = {https://arxiv.org/abs/2303.17580v4},
   year = {2023},
}
@inproceedings{Raman2022,
   author = {Shreyas Sundara Raman and Vanya Cohen and Eric Rosen and Ifrah Idrees and David Paulius and Stefanie Tellex},
   booktitle = {NeurIPS 2022 Foundation Models for Decision Making Workshop},
   title = {Planning with large language models via corrective re-prompting},
   year = {2022},
}
@inproceedings{Song2023,
   author = {Chan Hee Song and Jiaman Wu and Clayton Washington and Brian M Sadler and Wei-Lun Chao and Yu Su},
   booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision},
   pages = {2998-3009},
   title = {Llm-planner: Few-shot grounded planning for embodied agents with large language models},
   year = {2023},
}
@article{Huang2022,
   author = {Wenlong Huang and Fei Xia and Ted Xiao and Harris Chan and Jacky Liang and Pete Florence and Andy Zeng and Jonathan Tompson and Igor Mordatch and Yevgen Chebotar and others},
   journal = {arXiv preprint arXiv:2207.05608},
   title = {Inner monologue: Embodied reasoning through planning with language models},
   year = {2022},
}
@article{Miao2023,
   abstract = {The recent progress in large language models (LLMs), especially the invention of chain-of-thought prompting, has made it possible to automatically answer questions by stepwise reasoning. However, when faced with more complicated problems that require non-linear thinking, even the strongest LLMs make mistakes. To address this, we explore whether LLMs are able to recognize errors in their own step-by-step reasoning, without resorting to external resources. To this end, we propose SelfCheck, a general-purpose zero-shot verification schema for recognizing such errors. We then use the results of these checks to improve question-answering performance by conducting weighted voting on multiple solutions to the question. We test SelfCheck on three datasets (GSM8K, MathQA, and MATH) and find that it successfully recognizes errors and, in turn, increases final answer accuracies.},
   author = {Ning Miao and Yee Whye Teh and Tom Rainforth},
   month = {8},
   title = {SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning},
   year = {2023},
}
@article{Ruan2023,
   abstract = {With recent advancements in natural language processing, Large Language Models (LLMs) have emerged as powerful tools for various real-world applications. Despite their prowess, the intrinsic generative abilities of LLMs may prove insufficient for handling complex tasks which necessitate a combination of task planning and the usage of external tools. In this paper, we first propose a structured framework tailored for LLM-based AI Agents and discuss the crucial capabilities necessary for tackling intricate problems. Within this framework, we design two distinct types of agents (i.e., one-step agent and sequential agent) to execute the inference process. Subsequently, we instantiate the framework using various LLMs and evaluate their Task Planning and Tool Usage (TPTU) abilities on typical tasks. By highlighting key findings and challenges, our goal is to provide a helpful resource for researchers and practitioners to leverage the power of LLMs in their AI applications. Our study emphasizes the substantial potential of these models, while also identifying areas that need more investigation and improvement.},
   author = {Jingqing Ruan and Yihong Chen and Bin Zhang and Zhiwei Xu and Tianpeng Bao and Guoqing Du and Shiwei Shi and Hangyu Mao and Ziyue Li and Xingyu Zeng and Rui Zhao},
   month = {8},
   title = {TPTU: Large Language Model-based AI Agents for Task Planning and Tool Usage},
   year = {2023},
}
@article{Hu2023,
   abstract = {Large language models (LLMs) with memory are computationally universal. However, mainstream LLMs are not taking full advantage of memory, and the designs are heavily influenced by biological brains. Due to their approximate nature and proneness to the accumulation of errors, conventional neural memory mechanisms cannot support LLMs to simulate complex reasoning. In this paper, we seek inspiration from modern computer architectures to augment LLMs with symbolic memory for complex multi-hop reasoning. Such a symbolic memory framework is instantiated as an LLM and a set of SQL databases, where the LLM generates SQL instructions to manipulate the SQL databases. We validate the effectiveness of the proposed memory framework on a synthetic dataset requiring complex reasoning. The project website is available at https://chatdatabase.github.io/ .},
   author = {Chenxu Hu and Jie Fu and Chenzhuang Du and Simian Luo and Junbo Zhao and Hang Zhao},
   month = {6},
   title = {ChatDB: Augmenting LLMs with Databases as Their Symbolic Memory},
   year = {2023},
}
@article{Ge2023,
   abstract = {Human Intelligence (HI) excels at combining basic skills to solve complex tasks. This capability is vital for Artificial Intelligence (AI) and should be embedded in comprehensive AI Agents, enabling them to harness expert models for complex task-solving towards Artificial General Intelligence (AGI). Large Language Models (LLMs) show promising learning and reasoning abilities, and can effectively use external models, tools, plugins, or APIs to tackle complex problems. In this work, we introduce OpenAGI, an open-source AGI research and development platform designed for solving multi-step, real-world tasks. Specifically, OpenAGI uses a dual strategy, integrating standard benchmark tasks for benchmarking and evaluation, and open-ended tasks including more expandable models, tools, plugins, or APIs for creative problem-solving. Tasks are presented as natural language queries to the LLM, which then selects and executes appropriate models. We also propose a Reinforcement Learning from Task Feedback (RLTF) mechanism that uses task results to improve the LLM's task-solving ability, which creates a self-improving AI feedback loop. While we acknowledge that AGI is a broad and multifaceted research challenge with no singularly defined solution path, the integration of LLMs with domain-specific expert models, inspired by mirroring the blend of general and specialized intelligence in humans, offers a promising approach towards AGI. We are open-sourcing the OpenAGI project's code, dataset, benchmarks, evaluation methods, and the UI demo to foster community involvement in AGI advancement: https://github.com/agiresearch/OpenAGI.},
   author = {Yingqiang Ge and Wenyue Hua and Kai Mei and Jianchao Ji and Juntao Tan and Shuyuan Xu and Zelong Li and Yongfeng Zhang},
   month = {4},
   title = {OpenAGI: When LLM Meets Domain Experts},
   year = {2023},
}
@article{Karpas2022,
   abstract = {Huge language models (LMs) have ushered in a new era for AI, serving as a gateway to natural-language-based knowledge tasks. Although an essential element of modern AI, LMs are also inherently limited in a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach. Conceptualizing the challenge as one that involves knowledge and reasoning in addition to linguistic processing, we define a flexible architecture with multiple neural models, complemented by discrete knowledge and reasoning modules. We describe this neuro-symbolic architecture, dubbed the Modular Reasoning, Knowledge and Language (MRKL, pronounced "miracle") system, some of the technical challenges in implementing it, and Jurassic-X, AI21 Labs' MRKL system implementation.},
   author = {Ehud Karpas and Omri Abend and Yonatan Belinkov and Barak Lenz and Opher Lieber and Nir Ratner and Yoav Shoham and Hofit Bata and Yoav Levine and Kevin Leyton-Brown and Dor Muhlgay and Noam Rozen and Erez Schwartz and Gal Shachaf and Shai Shalev-Shwartz and Amnon Shashua and Moshe Tenenholtz},
   month = {5},
   title = {MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning},
   year = {2022},
}
@article{Zhu2023,
   abstract = {The captivating realm of Minecraft has attracted substantial research interest in recent years, serving as a rich platform for developing intelligent agents capable of functioning in open-world environments. However, the current research landscape predominantly focuses on specific objectives, such as the popular "ObtainDiamond" task, and has not yet shown effective generalization to a broader spectrum of tasks. Furthermore, the current leading success rate for the "ObtainDiamond" task stands at around 20\%, highlighting the limitations of Reinforcement Learning (RL) based controllers used in existing methods. To tackle these challenges, we introduce Ghost in the Minecraft (GITM), a novel framework integrates Large Language Models (LLMs) with text-based knowledge and memory, aiming to create Generally Capable Agents (GCAs) in Minecraft. These agents, equipped with the logic and common sense capabilities of LLMs, can skillfully navigate complex, sparse-reward environments with text-based interactions. We develop a set of structured actions and leverage LLMs to generate action plans for the agents to execute. The resulting LLM-based agent markedly surpasses previous methods, achieving a remarkable improvement of +47.5\% in success rate on the "ObtainDiamond" task, demonstrating superior robustness compared to traditional RL-based controllers. Notably, our agent is the first to procure all items in the Minecraft Overworld technology tree, demonstrating its extensive capabilities. GITM does not need any GPU for training, but a single CPU node with 32 CPU cores is enough. This research shows the potential of LLMs in developing capable agents for handling long-horizon, complex tasks and adapting to uncertainties in open-world environments. See the project website at https://github.com/OpenGVLab/GITM.},
   author = {Xizhou Zhu and Yuntao Chen and Hao Tian and Chenxin Tao and Weijie Su and Chenyu Yang and Gao Huang and Bin Li and Lewei Lu and Xiaogang Wang and Yu Qiao and Zhaoxiang Zhang and Jifeng Dai},
   month = {5},
   title = {Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory},
   year = {2023},
}
@misc{Weng2023,
   author = {Lilian Weng},
   month = {6},
   title = {LLM Powered Autonomous Agents},
   url = {https://lilianweng.github.io/posts/2023-06-23-agent/},
   year = {2023},
}
@article{Wang2023,
   abstract = {We investigate the challenge of task planning for multi-task embodied agents in open-world environments. Two main difficulties are identified: 1) executing plans in an open-world environment (e.g., Minecraft) necessitates accurate and multi-step reasoning due to the long-term nature of tasks, and 2) as vanilla planners do not consider how easy the current agent can achieve a given sub-task when ordering parallel sub-goals within a complicated plan, the resulting plan could be inefficient or even infeasible. To this end, we propose "$\underline\{D\}$escribe, $\underline\{E\}$xplain, $\underline\{P\}$lan and $\underline\{S\}$elect" ($\textbf\{DEPS\}$), an interactive planning approach based on Large Language Models (LLMs). DEPS facilitates better error correction on initial LLM-generated $\textit\{plan\}$ by integrating $\textit\{description\}$ of the plan execution process and providing self-$\textit\{explanation\}$ of feedback when encountering failures during the extended planning phases. Furthermore, it includes a goal $\textit\{selector\}$, which is a trainable module that ranks parallel candidate sub-goals based on the estimated steps of completion, consequently refining the initial plan. Our experiments mark the milestone of the first zero-shot multi-task agent that can robustly accomplish 70+ Minecraft tasks and nearly double the overall performances. Further testing reveals our method's general effectiveness in popularly adopted non-open-ended domains as well (i.e., ALFWorld and tabletop manipulation). The ablation and exploratory studies detail how our design beats the counterparts and provide a promising update on the $\texttt\{ObtainDiamond\}$ grand challenge with our approach. The code is released at https://github.com/CraftJarvis/MC-Planner.},
   author = {Zihao Wang and Shaofei Cai and Guanzhou Chen and Anji Liu and Xiaojian Ma and Yitao Liang},
   month = {2},
   title = {Describe, Explain, Plan and Select: Interactive Planning with Large Language Models Enables Open-World Multi-Task Agents},
   year = {2023},
}
@article{Rana2023,
   abstract = {Large language models (LLMs) have demonstrated impressive results in developing generalist planning agents for diverse tasks. However, grounding these plans in expansive, multi-floor, and multi-room environments presents a significant challenge for robotics. We introduce SayPlan, a scalable approach to LLM-based, large-scale task planning for robotics using 3D scene graph (3DSG) representations. To ensure the scalability of our approach, we: (1) exploit the hierarchical nature of 3DSGs to allow LLMs to conduct a 'semantic search' for task-relevant subgraphs from a smaller, collapsed representation of the full graph; (2) reduce the planning horizon for the LLM by integrating a classical path planner and (3) introduce an 'iterative replanning' pipeline that refines the initial plan using feedback from a scene graph simulator, correcting infeasible actions and avoiding planning failures. We evaluate our approach on two large-scale environments spanning up to 3 floors and 36 rooms with 140 assets and objects and show that our approach is capable of grounding large-scale, long-horizon task plans from abstract, and natural language instruction for a mobile manipulator robot to execute. We provide real robot video demonstrations on our project page https://sayplan.github.io.},
   author = {Krishan Rana and Jesse Haviland and Sourav Garg and Jad Abou-Chakra and Ian Reid and Niko Suenderhauf},
   month = {7},
   title = {SayPlan: Grounding Large Language Models using 3D Scene Graphs for Scalable Robot Task Planning},
   year = {2023},
}
@article{Miao2023,
   abstract = {The recent progress in large language models (LLMs), especially the invention of chain-of-thought prompting, has made it possible to automatically answer questions by stepwise reasoning. However, when faced with more complicated problems that require non-linear thinking, even the strongest LLMs make mistakes. To address this, we explore whether LLMs are able to recognize errors in their own step-by-step reasoning, without resorting to external resources. To this end, we propose SelfCheck, a general-purpose zero-shot verification schema for recognizing such errors. We then use the results of these checks to improve question-answering performance by conducting weighted voting on multiple solutions to the question. We test SelfCheck on three datasets (GSM8K, MathQA, and MATH) and find that it successfully recognizes errors and, in turn, increases final answer accuracies.},
   author = {Ning Miao and Yee Whye Teh and Tom Rainforth},
   month = {8},
   title = {SelfCheck: Using LLMs to Zero-Shot Check Their Own Step-by-Step Reasoning},
   year = {2023},
}
@article{Luo2023,
   abstract = {Logical rules are essential for uncovering the logical connections between relations, which could improve the reasoning performance and provide interpretable results on knowledge graphs (KGs). Although there have been many efforts to mine meaningful logical rules over KGs, existing methods suffer from the computationally intensive searches over the rule space and a lack of scalability for large-scale KGs. Besides, they often ignore the semantics of relations which is crucial for uncovering logical connections. Recently, large language models (LLMs) have shown impressive performance in the field of natural language processing and various applications, owing to their emergent ability and generalizability. In this paper, we propose a novel framework, ChatRule, unleashing the power of large language models for mining logical rules over knowledge graphs. Specifically, the framework is initiated with an LLM-based rule generator, leveraging both the semantic and structural information of KGs to prompt LLMs to generate logical rules. To refine the generated rules, a rule ranking module estimates the rule quality by incorporating facts from existing KGs. Last, a rule validator harnesses the reasoning ability of LLMs to validate the logical correctness of ranked rules through chain-of-thought reasoning. ChatRule is evaluated on four large-scale KGs, w.r.t. different rule quality metrics and downstream tasks, showing the effectiveness and scalability of our method.},
   author = {Linhao Luo and Jiaxin Ju and Bo Xiong and Yuan-Fang Li and Gholamreza Haffari and Shirui Pan},
   month = {9},
   title = {ChatRule: Mining Logical Rules with Large Language Models for Knowledge Graph Reasoning},
   year = {2023},
}
@article{Pan2023,
   abstract = {Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolving by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs, which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; 2) LLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and 3) Synergized LLMs + KGs, in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions.},
   author = {Shirui Pan and Linhao Luo and Yufei Wang and Chen Chen and Jiapu Wang and Xindong Wu},
   month = {6},
   title = {Unifying Large Language Models and Knowledge Graphs: A Roadmap},
   year = {2023},
}
@article{Zhen2022,
   abstract = {Natural Language Processing (NLP) has been revolutionized by the use of Pre-trained Language Models (PLMs) such as BERT. Despite setting new records in nearly every NLP task, PLMs still face a number of challenges including poor interpretability, weak reasoning capability, and the need for a lot of expensive annotated data when applied to downstream tasks. By integrating external knowledge into PLMs, \textit\{\underline\{K\}nowledge-\underline\{E\}nhanced \underline\{P\}re-trained \underline\{L\}anguage \underline\{M\}odels\} (KEPLMs) have the potential to overcome the above-mentioned limitations. In this paper, we examine KEPLMs systematically through a series of studies. Specifically, we outline the common types and different formats of knowledge to be integrated into KEPLMs, detail the existing methods for building and evaluating KEPLMS, present the applications of KEPLMs in downstream tasks, and discuss the future research directions. Researchers will benefit from this survey by gaining a quick and comprehensive overview of the latest developments in this field.},
   author = {Chaoqi Zhen and Yanlei Shang and Xiangyu Liu and Yifei Li and Yong Chen and Dell Zhang},
   month = {12},
   title = {A Survey on Knowledge-Enhanced Pre-trained Language Models},
   year = {2022},
}
@article{AlKhamissi2022,
   abstract = {Recently, there has been a surge of interest in the NLP community on the use of pretrained Language Models (LMs) as Knowledge Bases (KBs). Researchers have shown that LMs trained on a sufficiently large (web) corpus will encode a significant amount of knowledge implicitly in its parameters. The resulting LM can be probed for different kinds of knowledge and thus acting as a KB. This has a major advantage over traditional KBs in that this method requires no human supervision. In this paper, we present a set of aspects that we deem a LM should have to fully act as a KB, and review the recent literature with respect to those aspects.},
   author = {Badr AlKhamissi and Millicent Li and Asli Celikyilmaz and Mona Diab and Marjan Ghazvininejad},
   month = {4},
   title = {A Review on Language Models as Knowledge Bases},
   year = {2022},
}
@article{Yin2022,
   abstract = {With the increasing of model capacity brought by pre-trained language models, there emerges boosting needs for more knowledgeable natural language processing (NLP) models with advanced functionalities including providing and making flexible use of encyclopedic and commonsense knowledge. The mere pre-trained language models, however, lack the capacity of handling such knowledge-intensive NLP tasks alone. To address this challenge, large numbers of pre-trained language models augmented with external knowledge sources are proposed and in rapid development. In this paper, we aim to summarize the current progress of pre-trained language model-based knowledge-enhanced models (PLMKEs) by dissecting their three vital elements: knowledge sources, knowledge-intensive NLP tasks, and knowledge fusion methods. Finally, we present the challenges of PLMKEs based on the discussion regarding the three elements and attempt to provide NLP practitioners with potential directions for further research.},
   author = {Da Yin and Li Dong and Hao Cheng and Xiaodong Liu and Kai-Wei Chang and Furu Wei and Jianfeng Gao},
   month = {2},
   title = {A Survey of Knowledge-Intensive NLP with Pre-Trained Language Models},
   year = {2022},
}
@article{Liang2022,
   abstract = {Knowledge graph reasoning (KGR), aiming to deduce new facts from existing facts based on mined logic rules underlying knowledge graphs (KGs), has become a fast-growing research direction. It has been proven to significantly benefit the usage of KGs in many AI applications, such as question answering, recommendation systems, and etc. According to the graph types, existing KGR models can be roughly divided into three categories, i.e., static models, temporal models, and multi-modal models. Early works in this domain mainly focus on static KGR, and recent works try to leverage the temporal and multi-modal information, which are more practical and closer to real-world. However, no survey papers and open-source repositories comprehensively summarize and discuss models in this important direction. To fill the gap, we conduct a first survey for knowledge graph reasoning tracing from static to temporal and then to multi-modal KGs. Concretely, the models are reviewed based on bi-level taxonomy, i.e., top-level (graph types) and base-level (techniques and scenarios). Besides, the performances, as well as datasets, are summarized and presented. Moreover, we point out the challenges and potential opportunities to enlighten the readers. The corresponding open-source repository is shared on GitHub https://github.com/LIANGKE23/Awesome-Knowledge-Graph-Reasoning.},
   author = {Ke Liang and Lingyuan Meng and Meng Liu and Yue Liu and Wenxuan Tu and Siwei Wang and Sihang Zhou and Xinwang Liu and Fuchun Sun},
   month = {12},
   title = {A Survey of Knowledge Graph Reasoning on Graph Types: Static, Dynamic, and Multimodal},
   year = {2022},
}
@article{Agrawal2023,
   abstract = {The contemporary LLMs are prone to producing hallucinations, stemming mainly from the knowledge gaps within the models. To address this critical limitation, researchers employ diverse strategies to augment the LLMs by incorporating external knowledge, aiming to reduce hallucinations and enhance reasoning accuracy. Among these strategies, leveraging knowledge graphs as a source of external information has demonstrated promising results. In this survey, we conduct a comprehensive review of these knowledge-graph-based knowledge augmentation techniques in LLMs, focusing on their efficacy in mitigating hallucinations. We systematically categorize these methods into three overarching groups, offering both methodological comparisons and empirical evaluations of their performance. Lastly, the paper explores the challenges associated with these techniques and outlines potential avenues for future research in this emerging field.},
   author = {Garima Agrawal and Tharindu Kumarage and Zeyad Alghami and Huan Liu},
   month = {11},
   title = {Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey},
   year = {2023},
}
@article{Wang2023,
   abstract = {This survey addresses the crucial issue of factuality in Large Language Models (LLMs). As LLMs find applications across diverse domains, the reliability and accuracy of their outputs become vital. We define the Factuality Issue as the probability of LLMs to produce content inconsistent with established facts. We first delve into the implications of these inaccuracies, highlighting the potential consequences and challenges posed by factual errors in LLM outputs. Subsequently, we analyze the mechanisms through which LLMs store and process facts, seeking the primary causes of factual errors. Our discussion then transitions to methodologies for evaluating LLM factuality, emphasizing key metrics, benchmarks, and studies. We further explore strategies for enhancing LLM factuality, including approaches tailored for specific domains. We focus two primary LLM configurations standalone LLMs and Retrieval-Augmented LLMs that utilizes external data, we detail their unique challenges and potential enhancements. Our survey offers a structured guide for researchers aiming to fortify the factual reliability of LLMs.},
   author = {Cunxiang Wang and Xiaoze Liu and Yuanhao Yue and Xiangru Tang and Tianhang Zhang and Cheng Jiayang and Yunzhi Yao and Wenyang Gao and Xuming Hu and Zehan Qi and Yidong Wang and Linyi Yang and Jindong Wang and Xing Xie and Zheng Zhang and Yue Zhang},
   month = {10},
   title = {Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity},
   year = {2023},
}
@article{Jiang2023,
   abstract = {Knowledge graphs (KGs) are structured representations of diversified knowledge. They are widely used in various intelligent applications. In this article, we provide a comprehensive survey on the evolution of various types of knowledge graphs (i.e., static KGs, dynamic KGs, temporal KGs, and event KGs) and techniques for knowledge extraction and reasoning. Furthermore, we introduce the practical applications of different types of KGs, including a case study in financial analysis. Finally, we propose our perspective on the future directions of knowledge engineering, including the potential of combining the power of knowledge graphs and large language models (LLMs), and the evolution of knowledge extraction, reasoning, and representation.},
   author = {Xuhui Jiang and Chengjin Xu and Yinghan Shen and Xun Sun and Lumingyuan Tang and Saizhuo Wang and Zhongwu Chen and Yuanzhuo Wang and Jian Guo},
   month = {10},
   title = {On the Evolution of Knowledge Graphs: A Survey and Perspective},
   year = {2023},
}
@article{Lewis2020,
   abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
   author = {Patrick Lewis and Ethan Perez and Aleksandra Piktus and Fabio Petroni and Vladimir Karpukhin and Naman Goyal and Heinrich Küttler and Mike Lewis and Wen-tau Yih and Tim Rocktäschel and Sebastian Riedel and Douwe Kiela},
   month = {5},
   title = {Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks},
   year = {2020},
}
@article{Wilmot2021,
   abstract = {Measuring event salience is essential in the understanding of stories. This paper takes a recent unsupervised method for salience detection derived from Barthes Cardinal Functions and theories of surprise and applies it to longer narrative forms. We improve the standard transformer language model by incorporating an external knowledgebase (derived from Retrieval Augmented Generation) and adding a memory mechanism to enhance performance on longer works. We use a novel approach to derive salience annotation using chapter-aligned summaries from the Shmoop corpus for classic literary works. Our evaluation against this data demonstrates that our salience detection model improves performance over and above a non-knowledgebase and memory augmented language model, both of which are crucial to this improvement.},
   author = {David Wilmot and Frank Keller},
   month = {9},
   title = {Memory and Knowledge Augmented Language Models for Inferring Salience in Long-Form Stories},
   year = {2021},
}
@article{Petroni2019,
   abstract = {Recent progress in pretraining language models on large textual corpora led to a surge of improvements for downstream NLP tasks. Whilst learning linguistic knowledge, these models may also be storing relational knowledge present in the training data, and may be able to answer queries structured as "fill-in-the-blank" cloze statements. Language models have many advantages over structured knowledge bases: they require no schema engineering, allow practitioners to query about an open class of relations, are easy to extend to more data, and require no human supervision to train. We present an in-depth analysis of the relational knowledge already present (without fine-tuning) in a wide range of state-of-the-art pretrained language models. We find that (i) without fine-tuning, BERT contains relational knowledge competitive with traditional NLP methods that have some access to oracle knowledge, (ii) BERT also does remarkably well on open-domain question answering against a supervised baseline, and (iii) certain types of factual knowledge are learned much more readily than others by standard language model pretraining approaches. The surprisingly strong ability of these models to recall factual knowledge without any fine-tuning demonstrates their potential as unsupervised open-domain QA systems. The code to reproduce our analysis is available at https://github.com/facebookresearch/LAMA.},
   author = {Fabio Petroni and Tim Rocktäschel and Patrick Lewis and Anton Bakhtin and Yuxiang Wu and Alexander H. Miller and Sebastian Riedel},
   month = {9},
   title = {Language Models as Knowledge Bases?},
   year = {2019},
}
@inproceedings{Li2023,
   author = {Zongjie Li and Chaozheng Wang and Zhibo Liu and Haoxuan Wang and Dong Chen and Shuai Wang and Cuiyun Gao},
   doi = {10.1109/ICSE48619.2023.00110},
   booktitle = {2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)},
   pages = {1238-1250},
   title = {CCTEST: Testing and Repairing Code Completion Systems},
   year = {2023},
}
@article{Ji2023,
   author = {Ziwei Ji and Nayeon Lee and Rita Frieske and Tiezheng Yu and Dan Su and Yan Xu and Etsuko Ishii and Ye Jin Bang and Andrea Madotto and Pascale Fung},
   issue = {12},
   journal = {ACM Computing Surveys},
   pages = {1-38},
   publisher = {ACM New York, NY},
   title = {Survey of hallucination in natural language generation},
   volume = {55},
   year = {2023},
}
@inproceedings{Li2023,
   author = {Zongjie Li and Chaozheng Wang and Zhibo Liu and Haoxuan Wang and Dong Chen and Shuai Wang and Cuiyun Gao},
   doi = {10.1109/ICSE48619.2023.00110},
   booktitle = {2023 IEEE/ACM 45th International Conference on Software Engineering (ICSE)},
   pages = {1238-1250},
   title = {CCTEST: Testing and Repairing Code Completion Systems},
   year = {2023},
}
@article{Petroni2019,
   author = {Fabio Petroni and Tim Rocktäschel and Patrick Lewis and Anton Bakhtin and Yuxiang Wu and Alexander H Miller and Sebastian Riedel},
   journal = {arXiv preprint arXiv:1909.01066},
   title = {Language models as knowledge bases?},
   year = {2019},
}
@article{Zhang2019,
   abstract = {Neural language representation models such as BERT pre-trained on large-scale corpora can well capture rich semantic patterns from plain text, and be fine-tuned to consistently improve the performance of various NLP tasks. However, the existing pre-trained language models rarely consider incorporating knowledge graphs (KGs), which can provide rich structured knowledge facts for better language understanding. We argue that informative entities in KGs can enhance language representation with external knowledge. In this paper, we utilize both large-scale textual corpora and KGs to train an enhanced language representation model (ERNIE), which can take full advantage of lexical, syntactic, and knowledge information simultaneously. The experimental results have demonstrated that ERNIE achieves significant improvements on various knowledge-driven tasks, and meanwhile is comparable with the state-of-the-art model BERT on other common NLP tasks. The source code of this paper can be obtained from https://github.com/thunlp/ERNIE.},
   author = {Zhengyan Zhang and Xu Han and Zhiyuan Liu and Xin Jiang and Maosong Sun and Qun Liu},
   month = {5},
   title = {ERNIE: Enhanced Language Representation with Informative Entities},
   year = {2019},
}
@article{Lin2019,
   abstract = {Commonsense reasoning aims to empower machines with the human ability to make presumptions about ordinary situations in our daily life. In this paper, we propose a textual inference framework for answering commonsense questions, which effectively utilizes external, structured commonsense knowledge graphs to perform explainable inferences. The framework first grounds a question-answer pair from the semantic space to the knowledge-based symbolic space as a schema graph, a related sub-graph of external knowledge graphs. It represents schema graphs with a novel knowledge-aware graph network module named KagNet, and finally scores answers with graph representations. Our model is based on graph convolutional networks and LSTMs, with a hierarchical path-based attention mechanism. The intermediate attention scores make it transparent and interpretable, which thus produce trustworthy inferences. Using ConceptNet as the only external resource for Bert-based models, we achieved state-of-the-art performance on the CommonsenseQA, a large-scale dataset for commonsense reasoning.},
   author = {Bill Yuchen Lin and Xinyue Chen and Jamin Chen and Xiang Ren},
   month = {9},
   title = {KagNet: Knowledge-Aware Graph Networks for Commonsense Reasoning},
   year = {2019},
}
@article{Choudhary2023,
   abstract = {Reasoning over knowledge graphs (KGs) is a challenging task that requires a deep understanding of the complex relationships between entities and the underlying logic of their relations. Current approaches rely on learning geometries to embed entities in vector space for logical query operations, but they suffer from subpar performance on complex queries and dataset-specific representations. In this paper, we propose a novel decoupled approach, Language-guided Abstract Reasoning over Knowledge graphs (LARK), that formulates complex KG reasoning as a combination of contextual KG search and logical query reasoning, to leverage the strengths of graph extraction algorithms and large language models (LLM), respectively. Our experiments demonstrate that the proposed approach outperforms state-of-the-art KG reasoning methods on standard benchmark datasets across several logical query constructs, with significant performance gain for queries of higher complexity. Furthermore, we show that the performance of our approach improves proportionally to the increase in size of the underlying LLM, enabling the integration of the latest advancements in LLMs for logical reasoning over KGs. Our work presents a new direction for addressing the challenges of complex KG reasoning and paves the way for future research in this area.},
   author = {Nurendra Choudhary and Chandan K. Reddy},
   month = {5},
   title = {Complex Logical Reasoning over Knowledge Graphs using Large Language Models},
   year = {2023},
}
@article{Yasunaga2022,
   abstract = {Pretraining a language model (LM) on text has been shown to help various downstream NLP tasks. Recent works show that a knowledge graph (KG) can complement text data, offering structured background knowledge that provides a useful scaffold for reasoning. However, these works are not pretrained to learn a deep fusion of the two modalities at scale, limiting the potential to acquire fully joint representations of text and KG. Here we propose DRAGON (Deep Bidirectional Language-Knowledge Graph Pretraining), a self-supervised approach to pretraining a deeply joint language-knowledge foundation model from text and KG at scale. Specifically, our model takes pairs of text segments and relevant KG subgraphs as input and bidirectionally fuses information from both modalities. We pretrain this model by unifying two self-supervised reasoning tasks, masked language modeling and KG link prediction. DRAGON outperforms existing LM and LM+KG models on diverse downstream tasks including question answering across general and biomedical domains, with +5\% absolute gain on average. In particular, DRAGON achieves notable performance on complex reasoning about language and knowledge (+10\% on questions involving long contexts or multi-step reasoning) and low-resource QA (+8\% on OBQA and RiddleSense), and new state-of-the-art results on various BioNLP tasks. Our code and trained models are available at https://github.com/michiyasunaga/dragon.},
   author = {Michihiro Yasunaga and Antoine Bosselut and Hongyu Ren and Xikun Zhang and Christopher D Manning and Percy Liang and Jure Leskovec},
   month = {10},
   title = {Deep Bidirectional Language-Knowledge Graph Pretraining},
   year = {2022},
}
@article{Logan2019,
   abstract = {Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset, a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark. In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language model's ability to complete sentences requiring factual knowledge, showing that the KGLM outperforms even very large language models in generating facts.},
   author = {Robert L. Logan and Nelson F. Liu and Matthew E. Peters and Matt Gardner and Sameer Singh},
   month = {6},
   title = {Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling},
   year = {2019},
}
@article{Guu2020,
   abstract = {Language model pre-training has been shown to capture a surprising amount of world knowledge, crucial for NLP tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring ever-larger networks to cover more facts. To capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents. We demonstrate the effectiveness of Retrieval-Augmented Language Model pre-training (REALM) by fine-tuning on the challenging task of Open-domain Question Answering (Open-QA). We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-QA benchmarks, and find that we outperform all previous methods by a significant margin (4-16\% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.},
   author = {Kelvin Guu and Kenton Lee and Zora Tung and Panupong Pasupat and Ming-Wei Chang},
   month = {2},
   title = {REALM: Retrieval-Augmented Language Model Pre-Training},
   year = {2020},
}
@article{Wu2022,
   abstract = {Access to external knowledge is essential for many natural language processing tasks, such as question answering and dialogue. Existing methods often rely on a parametric model that stores knowledge in its parameters, or use a retrieval-augmented model that has access to an external knowledge source. Parametric and retrieval-augmented models have complementary strengths in terms of computational efficiency and predictive accuracy. To combine the strength of both approaches, we propose the Efficient Memory-Augmented Transformer (EMAT) -- it encodes external knowledge into a key-value memory and exploits the fast maximum inner product search for memory querying. We also introduce pre-training tasks that allow EMAT to encode informative key-value representations, and to learn an implicit strategy to integrate multiple memory slots into the transformer. Experiments on various knowledge-intensive tasks such as question answering and dialogue datasets show that, simply augmenting parametric models (T5-base) using our method produces more accurate results (e.g., 25.8 -> 44.3 EM on NQ) while retaining a high throughput (e.g., 1000 queries/s on NQ). Compared to retrieval-augmented models, EMAT runs substantially faster across the board and produces more accurate results on WoW and ELI5. Our code and datasets are available at https://github. com/uclnlp/EMAT.},
   author = {Yuxiang Wu and Yu Zhao and Baotian Hu and Pasquale Minervini and Pontus Stenetorp and Sebastian Riedel},
   month = {10},
   title = {An Efficient Memory-Augmented Transformer for Knowledge-Intensive NLP Tasks},
   year = {2022},
}
@misc{,
   author = {马展 and 王岩 and 王微微 and 赵瑞莲},
   title = {基于多源信息融合的API知识图谱构建},
   url = {http://cnjournals.com/view_abstract.aspx?aid=CFC3B0096A6D80B2BB9723DA2B12C510&jid=D4F6864C950C88FFCE5B6C948A639E39&pcid=5B3AB970F71A803DEACDC0559115BFCF0A068CD97DD29835&yid=9475FABC7A03F4AB},
}

@inproceedings{Li2018,
   author = {Hongwei Li and Sirui Li and Jiamou Sun and Zhenchang Xing and Xin Peng and Mingwei Liu and Xuejiao Zhao},
   booktitle = {2018 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
   pages = {183-193},
   title = {Improving api caveats accessibility by mining api caveats knowledge graph},
   year = {2018},
}
@inproceedings{Liu2019,
   author = {Mingwei Liu and Xin Peng and Andrian Marcus and Zhenchang Xing and Wenkai Xie and Shuangshuang Xing and Yang Liu},
   booktitle = {Proceedings of the 2019 27th ACM joint meeting on European software engineering conference and symposium on the foundations of software engineering},
   pages = {120-130},
   title = {Generating query-specific class API summaries},
   year = {2019},
}
@article{Ling2019,
   author = {Chun-Yang Ling and Yan-Zhen Zou and Ze-Qi Lin and Bing Xie},
   journal = {Journal of Computer Science and Technology},
   pages = {993-1006},
   publisher = {Springer},
   title = {Graph embedding based API graph search and recommendation},
   volume = {34},
   year = {2019},
}
@inproceedings{Kwapong2019,
   author = {Benjamin Kwapong and Kenneth Fletcher},
   booktitle = {2019 IEEE World Congress on Services (SERVICES)},
   pages = {115-120},
   title = {A knowledge graph based framework for web API recommendation},
   volume = {2642},
   year = {2019},
}
@inproceedings{Liu2020,
   author = {Yang Liu and Mingwei Liu and Xin Peng and Christoph Treude and Zhenchang Xing and Xiaoxin Zhang},
   booktitle = {Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering},
   pages = {834-845},
   title = {Generating concept based API element comparison using a knowledge graph},
   year = {2020},
}
@article{Wang2021,
   author = {Xin Wang and Xiao Liu and Jin Liu and Xiaomei Chen and Hao Wu},
   issue = {3},
   journal = {World Wide Web},
   pages = {869-894},
   publisher = {Springer},
   title = {A novel knowledge graph embedding based API recommendation method for Mashup development},
   volume = {24},
   year = {2021},
}
@article{Autili2020,
   abstract = {This paper presents CHOReVOLUTION, a platform for the tool-assisted realization and execution of distributed applications. CHOReVOLUTION specifically targets service-oriented systems specified through service choreographies. It offers an Integrated Development and Runtime Environment (IDRE) organized into three layers, namely, front-end, back-end, and cloud. It comprises a wizard-aided development environment and a system monitoring console in the front-end layer, and a back-end for managing the deployment and execution of the choreographed system on the cloud. We describe the IDRE by using an industrial use case in the domain of Smart Mobility & Tourism, and finally we provide details on its experimental evaluation.},
   author = {Marco Autili and Amleto Di Salle and Francesco Gallo and Claudio Pompilio and Massimo Tivoli},
   doi = {10.1016/J.SCICO.2020.102498},
   issn = {0167-6423},
   journal = {Science of Computer Programming},
   keywords = {Automated synthesis,Distributed computing,Distributed coordination,Service choreographies},
   month = {10},
   pages = {102498},
   publisher = {Elsevier},
   title = {CHOReVOLUTION: Service choreography in practice},
   volume = {197},
   year = {2020},
}
@article{Oberhauser2016,
   abstract = {Business processes are facing increasing pressure to quickly and flexibly adapt to changes in the process context. Moreover, microservices are becoming increasingly popular as an architectural style for partitioning business logic into small services accessible with lightweight mechanisms, leading to increasing pressure for a more dynamic integration of information services with processes. Process-aware information systems must thus increasingly incorporate the ability to react to unforeseen changes during process enactment, facing difficulties in pre-modelling all the possible process variations and enactment circumstances for larger process models. This paper presents Microflows, an automatic lightweight declarative approach for the workflow-centric orchestration of semantically-annotated microservices using agent-based clients, graph-based methods, and the lightweight semantic vocabularies JSON-LD and Hydra. The evaluation results show the approach's potential in lightweight resource utilization, investigates its scalability, and compares its automation to common manual workflow modeling and enactment.},
   author = {Roy Oberhauser},
   doi = {10.5220/0006223001340143},
   isbn = {9789897581908},
   journal = {BMSD 2016 - Proceedings of the 6th International Symposium on Business Modeling and Software Design},
   keywords = {Agent systems,Microservices,Semantic technology,Service orchestration,Workflow management systems},
   pages = {134-143},
   publisher = {SciTePress},
   title = {Microflows: Lightweight automated planning and enactment of workflows comprising semantically-annotated microservices},
   year = {2016},
}
@article{Yahia2016,
   abstract = {Distributed applications are evolving at a frantic pace, critically relying on each other to offer a host of new functionalities. The emergence of the service-oriented paradigm has made it possible to build complex applications as a set of self-contained and loosely coupled services that work altogether in concert. However, the traditional vision of Service-Oriented Architectures (SOA) based on web service specifications does not meet the trend of many major service providers. Instead, they promote microservices, a refinement of SOA focusing on lightweight communication mechanisms such as HTTP. Therefore, existing approaches for orchestrating the composition of various services become unusable in practice. In this paper, we introduce Medley, an event-driven lightweight platform for service composition. Medley is based on a domain-specific language for describing orchestration and a compiler that produces efficient code. We have used Medley to develop various compositions, involving a large number of existing services. Our evaluation shows that it scales both on a mainstream server and an embedded device while consuming a reasonable amount of resources.},
   author = {Elyas Ben Hadj Yahia and Laurent Réveillère and Yérom David Bromberg and Raphaël Chevalier and Alain Cadot},
   doi = {10.1007/978-3-319-38791-8_1/TABLES/1},
   isbn = {9783319387901},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Domain-specific languages,Event-driven programming,Microservices,Services orchestration,Web composition},
   pages = {3-20},
   publisher = {Springer Verlag},
   title = {Medley: An event-driven lightweight platform for service composition},
   volume = {9671},
   url = {https://link.springer.com/chapter/10.1007/978-3-319-38791-8_1},
   year = {2016},
}
@article{Monteiro2020,
   abstract = {The microservices architecture style proposes a solution for efficiently scaling computational resources and solving other problems presented in the traditional monolithic architecture. Despite providing benefits, microservices bring challenges when there is a need to manage business processes that expand across the boundaries of an individual microservice. Traditional approaches such as workflows are not suitable to manage business processes in microservice systems, and existing solutions have limitations in dealing with the dynamic location of microservices. To fill that gap, this work proposes the use of declarative business processes to facilitate the modeling and execution of microservice orchestration from the perspective of data flow processes. To this end, we use Beethoven, a platform composed of a reference architecture, and a domain-specific language for expressing microservice communication flows. Finally, we demonstrate the feasibility of Beethoven in orchestrating an existing microservice application and assess its impact on the performance of the orchestrated application.},
   author = {Davi Monteiro and Paulo Henrique M. Maia and Lincoln S. Rocha and Nabor C. Mendonça},
   doi = {10.1007/S11761-020-00300-2/FIGURES/12},
   issn = {18632394},
   issue = {4},
   journal = {Service Oriented Computing and Applications},
   keywords = {Declarative business process,Domain-specific language,Microservice composition,Microservice orchestration,Reference architecture},
   month = {12},
   pages = {243-268},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Building orchestrated microservice systems using declarative business processes},
   volume = {14},
   url = {https://link.springer.com/article/10.1007/s11761-020-00300-2},
   year = {2020},
}
@article{Valderas2020,
   abstract = {Context: Microservices must be composed to provide users with complex and elaborated functionalities. It seems that the decentralized nature of microservices makes a choreography style more appropriate to achieve such cooperation, where lighter solutions based on asynchronous events are generally used. However, a microservice composition based on choreography distributes the flow logic of the composition among microservices making further analysis and updating difficult, i.e. there is not a big picture of the composition that facilitates these tasks. Business Process Model and Notation (BPMN) is the OMG standard developed to represent Business Processes (BPs), being widely used to define the big picture of such compositions. However, BPMN is usually considered in orchestration-based solutions, and orchestration can be a drawback to achieve the decoupling pursued by a microservice architecture. Objective: Defining a microservice composition approach that allows us to create a composition in a BPMN model, which facilitates further analysis for taking engineering decisions, and execute them through an event-based choreography to have a high degree of decoupling and independence among microservices. Method: We followed a research methodology for information systems that consists of a 5-step process: awareness of the problem, suggestion, development, evaluation, and conclusion. Results: We presented a microservice composition approach based on the choreography of BPMN fragments. On the one hand, we propose to describe the big picture of the composition with a BPMN model, providing a valuable mechanism to analyse it when engineering decisions need to be taken. On the other hand, this model is split into fragments in order to be executed through an event-based choreography form, providing the high degree of decoupling among microservices demanded in this type of architecture. This composition approach is supported by a microservice architecture defined to achieve that both descriptions of a composition (big picture and split one) coexist. A realization of this architecture in Java/Spring technology is also presented. Conclusions: The evaluation that is done to our work allows us to conclude that the proposed approach for composing microservices is more efficient than solutions based on ad-hoc development.},
   author = {Pedro Valderas and Victoria Torres and Vicente Pelechano},
   doi = {10.1016/J.INFSOF.2020.106370},
   issn = {0950-5849},
   journal = {Information and Software Technology},
   keywords = {BPMN,Choreography,Composition,Microservices},
   month = {11},
   pages = {106370},
   publisher = {Elsevier},
   title = {A microservice composition approach based on the choreography of BPMN fragments},
   volume = {127},
   year = {2020},
}
@article{,
   abstract = {In recent years, microservice architectures have emerged as an agile approach for scalable web applications on cloud environments. As each microservice is developed and deployed independently, they can be developed in the platform and programming language that best suite their purposes, using a simple communication protocol, as REST APIs or asynchronous event-based collaborations, to compose them. In this paper, we argue that process engines provide an excellent platform to develop microservices whose business logic involves complex work flows or processes so that a Business Process language can be used as high-level language to develop these services and a process engine to execute it. We identify the requirements for integrating a process engine in a microservice architecture and we propose how the communication and deployment in a microservice architecture can be handled by the process engine.},
   author = {Antonio Manuel Gutiérrez–Fernández and Manuel Resinas and Antonio Ruiz–Cortés},
   doi = {10.1007/978-3-319-58457-7_19/TABLES/2},
   isbn = {9783319584560},
   issn = {18651348},
   journal = {Lecture Notes in Business Information Processing},
   keywords = {Event-based asynchronous communication,Microservice architecture,Process engine},
   pages = {252-263},
   publisher = {Springer Verlag},
   title = {Redefining a process engine as a microservice platform},
   volume = {281},
   url = {https://link.springer.com/chapter/10.1007/978-3-319-58457-7_19},
   year = {2017},
}
@article{Sun2021,
   abstract = {A microservice-based system is composed of numerous independently deployed and executed microservices, among which normally exist the complex dependencies. Traditional service composition approaches usually expect the business process predefined at design time. As a result, it is difficult for the microservice-based system to quickly adapt to the frequently changing operation environments and business requirements. To address the above limitations, we propose a variability-enabling and model-driven approach to developing adaptive microservice-based systems. Our approach first models the business process with variability using VxBPMN4MS, an extension of Business Process Model and Notation (BPMN) with support for variability, then transforms the business process model to variability supported microservice composition frameworks, and finally derives business process instances at run-time according to the predefined process configuration. We have developed a platform to automate the proposed approach as much as possible, and conducted a case study to evaluate the effectiveness of the proposed approach and platform.},
   author = {Chang Ai Sun and Jing Wang and Zhenxian Liu and Yanbo Han},
   doi = {10.1109/COMPSAC51774.2021.00130/VIDEO},
   isbn = {9781665424639},
   journal = {Proceedings - 2021 IEEE 45th Annual Computers, Software, and Applications Conference, COMPSAC 2021},
   keywords = {Adaptive microservice compositions,Business process model and notation,Microservices,Model-driven architecture,Variability modelling},
   month = {7},
   pages = {968-973},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {A variability-enabling and model-driven approach to adaptive microservice-based systems},
   year = {2021},
}
@article{Mendling2008,
   author = {Jan Mendling and Michael Hafner},
   issue = {5},
   journal = {Journal of Enterprise Information Management},
   pages = {525-542},
   publisher = {Emerald Group Publishing Limited},
   title = {From WS-CDL choreography to BPEL process orchestration},
   volume = {21},
   year = {2008},
}
@article{Singhal2019,
   author = {Neha Singhal and Usha Sakthivel and Pethuru Raj},
   issue = {1},
   journal = {International Journal of Web & Semantic Technology (IJWesT)},
   pages = {25},
   title = {Selection mechanism of micro-services orchestration vs. choreography},
   volume = {10},
   year = {2019},
}
@article{Yongchareon2020,
   author = {Sira Yongchareon and Chengfei Liu and Xiaohui Zhao},
   issue = {11},
   journal = {Concurrency and Computation: Practice and Experience},
   pages = {e5646},
   publisher = {Wiley Online Library},
   title = {UniFlexView: A unified framework for consistent construction of BPMN and BPEL process views},
   volume = {32},
   year = {2020},
}
@article{,
   author = {Rakshata Karlingannavar and Nagaraj Bhat},
   title = {Orchestration of Microservices Using Conductor},
}
@article{Valderas2020,
   author = {Pedro Valderas and Victoria Torres and Vicente Pelechano},
   journal = {Information and Software Technology},
   pages = {106370},
   publisher = {Elsevier},
   title = {A microservice composition approach based on the choreography of BPMN fragments},
   volume = {127},
   year = {2020},
}
@article{White2004,
   author = {Stephen A White},
   issue = {0},
   journal = {Ibm Cooperation},
   pages = {0},
   title = {Introduction to BPMN},
   volume = {2},
   year = {2004},
}
@article{Chinosi2012,
   author = {Michele Chinosi and Alberto Trombetta},
   issue = {1},
   journal = {Computer Standards & Interfaces},
   pages = {124-134},
   publisher = {Elsevier},
   title = {BPMN: An introduction to the standard},
   volume = {34},
   year = {2012},
}
@article{Rudrabhatla2018,
   author = {Chaitanya K Rudrabhatla},
   issue = {8},
   journal = {International Journal of Advanced Computer Science and Applications},
   publisher = {Science and Information (SAI) Organization Limited},
   title = {Comparison of event choreography and orchestration techniques in microservice architecture},
   volume = {9},
   year = {2018},
}
@inproceedings{Nikoo2020,
   author = {Mahdi Saeedi Nikoo and Önder Babur and Mark Van Den Brand},
   booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
   pages = {1-5},
   title = {A survey on service composition languages},
   year = {2020},
}
@inproceedings{Jiang2018,
   author = {Hui Jiang},
   booktitle = {2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)},
   pages = {394-399},
   title = {Research and implementation of financial approval system based on jBPM engine},
   year = {2018},
}
@book{,
   author = {程超等},
   month = {5},
   pages = {26-30},
   publisher = {北京：电子工业出版社},
   title = {高可用可伸缩微服务架构：基于Dubbo、Spring Cloud和Service Mesh},
   year = {2019},
}
@misc{Chopella2001,
   author = {Venkatesh Chopella and Kannan Govindarajan and Alan Karp and Harumi Kuno and Mike Lemon and Gregory Pogossiants and Shamik Sharma and Scott Williams},
   institution = {Technical Report, W3C. 2002. Available online: https://www. w3. org/TR~…},
   title = {Web services conversation language (wscl) 1.0},
   year = {2001},
}
@article{Leymann2001,
   author = {Frank Leymann and others},
   title = {Web services flow language (WSFL 1.0)},
   year = {2001},
}
@article{White2004,
   author = {Stephen A White},
   issue = {0},
   journal = {Ibm Cooperation},
   pages = {0},
   title = {Introduction to BPMN},
   volume = {2},
   year = {2004},
}
@article{Laskey2009,
   author = {Kathryn B Laskey and Kenneth Laskey},
   issue = {1},
   journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
   pages = {101-105},
   publisher = {Wiley Online Library},
   title = {Service oriented architecture},
   volume = {1},
   year = {2009},
}
@article{,
   author = {Johannes Thönes},
   issue = {1},
   journal = {IEEE software},
   pages = {116},
   publisher = {IEEE},
   title = {Microservices},
   volume = {32},
   year = {2015},
}
@article{,
   author = {王美林 and 彭希灵},
   issue = {010},
   journal = {物联网技术},
   pages = {54-57},
   title = {基于微服务的业务可编排重构MES系统},
   volume = {011},
   year = {2021},
}
@article{,
   author = {方家俊},
   institution = {南京大学},
   title = {基于微服务架构的工作流编排系统的设计与实现},
   year = {2021},
}
@article{,
   author = {戴伟},
   institution = {华东师范大学},
   title = {基于微服务架构的业务流程引擎设计与实现},
   year = {2022},
}
@article{,
   author = {王钧},
   institution = {北京邮电大学},
   title = {基于微服务平台的编排技术研究与优化},
   year = {2022},
}
@article{,
   author = {虞果},
   institution = {浙江大学},
   title = {基于微服务的精细化业务流程编排系统},
   year = {2019},
}
@article{Monteiro2018,
   abstract = {The microservice architecture provides an efficient manner to allocate computational resources since each microservice can be individually scaled. Despite its benefits, there are still challenges regarding the cooperation among different microservices in order to provide elaborated business processes. In this paper, we propose Beethoven, an event-driven lightweight platform for microservice orchestration that eases the creation of complex applications that use microservice data flows. The platform is composed of a reference architecture and an orchestration language. The reference architecture has been instantiated by using the Spring Cloud Netflix ecosystem. To demonstrate the feasibility of the Beethoven platform, an example application has been developed. All artifacts produced as part of this work are available.},
   author = {Davi Monteiro and Rômulo Gadelha and Paulo Henrique M. Maia and Lincoln S. Rocha and Nabor C. Mendonça},
   doi = {10.1007/978-3-030-00761-4_13},
   isbn = {9783030007607},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Event-driven architecture,Microservice composition,Orchestration,Reference architecture},
   pages = {191-199},
   publisher = {Springer Verlag},
   title = {Beethoven: An event-driven lightweight platform for microservice orchestration},
   volume = {11048 LNCS},
   year = {2018},
}
@article{,
   author = {Wil M P van der Aalst},
   issue = {1},
   journal = {IEEE intelligent systems},
   pages = {72-76},
   title = {Don’t go with the flow: Web services composition standards exposed},
   volume = {18},
   year = {2003},
}
@article{Ye2021,
   abstract = {Existing KBQA approaches, despite achieving strong performance on i.i.d. test data, often struggle in generalizing to questions involving unseen KB schema items. Prior ranking-based approaches have shown some success in generalization, but suffer from the coverage issue. We present RnG-KBQA, a Rank-and-Generate approach for KBQA, which remedies the coverage issue with a generation model while preserving a strong generalization capability. Our approach first uses a contrastive ranker to rank a set of candidate logical forms obtained by searching over the knowledge graph. It then introduces a tailored generation model conditioned on the question and the top-ranked candidates to compose the final logical form. We achieve new state-of-the-art results on GrailQA and WebQSP datasets. In particular, our method surpasses the prior state-of-the-art by a large margin on the GrailQA leaderboard. In addition, RnG-KBQA outperforms all prior approaches on the popular WebQSP benchmark, even including the ones that use the oracle entity linking. The experimental results demonstrate the effectiveness of the interplay between ranking and generation, which leads to the superior performance of our proposed approach across all settings with especially strong improvements in zero-shot generalization.},
   author = {Xi Ye and Semih Yavuz and Kazuma Hashimoto and Yingbo Zhou and Caiming Xiong},
   doi = {10.18653/v1/2022.acl-long.417},
   isbn = {9781955917216},
   issn = {0736587X},
   journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
   month = {9},
   pages = {6032-6043},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {RnG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering},
   volume = {1},
   url = {https://arxiv.org/abs/2109.08678v2},
   year = {2021},
}
@article{Shu2022,
   abstract = {Pre-trained language models (PLMs) have shown their effectiveness in multiple scenarios. However, KBQA remains challenging, especially regarding coverage and generalization settings. This is due to two main factors: i) understanding the semantics of both questions and relevant knowledge from the KB; ii) generating executable logical forms with both semantic and syntactic correctness. In this paper, we present a new KBQA model, TIARA, which addresses those issues by applying multi-grained retrieval to help the PLM focus on the most relevant KB contexts, viz., entities, exemplary logical forms, and schema items. Moreover, constrained decoding is used to control the output space and reduce generation errors. Experiments over important benchmarks demonstrate the effectiveness of our approach. TIARA outperforms previous SOTA, including those using PLMs or oracle entity annotations, by at least 4.1 and 1.1 F1 points on GrailQA and WebQuestionsSP, respectively.},
   author = {Yiheng Shu and Zhiwei Yu and Yuhan Li and Börje F. Karlsson and Tingting Ma and Yuzhong Qu and Chin Yew Lin},
   doi = {10.18653/v1/2022.emnlp-main.555},
   journal = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022},
   month = {10},
   pages = {8108-8121},
   publisher = {Association for Computational Linguistics (ACL)},
   title = {TIARA: Multi-grained Retrieval for Robust Question Answering over Large Knowledge Bases},
   url = {https://arxiv.org/abs/2210.12925v1},
   year = {2022},
}

@article{Jones1972,
   author = {Karen Sparck Jones},
   issue = {1},
   journal = {Journal of documentation},
   pages = {11-21},
   publisher = {MCB UP Ltd},
   title = {A statistical interpretation of term specificity and its application in retrieval},
   volume = {28},
   year = {1972},
}

@article{Patil2023,
   author = {Shishir G Patil and Tianjun Zhang and Xin Wang and Joseph E Gonzalez},
   journal = {arXiv preprint arXiv:2305.15334},
   title = {Gorilla: Large language model connected with massive apis},
   year = {2023},
}
@article{Robertson2009,
   author = {Stephen Robertson and Hugo Zaragoza and others},
   issue = {4},
   journal = {Foundations and Trends® in Information Retrieval},
   pages = {333-389},
   publisher = {Now Publishers, Inc.},
   title = {The probabilistic relevance framework: BM25 and beyond},
   volume = {3},
   year = {2009},
}
@article{Xu2023,
   author = {Fangyuan Xu and Weijia Shi and Eunsol Choi},
   journal = {arXiv preprint arXiv:2310.04408},
   title = {Recomp: Improving retrieval-augmented lms with compression and selective augmentation},
   year = {2023},
}
@article{Xiong2020,
   author = {Lee Xiong and Chenyan Xiong and Ye Li and Kwok-Fung Tang and Jialin Liu and Paul Bennett and Junaid Ahmed and Arnold Overwijk},
   journal = {arXiv preprint arXiv:2007.00808},
   title = {Approximate nearest neighbor negative contrastive learning for dense text retrieval},
   year = {2020},
}
@article{Zheng2024,
   author = {Yuanhang Zheng and Peng Li and Wei Liu and Yang Liu and Jian Luan and Bin Wang},
   journal = {arXiv preprint arXiv:2403.06551},
   title = {ToolRerank: Adaptive and Hierarchy-Aware Reranking for Tool Retrieval},
   year = {2024},
}
@inproceedings{Gao2024,
   author = {Shen Gao and Zhengliang Shi and Minghang Zhu and Bowen Fang and Xin Xin and Pengjie Ren and Zhumin Chen and Jun Ma and Zhaochun Ren},
   issue = {16},
   booktitle = {Proceedings of the AAAI Conference on Artificial Intelligence},
   pages = {18030-18038},
   title = {Confucius: Iterative tool learning from introspection feedback by easy-to-difficult curriculum},
   volume = {38},
   year = {2024},
}
@article{Gao2023,
   author = {Tianyu Gao and Howard Yen and Jiatong Yu and Danqi Chen},
   journal = {arXiv preprint arXiv:2305.14627},
   title = {Enabling large language models to generate text with citations},
   year = {2023},
}
@article{Gao2024,
   author = {Silin Gao and Jane Dwivedi-Yu and Ping Yu and Xiaoqing Ellen Tan and Ramakanth Pasunuru and Olga Golovneva and Koustuv Sinha and Asli Celikyilmaz and Antoine Bosselut and Tianlu Wang},
   journal = {arXiv preprint arXiv:2401.17464},
   title = {Efficient Tool Use with Chain-of-Abstraction Reasoning},
   year = {2024},
}
@article{Gao2023,
   author = {Yunfan Gao and Yun Xiong and Xinyu Gao and Kangxiang Jia and Jinliu Pan and Yuxi Bi and Yi Dai and Jiawei Sun and Haofen Wang},
   journal = {arXiv preprint arXiv:2312.10997},
   title = {Retrieval-augmented generation for large language models: A survey},
   year = {2023},
}
@inproceedings{Gao2024,
   author = {Zhi Gao and Yuntao Du and Xintong Zhang and Xiaojian Ma and Wenjuan Han and Song-Chun Zhu and Qing Li},
   booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
   pages = {13258-13268},
   title = {Clova: A closed-loop visual assistant with tool usage and update},
   year = {2024},
}
@article{Ge2024,
   author = {Yingqiang Ge and Wenyue Hua and Kai Mei and Juntao Tan and Shuyuan Xu and Zelong Li and Yongfeng Zhang and others},
   journal = {Advances in Neural Information Processing Systems},
   title = {Openagi: When llm meets domain experts},
   volume = {36},
   year = {2024},
}
@article{Qiao2022,
   author = {Shuofei Qiao and Yixin Ou and Ningyu Zhang and Xiang Chen and Yunzhi Yao and Shumin Deng and Chuanqi Tan and Fei Huang and Huajun Chen},
   journal = {arXiv preprint arXiv:2212.09597},
   title = {Reasoning with language model prompting: A survey},
   year = {2022},
}
@article{Qu2024,
   author = {Changle Qu and Sunhao Dai and Xiaochi Wei and Hengyi Cai and Shuaiqiang Wang and Dawei Yin and Jun Xu and Ji-Rong Wen},
   journal = {arXiv preprint arXiv:2405.16089},
   title = {COLT: Towards Completeness-Oriented Tool Retrieval for Large Language Models},
   year = {2024},
}
@article{Huang2024,
   author = {Tenghao Huang and Dongwon Jung and Muhao Chen},
   journal = {arXiv preprint arXiv:2404.00450},
   title = {Planning and Editing What You Retrieve for Enhanced Tool Learning},
   year = {2024},
}
@article{Liu2023,
   author = {Zhaoyang Liu and Zeqiang Lai and Zhangwei Gao and Erfei Cui and Zhiheng Li and Xizhou Zhu and Lewei Lu and Qifeng Chen and Yu Qiao and Jifeng Dai and others},
   journal = {arXiv preprint arXiv:2310.17796},
   title = {Controlllm: Augment language models with tools by searching on graphs},
   year = {2023},
}
@inproceedings{Huang2022,
   author = {Wenlong Huang and Pieter Abbeel and Deepak Pathak and Igor Mordatch},
   booktitle = {International conference on machine learning},
   pages = {9118-9147},
   title = {Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
   year = {2022},
}
@article{Huang2024,
   author = {Xu Huang and Weiwen Liu and Xiaolong Chen and Xingmei Wang and Hao Wang and Defu Lian and Yasheng Wang and Ruiming Tang and Enhong Chen},
   journal = {arXiv preprint arXiv:2402.02716},
   title = {Understanding the planning of LLM agents: A survey},
   year = {2024},
}
@inproceedings{Huang2022,
   author = {Wenlong Huang and Pieter Abbeel and Deepak Pathak and Igor Mordatch},
   booktitle = {International conference on machine learning},
   pages = {9118-9147},
   title = {Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
   year = {2022},
}
@article{Huang2024,
   author = {Xu Huang and Weiwen Liu and Xiaolong Chen and Xingmei Wang and Hao Wang and Defu Lian and Yasheng Wang and Ruiming Tang and Enhong Chen},
   journal = {arXiv preprint arXiv:2402.02716},
   title = {Understanding the planning of LLM agents: A survey},
   year = {2024},
}
@article{Liu2024,
   author = {Xukun Liu and Zhiyuan Peng and Xiaoyuan Yi and Xing Xie and Lirong Xiang and Yuchen Liu and Dongkuan Xu},
   journal = {arXiv preprint arXiv:2403.00839},
   title = {ToolNet: Connecting large language models with massive tools via tool graph},
   year = {2024},
}
@article{Mekala2024,
   author = {Dheeraj Mekala and Jason Weston and Jack Lanchantin and Roberta Raileanu and Maria Lomeli and Jingbo Shang and Jane Dwivedi-Yu},
   journal = {arXiv preprint arXiv:2402.14158},
   title = {TOOLVERIFIER: Generalization to New Tools via Self-Verification},
   year = {2024},
}
@article{Du2024,
   author = {Yu Du and Fangyun Wei and Hongyang Zhang},
   journal = {arXiv preprint arXiv:2402.04253},
   title = {Anytool: Self-reflective, hierarchical agents for large-scale api calls},
   year = {2024},
}
@article{Fatemi2023,
   author = {Bahare Fatemi and Jonathan Halcrow and Bryan Perozzi},
   journal = {arXiv preprint arXiv:2310.04560},
   title = {Talk like a graph: Encoding graphs for large language models},
   year = {2023},
}
@article{Guo2023,
   author = {Jiayan Guo and Lun Du and Hengyu Liu and Mengyu Zhou and Xinyi He and Shi Han},
   journal = {arXiv preprint arXiv:2305.15066},
   title = {Gpt4graph: Can large language models understand graph structured data? an empirical evaluation and benchmarking},
   year = {2023},
}
@article{Chai2023,
   author = {Ziwei Chai and Tianjie Zhang and Liang Wu and Kaiqiao Han and Xiaohai Hu and Xuanwen Huang and Yang Yang},
   journal = {arXiv preprint arXiv:2310.05845},
   title = {Graphllm: Boosting graph reasoning ability of large language model},
   year = {2023},
}
@article{Jiang2023,
   author = {Jinhao Jiang and Kun Zhou and Zican Dong and Keming Ye and Wayne Xin Zhao and Ji-Rong Wen},
   journal = {arXiv preprint arXiv:2305.09645},
   title = {Structgpt: A general framework for large language model to reason over structured data},
   year = {2023},
}
@article{Sun2023,
   author = {Jiashuo Sun and Chengjin Xu and Lumingyuan Tang and Saizhuo Wang and Chen Lin and Yeyun Gong and Heung-Yeung Shum and Jian Guo},
   journal = {arXiv preprint arXiv:2307.07697},
   title = {Think-on-graph: Deep and responsible reasoning of large language model with knowledge graph},
   year = {2023},
}
@article{Ma2024,
   author = {Shengjie Ma and Chengjin Xu and Xuhui Jiang and Muzhi Li and Huaren Qu and Jian Guo},
   journal = {arXiv preprint arXiv:2407.10805},
   title = {Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval},
   year = {2024},
}
